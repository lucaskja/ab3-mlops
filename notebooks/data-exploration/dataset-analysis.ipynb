{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drone Imagery Dataset Analysis\n",
    "\n",
    "This notebook provides comprehensive analysis and exploration of the drone imagery dataset stored in S3 bucket 'lucaskle-ab3-project-pv'. It includes data profiling, visualization, and quality validation for YOLOv11 format requirements.\n",
    "\n",
    "## Requirements Addressed:\n",
    "- 1.1: Data Scientist read-only access to S3 dataset\n",
    "- 1.2: Data profiling and visualization capabilities\n",
    "- 1.3: Dataset exploration functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Import custom utilities\n",
    "import sys\n",
    "sys.path.append('../../src')\n",
    "from data.s3_utils import S3DataAccess\n",
    "from data.data_profiler import DroneImageryProfiler\n",
    "from data.data_validator import YOLOv11Validator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize S3 Data Access\n",
    "\n",
    "Set up connection to the S3 bucket containing drone imagery data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize S3 data access with proper error handling\n",
    "BUCKET_NAME = 'lucaskle-ab3-project-pv'\n",
    "AWS_PROFILE = 'ab'  # Using the specified AWS CLI profile\n",
    "\n",
    "try:\n",
    "    s3_access = S3DataAccess(bucket_name=BUCKET_NAME, aws_profile=AWS_PROFILE)\n",
    "    print(f\"‚úÖ Successfully connected to S3 bucket: {BUCKET_NAME}\")\n",
    "    \n",
    "    # Test connection and list some objects\n",
    "    sample_objects = s3_access.list_objects(prefix='', max_keys=10)\n",
    "    print(f\"üìÅ Found {len(sample_objects)} sample objects in bucket\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error connecting to S3: {str(e)}\")\n",
    "    print(\"Please ensure AWS credentials are configured for profile 'ab'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Overview and Structure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze dataset structure\n",
    "print(\"üîç Analyzing dataset structure...\")\n",
    "\n",
    "# Get all objects in the bucket\n",
    "all_objects = s3_access.list_objects(prefix='', max_keys=1000)\n",
    "\n",
    "# Categorize files by type\n",
    "file_types = {}\n",
    "total_size = 0\n",
    "\n",
    "for obj in all_objects:\n",
    "    key = obj['Key']\n",
    "    size = obj['Size']\n",
    "    total_size += size\n",
    "    \n",
    "    # Extract file extension\n",
    "    ext = key.split('.')[-1].lower() if '.' in key else 'no_extension'\n",
    "    \n",
    "    if ext not in file_types:\n",
    "        file_types[ext] = {'count': 0, 'total_size': 0}\n",
    "    \n",
    "    file_types[ext]['count'] += 1\n",
    "    file_types[ext]['total_size'] += size\n",
    "\n",
    "# Display dataset overview\n",
    "print(f\"üìä Dataset Overview:\")\n",
    "print(f\"   Total files: {len(all_objects)}\")\n",
    "print(f\"   Total size: {total_size / (1024**3):.2f} GB\")\n",
    "print(f\"\\nüìÅ File types distribution:\")\n",
    "\n",
    "for ext, info in sorted(file_types.items(), key=lambda x: x[1]['count'], reverse=True):\n",
    "    size_mb = info['total_size'] / (1024**2)\n",
    "    print(f\"   .{ext}: {info['count']} files ({size_mb:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image Data Profiling and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data profiler\n",
    "profiler = DroneImageryProfiler(s3_access)\n",
    "\n",
    "# Profile image characteristics\n",
    "print(\"üñºÔ∏è Profiling drone imagery characteristics...\")\n",
    "\n",
    "# Get image files (assuming common image extensions)\n",
    "image_extensions = ['jpg', 'jpeg', 'png', 'tiff', 'tif']\n",
    "image_files = [obj['Key'] for obj in all_objects \n",
    "               if any(obj['Key'].lower().endswith(f'.{ext}') for ext in image_extensions)]\n",
    "\n",
    "print(f\"üì∏ Found {len(image_files)} image files\")\n",
    "\n",
    "# Sample a subset for detailed analysis (to avoid processing too many files)\n",
    "sample_size = min(50, len(image_files))\n",
    "sample_images = np.random.choice(image_files, sample_size, replace=False) if len(image_files) > 0 else []\n",
    "\n",
    "print(f\"üéØ Analyzing sample of {len(sample_images)} images for detailed profiling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform detailed image analysis\n",
    "if len(sample_images) > 0:\n",
    "    image_profile = profiler.profile_images(sample_images)\n",
    "    \n",
    "    # Display image statistics\n",
    "    print(\"üìä Image Characteristics Summary:\")\n",
    "    print(f\"   Resolution range: {image_profile['min_width']}x{image_profile['min_height']} to {image_profile['max_width']}x{image_profile['max_height']}\")\n",
    "    print(f\"   Average resolution: {image_profile['avg_width']:.0f}x{image_profile['avg_height']:.0f}\")\n",
    "    print(f\"   Color modes: {', '.join(image_profile['color_modes'])}\")\n",
    "    print(f\"   File formats: {', '.join(image_profile['formats'])}\")\n",
    "    print(f\"   Average file size: {image_profile['avg_file_size']:.1f} MB\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Drone Imagery Dataset Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Resolution distribution\n",
    "    axes[0, 0].scatter(image_profile['widths'], image_profile['heights'], alpha=0.6)\n",
    "    axes[0, 0].set_xlabel('Width (pixels)')\n",
    "    axes[0, 0].set_ylabel('Height (pixels)')\n",
    "    axes[0, 0].set_title('Image Resolution Distribution')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Aspect ratio distribution\n",
    "    aspect_ratios = [w/h for w, h in zip(image_profile['widths'], image_profile['heights'])]\n",
    "    axes[0, 1].hist(aspect_ratios, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axes[0, 1].set_xlabel('Aspect Ratio (W/H)')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].set_title('Aspect Ratio Distribution')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # File size distribution\n",
    "    file_sizes_mb = [size / (1024**2) for size in image_profile['file_sizes']]\n",
    "    axes[1, 0].hist(file_sizes_mb, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axes[1, 0].set_xlabel('File Size (MB)')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].set_title('File Size Distribution')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Color mode distribution\n",
    "    color_mode_counts = {mode: image_profile['color_modes'].count(mode) for mode in set(image_profile['color_modes'])}\n",
    "    axes[1, 1].pie(color_mode_counts.values(), labels=color_mode_counts.keys(), autopct='%1.1f%%')\n",
    "    axes[1, 1].set_title('Color Mode Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No image files found for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. YOLOv11 Format Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YOLOv11 validator\n",
    "validator = YOLOv11Validator(s3_access)\n",
    "\n",
    "print(\"üéØ Validating data for YOLOv11 format requirements...\")\n",
    "\n",
    "# Look for annotation files (common formats: .txt, .json, .xml)\n",
    "annotation_files = [obj['Key'] for obj in all_objects \n",
    "                   if any(obj['Key'].lower().endswith(f'.{ext}') for ext in ['txt', 'json', 'xml', 'yaml', 'yml'])]\n",
    "\n",
    "print(f\"üìù Found {len(annotation_files)} potential annotation files\")\n",
    "\n",
    "# Validate dataset structure for YOLOv11\n",
    "validation_results = validator.validate_dataset_structure(image_files, annotation_files)\n",
    "\n",
    "print(\"\\n‚úÖ YOLOv11 Format Validation Results:\")\n",
    "print(f\"   Images suitable for YOLOv11: {validation_results['valid_images']}\")\n",
    "print(f\"   Images requiring preprocessing: {validation_results['images_need_preprocessing']}\")\n",
    "print(f\"   Annotation files found: {validation_results['annotation_files_found']}\")\n",
    "print(f\"   Recommended input size: {validation_results['recommended_input_size']}\")\n",
    "\n",
    "if validation_results['issues']:\n",
    "    print(\"\\n‚ö†Ô∏è Issues identified:\")\n",
    "    for issue in validation_results['issues']:\n",
    "        print(f\"   - {issue}\")\n",
    "\n",
    "if validation_results['recommendations']:\n",
    "    print(\"\\nüí° Recommendations:\")\n",
    "    for rec in validation_results['recommendations']:\n",
    "        print(f\"   - {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform comprehensive data quality assessment\n",
    "print(\"üîç Performing data quality assessment...\")\n",
    "\n",
    "quality_report = validator.assess_data_quality(sample_images)\n",
    "\n",
    "print(\"\\nüìä Data Quality Report:\")\n",
    "print(f\"   Overall quality score: {quality_report['overall_score']:.1f}/10\")\n",
    "print(f\"   Images with good quality: {quality_report['high_quality_count']}\")\n",
    "print(f\"   Images with medium quality: {quality_report['medium_quality_count']}\")\n",
    "print(f\"   Images with low quality: {quality_report['low_quality_count']}\")\n",
    "\n",
    "# Quality metrics breakdown\n",
    "print(\"\\nüìà Quality Metrics:\")\n",
    "for metric, value in quality_report['metrics'].items():\n",
    "    print(f\"   {metric}: {value:.3f}\")\n",
    "\n",
    "# Visualize quality distribution\n",
    "if 'quality_scores' in quality_report:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(quality_report['quality_scores'], bins=20, alpha=0.7, edgecolor='black')\n",
    "    plt.axvline(quality_report['overall_score'], color='red', linestyle='--', \n",
    "                label=f'Average Score: {quality_report[\"overall_score\"]:.1f}')\n",
    "    plt.xlabel('Quality Score')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.title('Image Quality Score Distribution')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sample Image Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images from the dataset\n",
    "if len(sample_images) >= 4:\n",
    "    print(\"üñºÔ∏è Displaying sample images from the dataset...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle('Sample Drone Imagery from Dataset', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Display 4 random sample images\n",
    "    sample_to_display = np.random.choice(sample_images, 4, replace=False)\n",
    "    \n",
    "    for idx, img_key in enumerate(sample_to_display):\n",
    "        try:\n",
    "            # Download and display image\n",
    "            img_data = s3_access.download_file_to_memory(img_key)\n",
    "            img = Image.open(img_data)\n",
    "            \n",
    "            row, col = idx // 2, idx % 2\n",
    "            axes[row, col].imshow(img)\n",
    "            axes[row, col].set_title(f'{os.path.basename(img_key)}\\n{img.size[0]}x{img.size[1]}')\n",
    "            axes[row, col].axis('off')\n",
    "            \n",
    "        except Exception as e:\n",
    "            axes[row, col].text(0.5, 0.5, f'Error loading\\n{os.path.basename(img_key)}', \n",
    "                              ha='center', va='center', transform=axes[row, col].transAxes)\n",
    "            axes[row, col].set_title(f'Error: {str(e)[:30]}...')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Not enough sample images available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary report\n",
    "print(\"üìã Dataset Analysis Summary Report\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nüóÇÔ∏è Dataset Overview:\")\n",
    "print(f\"   ‚Ä¢ Total files in bucket: {len(all_objects)}\")\n",
    "print(f\"   ‚Ä¢ Image files identified: {len(image_files)}\")\n",
    "print(f\"   ‚Ä¢ Annotation files found: {len(annotation_files)}\")\n",
    "print(f\"   ‚Ä¢ Total dataset size: {total_size / (1024**3):.2f} GB\")\n",
    "\n",
    "if len(sample_images) > 0 and 'image_profile' in locals():\n",
    "    print(f\"\\nüñºÔ∏è Image Characteristics:\")\n",
    "    print(f\"   ‚Ä¢ Resolution range: {image_profile['min_width']}x{image_profile['min_height']} to {image_profile['max_width']}x{image_profile['max_height']}\")\n",
    "    print(f\"   ‚Ä¢ Average resolution: {image_profile['avg_width']:.0f}x{image_profile['avg_height']:.0f}\")\n",
    "    print(f\"   ‚Ä¢ Dominant color mode: {max(set(image_profile['color_modes']), key=image_profile['color_modes'].count)}\")\n",
    "    print(f\"   ‚Ä¢ Average file size: {image_profile['avg_file_size']:.1f} MB\")\n",
    "\n",
    "if 'validation_results' in locals():\n",
    "    print(f\"\\nüéØ YOLOv11 Readiness:\")\n",
    "    print(f\"   ‚Ä¢ Images ready for YOLOv11: {validation_results['valid_images']}\")\n",
    "    print(f\"   ‚Ä¢ Images needing preprocessing: {validation_results['images_need_preprocessing']}\")\n",
    "    print(f\"   ‚Ä¢ Recommended input size: {validation_results['recommended_input_size']}\")\n",
    "\n",
    "if 'quality_report' in locals():\n",
    "    print(f\"\\n‚úÖ Data Quality:\")\n",
    "    print(f\"   ‚Ä¢ Overall quality score: {quality_report['overall_score']:.1f}/10\")\n",
    "    print(f\"   ‚Ä¢ High quality images: {quality_report['high_quality_count']}\")\n",
    "    print(f\"   ‚Ä¢ Images requiring attention: {quality_report['low_quality_count']}\")\n",
    "\n",
    "print(f\"\\nüí° Next Steps:\")\n",
    "print(f\"   1. Review data quality issues and consider filtering low-quality images\")\n",
    "print(f\"   2. Implement data preprocessing pipeline for YOLOv11 format conversion\")\n",
    "print(f\"   3. Create or validate annotation files for supervised learning\")\n",
    "print(f\"   4. Consider data augmentation strategies for training enhancement\")\n",
    "print(f\"   5. Set up data versioning and lineage tracking for MLOps pipeline\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"‚úÖ Dataset analysis completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}