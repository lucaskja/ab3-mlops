{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Profiling for Drone Imagery Dataset\n",
    "\n",
    "This notebook focuses specifically on data profiling functions and quality metrics for the drone imagery dataset. It provides detailed analysis of image characteristics and generates comprehensive profiling reports.\n",
    "\n",
    "## Requirements Addressed:\n",
    "- 1.2: Data profiling and visualization capabilities\n",
    "- Analysis of drone imagery characteristics for ML pipeline optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "sys.path.append('../../src')\n",
    "\n",
    "from data.s3_utils import S3DataAccess\n",
    "from data.data_profiler import DroneImageryProfiler\n",
    "from data.data_validator import YOLOv11Validator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(f\"Data profiling session started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Data Access and Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BUCKET_NAME = 'lucaskle-ab3-project-pv'\n",
    "AWS_PROFILE = 'ab'\n",
    "\n",
    "# Initialize S3 access and profiler\n",
    "try:\n",
    "    s3_access = S3DataAccess(bucket_name=BUCKET_NAME, aws_profile=AWS_PROFILE)\n",
    "    profiler = DroneImageryProfiler(s3_access)\n",
    "    validator = YOLOv11Validator(s3_access)\n",
    "    \n",
    "    print(\"✅ Successfully initialized data access and profiling tools\")\n",
    "    \n",
    "    # Display connection info\n",
    "    conn_info = s3_access.get_connection_info()\n",
    "    print(f\"📡 Connected to: {conn_info['bucket_name']} using profile '{conn_info['aws_profile']}'\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error initializing tools: {str(e)}\")\n",
    "    print(\"Please ensure AWS credentials are properly configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Discover and Categorize Dataset Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discover all files in the dataset\n",
    "print(\"🔍 Discovering dataset files...\")\n",
    "\n",
    "all_objects = s3_access.list_objects(prefix='', max_keys=2000)\n",
    "print(f\"📁 Found {len(all_objects)} total files\")\n",
    "\n",
    "# Filter image files\n",
    "image_extensions = ['jpg', 'jpeg', 'png', 'tiff', 'tif', 'bmp']\n",
    "image_files = s3_access.filter_objects_by_extension(image_extensions)\n",
    "\n",
    "# Filter annotation files\n",
    "annotation_extensions = ['txt', 'json', 'xml', 'yaml', 'yml']\n",
    "annotation_files = s3_access.filter_objects_by_extension(annotation_extensions)\n",
    "\n",
    "print(f\"🖼️ Image files: {len(image_files)}\")\n",
    "print(f\"📝 Annotation files: {len(annotation_files)}\")\n",
    "\n",
    "# Display file type distribution\n",
    "file_types = {}\n",
    "for obj in all_objects:\n",
    "    ext = obj['Key'].split('.')[-1].lower() if '.' in obj['Key'] else 'no_extension'\n",
    "    file_types[ext] = file_types.get(ext, 0) + 1\n",
    "\n",
    "print(\"\\n📊 File type distribution:\")\n",
    "for ext, count in sorted(file_types.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"   .{ext}: {count} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comprehensive Image Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform comprehensive image profiling\n",
    "if len(image_files) > 0:\n",
    "    print(f\"🔬 Starting comprehensive profiling of {len(image_files)} images...\")\n",
    "    \n",
    "    # Use a reasonable sample size for detailed analysis\n",
    "    sample_size = min(100, len(image_files))\n",
    "    print(f\"📊 Analyzing sample of {sample_size} images for detailed profiling\")\n",
    "    \n",
    "    # Perform profiling\n",
    "    profile_results = profiler.profile_images(image_files, sample_size=sample_size)\n",
    "    \n",
    "    print(f\"✅ Profiling completed successfully!\")\n",
    "    print(f\"   - Images processed: {profile_results['total_images_processed']}\")\n",
    "    print(f\"   - Processing errors: {profile_results['processing_errors']}\")\n",
    "    print(f\"   - Success rate: {profile_results['success_rate']:.1%}\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ No image files found for profiling\")\n",
    "    profile_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Detailed Profile Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display comprehensive profile report\n",
    "if profile_results:\n",
    "    print(\"📋 Generating comprehensive profile report...\\n\")\n",
    "    \n",
    "    # Generate formatted report\n",
    "    report = profiler.generate_profile_report(profile_results)\n",
    "    print(report)\n",
    "    \n",
    "    # Generate recommendations\n",
    "    recommendations = profiler.get_recommendations(profile_results)\n",
    "    \n",
    "    print(\"\\n💡 PROFILING RECOMMENDATIONS\")\n",
    "    print(\"-\" * 40)\n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        print(f\"{i}. {rec}\")\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️ No profile results available for report generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Quality Metrics Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create advanced visualizations of quality metrics\n",
    "if profile_results and len(profile_results.get('brightness_scores', [])) > 0:\n",
    "    print(\"📈 Creating advanced quality metrics visualizations...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('Advanced Image Quality Metrics Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Brightness distribution\n",
    "    axes[0, 0].hist(profile_results['brightness_scores'], bins=30, alpha=0.7, color='gold', edgecolor='black')\n",
    "    axes[0, 0].axvline(np.mean(profile_results['brightness_scores']), color='red', linestyle='--', \n",
    "                      label=f'Mean: {np.mean(profile_results[\"brightness_scores\"]):.3f}')\n",
    "    axes[0, 0].set_xlabel('Brightness Score')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].set_title('Brightness Distribution')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Contrast distribution\n",
    "    axes[0, 1].hist(profile_results['contrast_scores'], bins=30, alpha=0.7, color='lightblue', edgecolor='black')\n",
    "    axes[0, 1].axvline(np.mean(profile_results['contrast_scores']), color='red', linestyle='--',\n",
    "                      label=f'Mean: {np.mean(profile_results[\"contrast_scores\"]):.3f}')\n",
    "    axes[0, 1].set_xlabel('Contrast Score')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].set_title('Contrast Distribution')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Sharpness distribution\n",
    "    axes[0, 2].hist(profile_results['sharpness_scores'], bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "    axes[0, 2].axvline(np.mean(profile_results['sharpness_scores']), color='red', linestyle='--',\n",
    "                      label=f'Mean: {np.mean(profile_results[\"sharpness_scores\"]):.3f}')\n",
    "    axes[0, 2].set_xlabel('Sharpness Score')\n",
    "    axes[0, 2].set_ylabel('Frequency')\n",
    "    axes[0, 2].set_title('Sharpness Distribution')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Color diversity distribution\n",
    "    axes[1, 0].hist(profile_results['color_diversity_scores'], bins=30, alpha=0.7, color='coral', edgecolor='black')\n",
    "    axes[1, 0].axvline(np.mean(profile_results['color_diversity_scores']), color='red', linestyle='--',\n",
    "                      label=f'Mean: {np.mean(profile_results[\"color_diversity_scores\"]):.3f}')\n",
    "    axes[1, 0].set_xlabel('Color Diversity Score')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].set_title('Color Diversity Distribution')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Quality correlation matrix\n",
    "    quality_data = pd.DataFrame({\n",
    "        'Brightness': profile_results['brightness_scores'],\n",
    "        'Contrast': profile_results['contrast_scores'],\n",
    "        'Sharpness': profile_results['sharpness_scores'],\n",
    "        'Color Diversity': profile_results['color_diversity_scores']\n",
    "    })\n",
    "    \n",
    "    correlation_matrix = quality_data.corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                square=True, ax=axes[1, 1], cbar_kws={'shrink': 0.8})\n",
    "    axes[1, 1].set_title('Quality Metrics Correlation')\n",
    "    \n",
    "    # Overall quality score distribution\n",
    "    overall_scores = []\n",
    "    for i in range(len(profile_results['brightness_scores'])):\n",
    "        # Calculate composite quality score\n",
    "        score = (profile_results['brightness_scores'][i] + \n",
    "                profile_results['contrast_scores'][i] + \n",
    "                profile_results['sharpness_scores'][i] + \n",
    "                profile_results['color_diversity_scores'][i]) / 4\n",
    "        overall_scores.append(score)\n",
    "    \n",
    "    axes[1, 2].hist(overall_scores, bins=30, alpha=0.7, color='mediumpurple', edgecolor='black')\n",
    "    axes[1, 2].axvline(np.mean(overall_scores), color='red', linestyle='--',\n",
    "                      label=f'Mean: {np.mean(overall_scores):.3f}')\n",
    "    axes[1, 2].set_xlabel('Overall Quality Score')\n",
    "    axes[1, 2].set_ylabel('Frequency')\n",
    "    axes[1, 2].set_title('Overall Quality Distribution')\n",
    "    axes[1, 2].legend()\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ Insufficient data for quality metrics visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Profiling Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export profiling results for further analysis\n",
    "if profile_results:\n",
    "    print(\"💾 Exporting profiling results...\")\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    if len(profile_results.get('widths', [])) > 0:\n",
    "        summary_data = {\n",
    "            'Image_Index': range(len(profile_results['widths'])),\n",
    "            'Width': profile_results['widths'],\n",
    "            'Height': profile_results['heights'],\n",
    "            'Aspect_Ratio': profile_results['aspect_ratios'],\n",
    "            'File_Size_MB': [size / (1024*1024) for size in profile_results['file_sizes']],\n",
    "            'Color_Mode': profile_results['color_modes'],\n",
    "            'Format': profile_results['formats'],\n",
    "            'Brightness': profile_results['brightness_scores'],\n",
    "            'Contrast': profile_results['contrast_scores'],\n",
    "            'Sharpness': profile_results['sharpness_scores'],\n",
    "            'Color_Diversity': profile_results['color_diversity_scores']\n",
    "        }\n",
    "        \n",
    "        df = pd.DataFrame(summary_data)\n",
    "        \n",
    "        # Display summary statistics\n",
    "        print(\"\\n📊 Summary Statistics:\")\n",
    "        print(df.describe())\n",
    "        \n",
    "        # Save to CSV (optional - uncomment if needed)\n",
    "        # timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        # csv_filename = f'drone_imagery_profile_{timestamp}.csv'\n",
    "        # df.to_csv(csv_filename, index=False)\n",
    "        # print(f\"\\n💾 Results exported to: {csv_filename}\")\n",
    "        \n",
    "        print(\"\\n✅ Profiling analysis completed successfully!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"⚠️ No data available for export\")\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️ No profiling results available for export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Profiling Session Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate session summary\n",
    "print(\"📋 DATA PROFILING SESSION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Session completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Dataset: {BUCKET_NAME}\")\n",
    "print(f\"AWS Profile: {AWS_PROFILE}\")\n",
    "\n",
    "if profile_results:\n",
    "    print(f\"\\n📊 Processing Results:\")\n",
    "    print(f\"   • Total images found: {len(image_files)}\")\n",
    "    print(f\"   • Images analyzed: {profile_results['total_images_processed']}\")\n",
    "    print(f\"   • Processing success rate: {profile_results['success_rate']:.1%}\")\n",
    "    print(f\"   • Processing errors: {profile_results['processing_errors']}\")\n",
    "    \n",
    "    if 'avg_width' in profile_results:\n",
    "        print(f\"\\n🖼️ Image Characteristics:\")\n",
    "        print(f\"   • Average resolution: {profile_results['avg_width']:.0f}x{profile_results['avg_height']:.0f}\")\n",
    "        print(f\"   • Resolution range: {profile_results['min_width']}x{profile_results['min_height']} to {profile_results['max_width']}x{profile_results['max_height']}\")\n",
    "        print(f\"   • Average file size: {profile_results['avg_file_size']:.1f} MB\")\n",
    "        print(f\"   • Color modes: {', '.join(profile_results['color_modes'])}\")\n",
    "        print(f\"   • File formats: {', '.join(profile_results['formats'])}\")\n",
    "    \n",
    "    if 'avg_brightness' in profile_results:\n",
    "        print(f\"\\n✅ Quality Metrics:\")\n",
    "        print(f\"   • Average brightness: {profile_results['avg_brightness']:.3f}\")\n",
    "        print(f\"   • Average contrast: {profile_results['avg_contrast']:.3f}\")\n",
    "        print(f\"   • Average sharpness: {profile_results['avg_sharpness']:.3f}\")\n",
    "        print(f\"   • Average color diversity: {profile_results['avg_color_diversity']:.3f}\")\n",
    "\n",
    "print(f\"\\n📝 Annotation files found: {len(annotation_files)}\")\n",
    "print(f\"\\n🎯 Ready for next steps: YOLOv11 training pipeline development\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}