{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Scientist Core Workflow with MLFlow\n",
        "\n",
        "This notebook provides essential functionality for Data Scientists to explore and prepare drone imagery data for YOLOv11 model training, with MLFlow experiment tracking integration.\n",
        "\n",
        "## Workflow Overview\n",
        "\n",
        "1. **Data Exploration**: Analyze and visualize the drone imagery dataset\n",
        "2. **Data Preparation**: Prepare data for YOLOv11 training\n",
        "3. **Ground Truth Labeling**: Create labeling jobs for annotation\n",
        "4. **Experiment Tracking**: Track data exploration experiments with MLFlow\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- AWS account with appropriate permissions\n",
        "- AWS CLI configured with \"ab\" profile\n",
        "- SageMaker Studio access with Data Scientist role\n",
        "- Access to the drone imagery dataset in S3 bucket: `lucaskle-ab3-project-pv`\n",
        "- SageMaker managed MLFlow tracking server\n",
        "\n",
        "Let's start by importing the necessary libraries and setting up our environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import boto3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from IPython.display import display, HTML\n",
        "import io\n",
        "import json\n",
        "from PIL import Image\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import sagemaker\n",
        "\n",
        "# Set up AWS session with \"ab\" profile\n",
        "session = boto3.Session(profile_name='ab')\n",
        "s3_client = session.client('s3')\n",
        "sagemaker_client = session.client('sagemaker')\n",
        "sagemaker_session = sagemaker.Session(boto_session=session)\n",
        "region = session.region_name\n",
        "account_id = session.client('sts').get_caller_identity()['Account']\n",
        "\n",
        "# Set up MLFlow tracking\n",
        "# Get SageMaker managed MLFlow tracking server URI\n",
        "mlflow_tracking_uri = sagemaker_session.get_caller_identity_arn().replace('arn:aws:sts::', 'https://').replace(':assumed-role', '.mlflow')\n",
        "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
        "\n",
        "# Set up visualization\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
        "\n",
        "# Define bucket name\n",
        "BUCKET_NAME = 'lucaskle-ab3-project-pv'\n",
        "\n",
        "print(f\"Data Bucket: {BUCKET_NAME}\")\n",
        "print(f\"Region: {region}\")\n",
        "print(f\"Account ID: {account_id}\")\n",
        "print(f\"MLFlow Tracking URI: {mlflow_tracking_uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Exploration with MLFlow Tracking\n",
        "\n",
        "Let's start by exploring the drone imagery dataset stored in S3 and track our exploration with MLFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start MLFlow experiment for data exploration\n",
        "experiment_name = \"drone-imagery-data-exploration\"\n",
        "mlflow.set_experiment(experiment_name)\n",
        "\n",
        "# Start MLFlow run\n",
        "with mlflow.start_run(run_name=f\"data-exploration-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"):\n",
        "    def list_s3_objects(bucket, prefix=\"\"):\n",
        "        \"\"\"List all objects in an S3 bucket with the given prefix\"\"\"\n",
        "        all_objects = []\n",
        "        paginator = s3_client.get_paginator('list_objects_v2')\n",
        "        \n",
        "        # Create a PageIterator from the Paginator\n",
        "        page_iterator = paginator.paginate(\n",
        "            Bucket=bucket,\n",
        "            Prefix=prefix\n",
        "        )\n",
        "        \n",
        "        # Iterate through each page\n",
        "        for page in page_iterator:\n",
        "            if 'Contents' in page:\n",
        "                all_objects.extend(page['Contents'])\n",
        "        \n",
        "        return all_objects\n",
        "\n",
        "    # Function to filter image files\n",
        "    def filter_image_files(objects):\n",
        "        \"\"\"Filter image files from S3 objects list\"\"\"\n",
        "        image_extensions = [\".jpg\", \".jpeg\", \".png\", \".tiff\", \".tif\"]\n",
        "        return [obj for obj in objects \n",
        "                if any(obj['Key'].lower().endswith(ext) for ext in image_extensions)]\n",
        "\n",
        "    # List raw images in the bucket\n",
        "    raw_objects = list_s3_objects(BUCKET_NAME, prefix=\"\")\n",
        "    raw_images = filter_image_files(raw_objects)\n",
        "\n",
        "    print(f\"Found {len(raw_images)} raw images in the bucket\")\n",
        "    \n",
        "    # Log dataset statistics to MLFlow\n",
        "    mlflow.log_param(\"bucket_name\", BUCKET_NAME)\n",
        "    mlflow.log_param(\"data_prefix\", \"raw-images/\")\n",
        "    mlflow.log_metric(\"total_images\", len(raw_images))\n",
        "    \n",
        "    # Display the first few image keys\n",
        "    if raw_images:\n",
        "        print(\"\\nSample image keys:\")\n",
        "        for i, img in enumerate(raw_images[:5]):\n",
        "            print(f\"  {i+1}. {img['Key']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Display Sample Images\n",
        "\n",
        "Let's display some sample images from the dataset to get a visual understanding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to download and display images\n",
        "def display_sample_images(bucket, image_objects, num_samples=4):\n",
        "    \"\"\"Download and display sample images from S3\"\"\"\n",
        "    # Limit to the requested number of samples\n",
        "    samples = image_objects[:min(num_samples, len(image_objects))]\n",
        "    \n",
        "    # Create a figure with subplots\n",
        "    fig, axes = plt.subplots(1, len(samples), figsize=(16, 4))\n",
        "    \n",
        "    # If only one sample, axes is not an array\n",
        "    if len(samples) == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    # Download and display each image\n",
        "    for i, img_obj in enumerate(samples):\n",
        "        try:\n",
        "            # Download image from S3\n",
        "            response = s3_client.get_object(Bucket=bucket, Key=img_obj['Key'])\n",
        "            img_data = response['Body'].read()\n",
        "            \n",
        "            # Open image with PIL\n",
        "            img = Image.open(io.BytesIO(img_data))\n",
        "            \n",
        "            # Display image\n",
        "            axes[i].imshow(img)\n",
        "            axes[i].set_title(os.path.basename(img_obj['Key']))\n",
        "            axes[i].axis('off')\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error displaying image {img_obj['Key']}: {str(e)}\")\n",
        "            axes[i].text(0.5, 0.5, f\"Error loading image\", ha='center')\n",
        "            axes[i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Save plot as artifact in MLFlow\n",
        "    plt.savefig('sample_images.png', dpi=150, bbox_inches='tight')\n",
        "    mlflow.log_artifact('sample_images.png')\n",
        "\n",
        "# Display sample images\n",
        "if raw_images:\n",
        "    display_sample_images(BUCKET_NAME, raw_images, num_samples=4)\n",
        "else:\n",
        "    print(\"No images found to display\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Basic Image Analysis with MLFlow Tracking\n",
        "\n",
        "Let's analyze some basic characteristics of the images in our dataset and track the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Continue with the same MLFlow run\n",
        "with mlflow.start_run(run_name=f\"image-analysis-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"):\n",
        "    # Function to analyze image characteristics\n",
        "    def analyze_images(bucket, image_objects, sample_size=20):\n",
        "        \"\"\"Analyze basic characteristics of images\"\"\"\n",
        "        # Limit to sample size\n",
        "        samples = image_objects[:min(sample_size, len(image_objects))]\n",
        "        \n",
        "        # Initialize lists to store image characteristics\n",
        "        widths = []\n",
        "        heights = []\n",
        "        aspect_ratios = []\n",
        "        file_sizes = []\n",
        "        formats = []\n",
        "        \n",
        "        print(f\"Analyzing {len(samples)} sample images...\")\n",
        "        \n",
        "        # Process each image\n",
        "        for img_obj in samples:\n",
        "            try:\n",
        "                # Download image from S3\n",
        "                response = s3_client.get_object(Bucket=bucket, Key=img_obj['Key'])\n",
        "                img_data = response['Body'].read()\n",
        "                \n",
        "                # Get file size\n",
        "                file_size = len(img_data) / (1024 * 1024)  # Convert to MB\n",
        "                file_sizes.append(file_size)\n",
        "                \n",
        "                # Open image with PIL\n",
        "                img = Image.open(io.BytesIO(img_data))\n",
        "                \n",
        "                # Get image dimensions\n",
        "                width, height = img.size\n",
        "                widths.append(width)\n",
        "                heights.append(height)\n",
        "                \n",
        "                # Calculate aspect ratio\n",
        "                aspect_ratio = width / height\n",
        "                aspect_ratios.append(aspect_ratio)\n",
        "                \n",
        "                # Get image format\n",
        "                formats.append(img.format)\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error analyzing image {img_obj['Key']}: {str(e)}\")\n",
        "        \n",
        "        # Calculate statistics\n",
        "        stats = {\n",
        "            'count': len(widths),\n",
        "            'avg_width': np.mean(widths) if widths else 0,\n",
        "            'avg_height': np.mean(heights) if heights else 0,\n",
        "            'min_width': min(widths) if widths else 0,\n",
        "            'max_width': max(widths) if widths else 0,\n",
        "            'min_height': min(heights) if heights else 0,\n",
        "            'max_height': max(heights) if heights else 0,\n",
        "            'avg_aspect_ratio': np.mean(aspect_ratios) if aspect_ratios else 0,\n",
        "            'avg_file_size': np.mean(file_sizes) if file_sizes else 0,\n",
        "            'formats': list(set(formats)) if formats else []\n",
        "        }\n",
        "        \n",
        "        return {\n",
        "            'stats': stats,\n",
        "            'widths': widths,\n",
        "            'heights': heights,\n",
        "            'aspect_ratios': aspect_ratios,\n",
        "            'file_sizes': file_sizes,\n",
        "            'formats': formats\n",
        "        }\n",
        "\n",
        "    # Analyze sample images\n",
        "    if raw_images:\n",
        "        analysis_results = analyze_images(BUCKET_NAME, raw_images, sample_size=20)\n",
        "        \n",
        "        # Display statistics\n",
        "        stats = analysis_results['stats']\n",
        "        print(\"\\nImage Statistics:\")\n",
        "        print(f\"Total images analyzed: {stats['count']}\")\n",
        "        print(f\"Average dimensions: {stats['avg_width']:.1f}x{stats['avg_height']:.1f} pixels\")\n",
        "        print(f\"Dimension range: {stats['min_width']}x{stats['min_height']} to {stats['max_width']}x{stats['max_height']} pixels\")\n",
        "        print(f\"Average aspect ratio: {stats['avg_aspect_ratio']:.2f}\")\n",
        "        print(f\"Average file size: {stats['avg_file_size']:.2f} MB\")\n",
        "        print(f\"Image formats: {', '.join(stats['formats'])}\")\n",
        "        \n",
        "        # Log statistics to MLFlow\n",
        "        mlflow.log_param(\"sample_size\", stats['count'])\n",
        "        mlflow.log_metric(\"avg_width\", stats['avg_width'])\n",
        "        mlflow.log_metric(\"avg_height\", stats['avg_height'])\n",
        "        mlflow.log_metric(\"min_width\", stats['min_width'])\n",
        "        mlflow.log_metric(\"max_width\", stats['max_width'])\n",
        "        mlflow.log_metric(\"min_height\", stats['min_height'])\n",
        "        mlflow.log_metric(\"max_height\", stats['max_height'])\n",
        "        mlflow.log_metric(\"avg_aspect_ratio\", stats['avg_aspect_ratio'])\n",
        "        mlflow.log_metric(\"avg_file_size_mb\", stats['avg_file_size'])\n",
        "        mlflow.log_param(\"image_formats\", \", \".join(stats['formats']))\n",
        "        \n",
        "    else:\n",
        "        print(\"No images found to analyze\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 Visualize Image Characteristics\n",
        "\n",
        "Let's create some visualizations to better understand our dataset and save them as MLFlow artifacts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize image characteristics\n",
        "if 'analysis_results' in locals() and analysis_results['stats']['count'] > 0:\n",
        "    # Create a figure with subplots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    \n",
        "    # Plot image dimensions\n",
        "    axes[0, 0].scatter(analysis_results['widths'], analysis_results['heights'])\n",
        "    axes[0, 0].set_xlabel('Width (pixels)')\n",
        "    axes[0, 0].set_ylabel('Height (pixels)')\n",
        "    axes[0, 0].set_title('Image Dimensions')\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot aspect ratio distribution\n",
        "    axes[0, 1].hist(analysis_results['aspect_ratios'], bins=10)\n",
        "    axes[0, 1].set_xlabel('Aspect Ratio (width/height)')\n",
        "    axes[0, 1].set_ylabel('Count')\n",
        "    axes[0, 1].set_title('Aspect Ratio Distribution')\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot file size distribution\n",
        "    axes[1, 0].hist(analysis_results['file_sizes'], bins=10)\n",
        "    axes[1, 0].set_xlabel('File Size (MB)')\n",
        "    axes[1, 0].set_ylabel('Count')\n",
        "    axes[1, 0].set_title('File Size Distribution')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot format distribution\n",
        "    format_counts = {}\n",
        "    for fmt in analysis_results['formats']:\n",
        "        if fmt in format_counts:\n",
        "            format_counts[fmt] += 1\n",
        "        else:\n",
        "            format_counts[fmt] = 1\n",
        "    \n",
        "    formats = list(format_counts.keys())\n",
        "    counts = list(format_counts.values())\n",
        "    \n",
        "    axes[1, 1].bar(formats, counts)\n",
        "    axes[1, 1].set_xlabel('Image Format')\n",
        "    axes[1, 1].set_ylabel('Count')\n",
        "    axes[1, 1].set_title('Image Format Distribution')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Save visualization as MLFlow artifact\n",
        "    plt.savefig('image_analysis.png', dpi=150, bbox_inches='tight')\n",
        "    mlflow.log_artifact('image_analysis.png')\n",
        "    \n",
        "else:\n",
        "    print(\"No analysis results available for visualization\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Preparation for YOLOv11 Training\n",
        "\n",
        "Now let's prepare our data for YOLOv11 training and track the preparation process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start new MLFlow run for data preparation\n",
        "with mlflow.start_run(run_name=f\"data-preparation-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"):\n",
        "    # Function to check if labeled data exists\n",
        "    def check_labeled_data(bucket, prefix=\"labeled-data/\"):\n",
        "        \"\"\"Check if labeled data exists in the bucket\"\"\"\n",
        "        objects = list_s3_objects(bucket, prefix=prefix)\n",
        "        \n",
        "        if objects:\n",
        "            print(f\"Found {len(objects)} objects in labeled data directory\")\n",
        "            \n",
        "            # Group by job name (assuming directory structure)\n",
        "            jobs = {}\n",
        "            for obj in objects:\n",
        "                key = obj['Key']\n",
        "                parts = key.split('/')\n",
        "                if len(parts) > 2:\n",
        "                    job_name = parts[1]\n",
        "                    if job_name not in jobs:\n",
        "                        jobs[job_name] = []\n",
        "                    jobs[job_name].append(key)\n",
        "            \n",
        "            # Display job information\n",
        "            if jobs:\n",
        "                print(f\"\\nFound {len(jobs)} labeling jobs:\")\n",
        "                for job, files in jobs.items():\n",
        "                    print(f\"  - {job}: {len(files)} files\")\n",
        "                \n",
        "                # Log to MLFlow\n",
        "                mlflow.log_metric(\"labeled_jobs_count\", len(jobs))\n",
        "                mlflow.log_metric(\"labeled_files_count\", len(objects))\n",
        "            \n",
        "            return jobs\n",
        "        else:\n",
        "            print(\"No labeled data found\")\n",
        "            mlflow.log_metric(\"labeled_jobs_count\", 0)\n",
        "            return {}\n",
        "\n",
        "    # Check for labeled data\n",
        "    labeled_jobs = check_labeled_data(BUCKET_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Prepare Data Structure for YOLOv11\n",
        "\n",
        "YOLOv11 requires a specific data structure. Let's prepare our data accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to create YOLO dataset structure\n",
        "def prepare_yolo_structure(bucket, job_name=None):\n",
        "    \"\"\"Prepare YOLO dataset structure in S3\"\"\"\n",
        "    # Define dataset structure\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    dataset_name = f\"yolov11_dataset_{timestamp}\"\n",
        "    \n",
        "    # Define directories\n",
        "    base_prefix = f\"datasets/{dataset_name}/\"\n",
        "    train_prefix = f\"{base_prefix}train/\"\n",
        "    val_prefix = f\"{base_prefix}val/\"\n",
        "    \n",
        "    # Create empty directories in S3\n",
        "    for prefix in [train_prefix, val_prefix]:\n",
        "        for subdir in [\"images/\", \"labels/\"]:\n",
        "            full_prefix = f\"{prefix}{subdir}\"\n",
        "            # Create an empty object to represent the directory\n",
        "            s3_client.put_object(Bucket=bucket, Key=full_prefix)\n",
        "    \n",
        "    print(f\"Created YOLO dataset structure at s3://{bucket}/{base_prefix}\")\n",
        "    print(\"\\nDirectory structure:\")\n",
        "    print(f\"s3://{bucket}/{base_prefix}\")\n",
        "    print(f\"├── train/\")\n",
        "    print(f\"│   ├── images/\")\n",
        "    print(f\"│   └── labels/\")\n",
        "    print(f\"└── val/\")\n",
        "    print(f\"    ├── images/\")\n",
        "    print(f\"    └── labels/\")\n",
        "    \n",
        "    # Log to MLFlow\n",
        "    mlflow.log_param(\"dataset_name\", dataset_name)\n",
        "    mlflow.log_param(\"dataset_s3_path\", f\"s3://{bucket}/{base_prefix}\")\n",
        "    \n",
        "    return {\n",
        "        'dataset_name': dataset_name,\n",
        "        'base_prefix': base_prefix,\n",
        "        'train_prefix': train_prefix,\n",
        "        'val_prefix': val_prefix\n",
        "    }\n",
        "\n",
        "# Create YOLO dataset structure\n",
        "yolo_structure = prepare_yolo_structure(BUCKET_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Ground Truth Labeling Job Creation\n",
        "\n",
        "Now let's create a SageMaker Ground Truth labeling job to annotate our drone imagery for object detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Configure Labeling Job Parameters\n",
        "\n",
        "Let's configure the parameters for our Ground Truth labeling job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start new MLFlow run for labeling job creation\n",
        "with mlflow.start_run(run_name=f\"labeling-job-creation-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"):\n",
        "    # Configure labeling job parameters\n",
        "    labeling_job_config = {\n",
        "        'job_name': f\"drone-detection-labeling-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
        "        'input_s3_path': f\"s3://{BUCKET_NAME}/raw-images/\",\n",
        "        'output_s3_path': f\"s3://{BUCKET_NAME}/labeled-data/\",\n",
        "        'task_type': 'BoundingBox',\n",
        "        'labels': ['drone', 'vehicle', 'person', 'building'],\n",
        "        'instructions': 'Please draw bounding boxes around all drones and other objects visible in the image.',\n",
        "        'max_budget_usd': 50.00,\n",
        "        'workforce_type': 'private'  # or 'public' for Mechanical Turk\n",
        "    }\n",
        "    \n",
        "    # Display configuration\n",
        "    print(\"Labeling Job Configuration:\")\n",
        "    for key, value in labeling_job_config.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "    \n",
        "    # Log configuration to MLFlow\n",
        "    for key, value in labeling_job_config.items():\n",
        "        if isinstance(value, (str, int, float)):\n",
        "            mlflow.log_param(f\"labeling_{key}\", value)\n",
        "        elif isinstance(value, list):\n",
        "            mlflow.log_param(f\"labeling_{key}\", \", \".join(value))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Create Input Manifest for Ground Truth\n",
        "\n",
        "Ground Truth requires an input manifest file that lists all images to be labeled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to create input manifest for Ground Truth\n",
        "def create_input_manifest(bucket, image_objects, output_key=\"input-manifest.json\"):\n",
        "    \"\"\"Create input manifest file for Ground Truth labeling job\"\"\"\n",
        "    \n",
        "    # Create manifest entries\n",
        "    manifest_entries = []\n",
        "    for img_obj in image_objects[:10]:  # Limit to first 10 images for demo\n",
        "        s3_uri = f\"s3://{bucket}/{img_obj['Key']}\"\n",
        "        manifest_entry = {\n",
        "            \"source-ref\": s3_uri\n",
        "        }\n",
        "        manifest_entries.append(json.dumps(manifest_entry))\n",
        "    \n",
        "    # Create manifest content\n",
        "    manifest_content = \"\\n\".join(manifest_entries)\n",
        "    \n",
        "    # Upload manifest to S3\n",
        "    s3_client.put_object(\n",
        "        Bucket=bucket,\n",
        "        Key=output_key,\n",
        "        Body=manifest_content,\n",
        "        ContentType='application/json'\n",
        "    )\n",
        "    \n",
        "    manifest_s3_uri = f\"s3://{bucket}/{output_key}\"\n",
        "    print(f\"Created input manifest: {manifest_s3_uri}\")\n",
        "    print(f\"Number of images in manifest: {len(manifest_entries)}\")\n",
        "    \n",
        "    return manifest_s3_uri\n",
        "\n",
        "# Create input manifest\n",
        "if raw_images:\n",
        "    manifest_uri = create_input_manifest(BUCKET_NAME, raw_images)\n",
        "    mlflow.log_param(\"input_manifest_uri\", manifest_uri)\n",
        "    mlflow.log_metric(\"images_to_label\", min(10, len(raw_images)))\n",
        "else:\n",
        "    print(\"No images available for labeling\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Create Ground Truth Labeling Job\n",
        "\n",
        "Now let's create the actual Ground Truth labeling job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to create Ground Truth labeling job\n",
        "def create_ground_truth_job(config, manifest_uri):\n",
        "    \"\"\"Create SageMaker Ground Truth labeling job\"\"\"\n",
        "    \n",
        "    try:\n",
        "        # Get execution role\n",
        "        role_arn = sagemaker_session.get_caller_identity_arn()\n",
        "        \n",
        "        # Create labeling job\n",
        "        response = sagemaker_client.create_labeling_job(\n",
        "            LabelingJobName=config['job_name'],\n",
        "            LabelAttributeName='drone-detection',\n",
        "            InputConfig={\n",
        "                'DataSource': {\n",
        "                    'S3DataSource': {\n",
        "                        'ManifestS3Uri': manifest_uri\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            OutputConfig={\n",
        "                'S3OutputPath': config['output_s3_path']\n",
        "            },\n",
        "            RoleArn=role_arn,\n",
        "            HumanTaskConfig={\n",
        "                'WorkteamArn': f\"arn:aws:sagemaker:{region}:{account_id}:workteam/private-crowd/default\",\n",
        "                'UiConfig': {\n",
        "                    'UiTemplateS3Uri': f\"s3://sagemaker-{region}/labeling-jobs/templates/bounding-box/template.liquid\"\n",
        "                },\n",
        "                'PreHumanTaskLambdaArn': f\"arn:aws:lambda:{region}:432418664414:function:PRE-BoundingBox\",\n",
        "                'TaskTitle': 'Drone Detection Labeling',\n",
        "                'TaskDescription': config['instructions'],\n",
        "                'NumberOfHumanWorkersPerDataObject': 1,\n",
        "                'TaskTimeLimitInSeconds': 3600,\n",
        "                'AnnotationConsolidationLambdaArn': f\"arn:aws:lambda:{region}:432418664414:function:ACS-BoundingBox\"\n",
        "            }\n",
        "        )\n",
        "        \n",
        "        job_arn = response['LabelingJobArn']\n",
        "        print(f\"✅ Created labeling job: {config['job_name']}\")\n",
        "        print(f\"Job ARN: {job_arn}\")\n",
        "        print(f\"You can monitor the job in the SageMaker console\")\n",
        "        \n",
        "        # Log to MLFlow\n",
        "        mlflow.log_param(\"labeling_job_arn\", job_arn)\n",
        "        mlflow.log_param(\"labeling_job_status\", \"created\")\n",
        "        \n",
        "        return job_arn\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error creating labeling job: {str(e)}\")\n",
        "        print(\"\\nPossible causes:\")\n",
        "        print(\"1. Insufficient permissions to create labeling jobs\")\n",
        "        print(\"2. No private workforce configured\")\n",
        "        print(\"3. Invalid S3 paths or manifest format\")\n",
        "        print(\"\\nTo set up a private workforce:\")\n",
        "        print(\"1. Go to SageMaker Console > Ground Truth > Labeling workforces\")\n",
        "        print(\"2. Create a private workforce\")\n",
        "        print(\"3. Add team members to the workforce\")\n",
        "        \n",
        "        # Log error to MLFlow\n",
        "        mlflow.log_param(\"labeling_job_error\", str(e))\n",
        "        mlflow.log_param(\"labeling_job_status\", \"failed\")\n",
        "        \n",
        "        return None\n",
        "\n",
        "# Create the labeling job\n",
        "if 'manifest_uri' in locals():\n",
        "    job_arn = create_ground_truth_job(labeling_job_config, manifest_uri)\n",
        "else:\n",
        "    print(\"No manifest available for labeling job creation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 Monitor Labeling Job Progress\n",
        "\n",
        "Let's create a function to monitor the labeling job progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to monitor labeling job\n",
        "def monitor_labeling_job(job_name):\n",
        "    \"\"\"Monitor Ground Truth labeling job progress\"\"\"\n",
        "    \n",
        "    try:\n",
        "        response = sagemaker_client.describe_labeling_job(\n",
        "            LabelingJobName=job_name\n",
        "        )\n",
        "        \n",
        "        status = response['LabelingJobStatus']\n",
        "        creation_time = response['CreationTime']\n",
        "        \n",
        "        print(f\"Job Name: {job_name}\")\n",
        "        print(f\"Status: {status}\")\n",
        "        print(f\"Created: {creation_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        \n",
        "        if 'LabelCounters' in response:\n",
        "            counters = response['LabelCounters']\n",
        "            print(f\"Total objects: {counters.get('TotalLabeled', 0) + counters.get('Unlabeled', 0)}\")\n",
        "            print(f\"Labeled: {counters.get('TotalLabeled', 0)}\")\n",
        "            print(f\"Remaining: {counters.get('Unlabeled', 0)}\")\n",
        "        \n",
        "        if status == 'Completed':\n",
        "            output_location = response['LabelingJobOutput']['OutputDatasetS3Uri']\n",
        "            print(f\"✅ Job completed! Output: {output_location}\")\n",
        "            \n",
        "            # Log completion to MLFlow\n",
        "            mlflow.log_param(\"labeling_job_output\", output_location)\n",
        "            mlflow.log_param(\"labeling_job_status\", \"completed\")\n",
        "            \n",
        "        elif status == 'Failed':\n",
        "            failure_reason = response.get('FailureReason', 'Unknown')\n",
        "            print(f\"❌ Job failed: {failure_reason}\")\n",
        "            \n",
        "            # Log failure to MLFlow\n",
        "            mlflow.log_param(\"labeling_job_failure\", failure_reason)\n",
        "            mlflow.log_param(\"labeling_job_status\", \"failed\")\n",
        "        \n",
        "        return response\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error monitoring labeling job: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Monitor the job if it was created\n",
        "if 'job_arn' in locals() and job_arn:\n",
        "    job_status = monitor_labeling_job(labeling_job_config['job_name'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. View MLFlow Experiments\n",
        "\n",
        "Let's view our MLFlow experiments and runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to list MLFlow experiments\n",
        "def list_mlflow_experiments():\n",
        "    \"\"\"List all MLFlow experiments\"\"\"\n",
        "    experiments = mlflow.search_experiments()\n",
        "    \n",
        "    if experiments:\n",
        "        print(\"MLFlow Experiments:\")\n",
        "        for exp in experiments:\n",
        "            print(f\"  - {exp.name} (ID: {exp.experiment_id})\")\n",
        "            \n",
        "            # Get runs for this experiment\n",
        "            runs = mlflow.search_runs(experiment_ids=[exp.experiment_id])\n",
        "            print(f\"    Runs: {len(runs)}\")\n",
        "            \n",
        "            if len(runs) > 0:\n",
        "                print(\"    Recent runs:\")\n",
        "                for _, run in runs.head(3).iterrows():\n",
        "                    run_name = run.get('tags.mlflow.runName', 'Unnamed')\n",
        "                    status = run.get('status', 'Unknown')\n",
        "                    print(f\"      - {run_name} ({status})\")\n",
        "            print()\n",
        "    else:\n",
        "        print(\"No MLFlow experiments found\")\n",
        "\n",
        "# List experiments\n",
        "list_mlflow_experiments()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Summary and Next Steps\n",
        "\n",
        "In this notebook, we've explored the drone imagery dataset, prepared the structure for YOLOv11 training, created a Ground Truth labeling job, and tracked our work with MLFlow. Here's a summary of what we've accomplished:\n",
        "\n",
        "1. **Data Exploration with MLFlow**:\n",
        "   - Listed and displayed sample images from the S3 bucket\n",
        "   - Analyzed image characteristics (dimensions, aspect ratios, file sizes)\n",
        "   - Visualized image statistics\n",
        "   - Tracked all metrics and artifacts in MLFlow\n",
        "\n",
        "2. **Data Preparation**:\n",
        "   - Checked for existing labeled data\n",
        "   - Created YOLO dataset structure in S3\n",
        "   - Logged dataset information to MLFlow\n",
        "\n",
        "3. **Ground Truth Labeling**:\n",
        "   - Configured labeling job parameters\n",
        "   - Created input manifest for Ground Truth\n",
        "   - Set up Ground Truth labeling job for object detection\n",
        "   - Implemented job monitoring functionality\n",
        "\n",
        "4. **Experiment Tracking**:\n",
        "   - Used MLFlow to track all data exploration and labeling activities\n",
        "   - Saved visualizations as artifacts\n",
        "   - Logged parameters and metrics for reproducibility\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. **Monitor Labeling Job**: Check the progress of your Ground Truth labeling job\n",
        "2. **Complete Labeling**: Ensure all images are properly labeled\n",
        "3. **Convert Labels**: Convert Ground Truth output to YOLOv11 format\n",
        "4. **Organize Training Data**: Place labeled data in the YOLO structure we created\n",
        "5. **Proceed to Training**: Use the ML Engineer notebook for model training\n",
        "6. **Review MLFlow**: Check all experiments in the SageMaker Studio MLFlow UI\n",
        "\n",
        "### Ground Truth Integration Benefits\n",
        "\n",
        "- **Quality Control**: Professional annotation with quality checks\n",
        "- **Scalability**: Handle large datasets efficiently\n",
        "- **Cost Management**: Budget controls and cost estimation\n",
        "- **Workforce Management**: Private or public workforce options\n",
        "- **Integration**: Seamless integration with SageMaker training pipelines\n",
        "\n",
        "### MLFlow Integration Benefits\n",
        "\n",
        "- **Complete Tracking**: All data exploration and labeling activities are tracked\n",
        "- **Reproducibility**: Parameters and configurations are logged\n",
        "- **Collaboration**: Team members can view and compare experiments\n",
        "- **Artifact Management**: Visualizations and data summaries are stored\n",
        "- **Lineage**: Track data from exploration to training\n",
        "\n",
        "### Accessing Your Work\n",
        "\n",
        "- **MLFlow UI**: Go to \"Experiments and trials\" > \"MLflow\" in SageMaker Studio\n",
        "- **Ground Truth Console**: Monitor labeling jobs in the SageMaker console\n",
        "- **S3 Data**: All data and artifacts are stored in your S3 bucket\n",
        "\n",
        "For more detailed functionality, refer to the comprehensive notebooks in the `notebooks/data-labeling/` directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Transform Classification Images to YOLOv11 Format with MLFlow Tracking\n",
        "\n",
        "Let's transform the images from the classification structure (raw-images/class_name/) to YOLOv11 format with proper train/val splits and label files, while tracking everything in MLFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import yaml\n",
        "from collections import defaultdict\n",
        "\n",
        "# Start new MLFlow run for image transformation\n",
        "with mlflow.start_run(run_name=f\"image-transformation-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"):\n",
        "    \n",
        "    # Function to discover classes from raw-images structure\n",
        "    def discover_classes_from_s3(bucket, prefix=\"raw-images/\"):\n",
        "        \"\"\"Discover class names from S3 directory structure\"\"\"\n",
        "        response = s3_client.list_objects_v2(\n",
        "            Bucket=bucket,\n",
        "            Prefix=prefix,\n",
        "            Delimiter='/'\n",
        "        )\n",
        "        \n",
        "        classes = []\n",
        "        if 'CommonPrefixes' in response:\n",
        "            for obj in response['CommonPrefixes']:\n",
        "                class_prefix = obj['Prefix']\n",
        "                class_name = class_prefix.replace(prefix, '').rstrip('/')\n",
        "                if class_name:  # Skip empty class names\n",
        "                    classes.append(class_name)\n",
        "        \n",
        "        return sorted(classes)\n",
        "\n",
        "    # Function to get images for each class\n",
        "    def get_images_by_class(bucket, prefix=\"raw-images/\"):\n",
        "        \"\"\"Get all images organized by class\"\"\"\n",
        "        classes = discover_classes_from_s3(bucket, prefix)\n",
        "        images_by_class = {}\n",
        "        \n",
        "        print(f\"Found {len(classes)} classes: {classes}\")\n",
        "        \n",
        "        for class_name in classes:\n",
        "            class_prefix = f\"{prefix}{class_name}/\"\n",
        "            objects = list_s3_objects(bucket, prefix=class_prefix)\n",
        "            images = filter_image_files(objects)\n",
        "            images_by_class[class_name] = images\n",
        "            print(f\"  {class_name}: {len(images)} images\")\n",
        "        \n",
        "        return images_by_class\n",
        "\n",
        "    # Discover classes and images\n",
        "    images_by_class = get_images_by_class(BUCKET_NAME)\n",
        "    class_names = list(images_by_class.keys())\n",
        "    total_images = sum(len(images) for images in images_by_class.values())\n",
        "\n",
        "    print(f\"\\nTotal images found: {total_images}\")\n",
        "    print(f\"Classes: {class_names}\")\n",
        "    \n",
        "    # Log class discovery to MLFlow\n",
        "    mlflow.log_param(\"num_classes\", len(class_names))\n",
        "    mlflow.log_param(\"class_names\", \", \".join(class_names))\n",
        "    mlflow.log_metric(\"total_raw_images\", total_images)\n",
        "    \n",
        "    # Log per-class image counts\n",
        "    for class_name, images in images_by_class.items():\n",
        "        mlflow.log_metric(f\"images_{class_name}\", len(images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Continue with the same MLFlow run for transformation\n",
        "with mlflow.start_run(run_name=f\"yolo-transformation-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"):\n",
        "    \n",
        "    # Function to create YOLO label file content\n",
        "    def create_yolo_label(class_id, image_width, image_height, \n",
        "                         bbox_x=None, bbox_y=None, bbox_w=None, bbox_h=None):\n",
        "        \"\"\"Create YOLO format label content\n",
        "        \n",
        "        For classification images, we'll create a bounding box that covers the entire image\n",
        "        since we don't have specific object locations.\n",
        "        \n",
        "        Args:\n",
        "            class_id: Class ID (0-based)\n",
        "            image_width: Image width in pixels\n",
        "            image_height: Image height in pixels\n",
        "            bbox_x, bbox_y, bbox_w, bbox_h: Optional specific bounding box coordinates\n",
        "        \n",
        "        Returns:\n",
        "            YOLO format label string\n",
        "        \"\"\"\n",
        "        if bbox_x is None or bbox_y is None or bbox_w is None or bbox_h is None:\n",
        "            # Create a bounding box covering most of the image (80% centered)\n",
        "            # This assumes the object of interest is roughly centered in the image\n",
        "            x_center = 0.5  # Center of image (normalized)\n",
        "            y_center = 0.5  # Center of image (normalized)\n",
        "            width = 0.8     # 80% of image width (normalized)\n",
        "            height = 0.8    # 80% of image height (normalized)\n",
        "        else:\n",
        "            # Normalize the provided bounding box coordinates\n",
        "            x_center = (bbox_x + bbox_w/2) / image_width\n",
        "            y_center = (bbox_y + bbox_h/2) / image_height\n",
        "            width = bbox_w / image_width\n",
        "            height = bbox_h / image_height\n",
        "        \n",
        "        # Ensure values are within [0, 1] range\n",
        "        x_center = max(0, min(1, x_center))\n",
        "        y_center = max(0, min(1, y_center))\n",
        "        width = max(0, min(1, width))\n",
        "        height = max(0, min(1, height))\n",
        "        \n",
        "        return f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\"\n",
        "\n",
        "    # Function to split data into train/val sets\n",
        "    def split_train_val(images_by_class, train_ratio=0.8, random_seed=42):\n",
        "        \"\"\"Split images into train and validation sets\"\"\"\n",
        "        random.seed(random_seed)\n",
        "        \n",
        "        train_data = {}\n",
        "        val_data = {}\n",
        "        \n",
        "        for class_name, images in images_by_class.items():\n",
        "            # Shuffle images\n",
        "            shuffled_images = images.copy()\n",
        "            random.shuffle(shuffled_images)\n",
        "            \n",
        "            # Split into train/val\n",
        "            split_idx = int(len(shuffled_images) * train_ratio)\n",
        "            train_data[class_name] = shuffled_images[:split_idx]\n",
        "            val_data[class_name] = shuffled_images[split_idx:]\n",
        "            \n",
        "            print(f\"{class_name}: {len(train_data[class_name])} train, {len(val_data[class_name])} val\")\n",
        "        \n",
        "        return train_data, val_data\n",
        "\n",
        "    # Split data into train/val\n",
        "    if images_by_class:\n",
        "        train_data, val_data = split_train_val(images_by_class)\n",
        "        \n",
        "        total_train = sum(len(images) for images in train_data.values())\n",
        "        total_val = sum(len(images) for images in val_data.values())\n",
        "        \n",
        "        print(f\"\\nTotal train images: {total_train}\")\n",
        "        print(f\"Total validation images: {total_val}\")\n",
        "        \n",
        "        # Log split information to MLFlow\n",
        "        mlflow.log_param(\"train_ratio\", 0.8)\n",
        "        mlflow.log_param(\"random_seed\", 42)\n",
        "        mlflow.log_metric(\"train_images_total\", total_train)\n",
        "        mlflow.log_metric(\"val_images_total\", total_val)\n",
        "        \n",
        "        # Log per-class split information\n",
        "        for class_name in class_names:\n",
        "            mlflow.log_metric(f\"train_images_{class_name}\", len(train_data[class_name]))\n",
        "            mlflow.log_metric(f\"val_images_{class_name}\", len(val_data[class_name]))\n",
        "        \n",
        "    else:\n",
        "        print(\"No images found to split\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Continue transformation with MLFlow tracking\n",
        "with mlflow.start_run(run_name=f\"yolo-dataset-creation-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"):\n",
        "    \n",
        "    # Function to transform and upload images to YOLO format\n",
        "    def transform_to_yolo_format(bucket, train_data, val_data, class_names, \n",
        "                               dataset_name, progress_callback=None):\n",
        "        \"\"\"Transform classification images to YOLO format and upload to S3\"\"\"\n",
        "        \n",
        "        # Create class ID mapping\n",
        "        class_to_id = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
        "        \n",
        "        # Define S3 prefixes\n",
        "        base_prefix = f\"datasets/{dataset_name}/\"\n",
        "        train_images_prefix = f\"{base_prefix}train/images/\"\n",
        "        train_labels_prefix = f\"{base_prefix}train/labels/\"\n",
        "        val_images_prefix = f\"{base_prefix}val/images/\"\n",
        "        val_labels_prefix = f\"{base_prefix}val/labels/\"\n",
        "        \n",
        "        def process_split(data, images_prefix, labels_prefix, split_name):\n",
        "            \"\"\"Process a data split (train or val)\"\"\"\n",
        "            processed_count = 0\n",
        "            total_count = sum(len(images) for images in data.values())\n",
        "            \n",
        "            print(f\"\\nProcessing {split_name} split ({total_count} images)...\")\n",
        "            \n",
        "            for class_name, images in data.items():\n",
        "                class_id = class_to_id[class_name]\n",
        "                \n",
        "                for img_obj in images:\n",
        "                    try:\n",
        "                        # Get original image key and filename\n",
        "                        original_key = img_obj['Key']\n",
        "                        filename = os.path.basename(original_key)\n",
        "                        name_without_ext = os.path.splitext(filename)[0]\n",
        "                        \n",
        "                        # Download image to get dimensions\n",
        "                        response = s3_client.get_object(Bucket=bucket, Key=original_key)\n",
        "                        img_data = response['Body'].read()\n",
        "                        img = Image.open(io.BytesIO(img_data))\n",
        "                        width, height = img.size\n",
        "                        \n",
        "                        # Copy image to new location\n",
        "                        new_image_key = f\"{images_prefix}{filename}\"\n",
        "                        s3_client.copy_object(\n",
        "                            Bucket=bucket,\n",
        "                            CopySource={'Bucket': bucket, 'Key': original_key},\n",
        "                            Key=new_image_key\n",
        "                        )\n",
        "                        \n",
        "                        # Create YOLO label\n",
        "                        label_content = create_yolo_label(class_id, width, height)\n",
        "                        \n",
        "                        # Upload label file\n",
        "                        label_key = f\"{labels_prefix}{name_without_ext}.txt\"\n",
        "                        s3_client.put_object(\n",
        "                            Bucket=bucket,\n",
        "                            Key=label_key,\n",
        "                            Body=label_content.encode('utf-8')\n",
        "                        )\n",
        "                        \n",
        "                        processed_count += 1\n",
        "                        \n",
        "                        # Progress callback\n",
        "                        if progress_callback and processed_count % 10 == 0:\n",
        "                            progress_callback(processed_count, total_count, split_name)\n",
        "                            \n",
        "                    except Exception as e:\n",
        "                        print(f\"Error processing {original_key}: {str(e)}\")\n",
        "            \n",
        "            print(f\"Completed {split_name} split: {processed_count}/{total_count} images processed\")\n",
        "            return processed_count\n",
        "        \n",
        "        # Progress callback function\n",
        "        def show_progress(current, total, split_name):\n",
        "            percentage = (current / total) * 100\n",
        "            print(f\"  {split_name}: {current}/{total} ({percentage:.1f}%) processed\")\n",
        "        \n",
        "        # Process train and validation splits\n",
        "        train_processed = process_split(train_data, train_images_prefix, train_labels_prefix, \"Train\")\n",
        "        val_processed = process_split(val_data, val_images_prefix, val_labels_prefix, \"Validation\")\n",
        "        \n",
        "        return {\n",
        "            'train_processed': train_processed,\n",
        "            'val_processed': val_processed,\n",
        "            'class_to_id': class_to_id,\n",
        "            'base_prefix': base_prefix\n",
        "        }\n",
        "\n",
        "    # Transform images to YOLO format\n",
        "    if 'train_data' in locals() and 'val_data' in locals() and class_names:\n",
        "        print(\"Starting transformation to YOLO format...\")\n",
        "        \n",
        "        # Create a new dataset with timestamp\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        dataset_name = f\"yolov11_dataset_{timestamp}\"\n",
        "        \n",
        "        # Log dataset creation to MLFlow\n",
        "        mlflow.log_param(\"dataset_name\", dataset_name)\n",
        "        mlflow.log_param(\"transformation_timestamp\", timestamp)\n",
        "        mlflow.log_param(\"bbox_strategy\", \"80% centered\")\n",
        "        \n",
        "        transformation_result = transform_to_yolo_format(\n",
        "            BUCKET_NAME, train_data, val_data, class_names, dataset_name\n",
        "        )\n",
        "        \n",
        "        print(f\"\\nTransformation completed!\")\n",
        "        print(f\"Dataset created at: s3://{BUCKET_NAME}/datasets/{dataset_name}/\")\n",
        "        print(f\"Train images processed: {transformation_result['train_processed']}\")\n",
        "        print(f\"Validation images processed: {transformation_result['val_processed']}\")\n",
        "        \n",
        "        # Log transformation results to MLFlow\n",
        "        mlflow.log_param(\"dataset_s3_path\", f\"s3://{BUCKET_NAME}/datasets/{dataset_name}/\")\n",
        "        mlflow.log_metric(\"train_processed\", transformation_result['train_processed'])\n",
        "        mlflow.log_metric(\"val_processed\", transformation_result['val_processed'])\n",
        "        mlflow.log_metric(\"total_processed\", transformation_result['train_processed'] + transformation_result['val_processed'])\n",
        "        \n",
        "        # Log class mapping\n",
        "        for class_name, class_id in transformation_result['class_to_id'].items():\n",
        "            mlflow.log_param(f\"class_id_{class_name}\", class_id)\n",
        "        \n",
        "    else:\n",
        "        print(\"No data available for transformation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Continue with data.yaml creation and verification\n",
        "with mlflow.start_run(run_name=f\"dataset-finalization-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"):\n",
        "    \n",
        "    # Function to create data.yaml configuration file\n",
        "    def create_data_yaml(bucket, dataset_name, class_names, class_to_id):\n",
        "        \"\"\"Create YOLO data.yaml configuration file\"\"\"\n",
        "        \n",
        "        # Create the YAML configuration\n",
        "        data_config = {\n",
        "            'path': f's3://{bucket}/datasets/{dataset_name}',\n",
        "            'train': 'train/images',\n",
        "            'val': 'val/images',\n",
        "            'nc': len(class_names),\n",
        "            'names': {class_to_id[name]: name for name in class_names}\n",
        "        }\n",
        "        \n",
        "        # Convert to YAML string\n",
        "        yaml_content = yaml.dump(data_config, default_flow_style=False, sort_keys=False)\n",
        "        \n",
        "        # Upload to S3\n",
        "        yaml_key = f\"datasets/{dataset_name}/data.yaml\"\n",
        "        s3_client.put_object(\n",
        "            Bucket=bucket,\n",
        "            Key=yaml_key,\n",
        "            Body=yaml_content.encode('utf-8')\n",
        "        )\n",
        "        \n",
        "        print(f\"Created data.yaml at: s3://{bucket}/{yaml_key}\")\n",
        "        print(\"\\nYAML content:\")\n",
        "        print(yaml_content)\n",
        "        \n",
        "        return yaml_key\n",
        "\n",
        "    # Create data.yaml file\n",
        "    if 'transformation_result' in locals():\n",
        "        yaml_key = create_data_yaml(\n",
        "            BUCKET_NAME, \n",
        "            dataset_name, \n",
        "            class_names, \n",
        "            transformation_result['class_to_id']\n",
        "        )\n",
        "        \n",
        "        # Log YAML creation to MLFlow\n",
        "        mlflow.log_param(\"data_yaml_path\", f\"s3://{BUCKET_NAME}/{yaml_key}\")\n",
        "        mlflow.log_artifact_from_s3(f\"s3://{BUCKET_NAME}/{yaml_key}\", \"data.yaml\")\n",
        "        \n",
        "    else:\n",
        "        print(\"No transformation result available to create data.yaml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final dataset summary with MLFlow logging\n",
        "with mlflow.start_run(run_name=f\"dataset-summary-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"):\n",
        "    \n",
        "    # Display dataset summary\n",
        "    if 'dataset_name' in locals() and 'transformation_result' in locals():\n",
        "        print(\"🎉 Dataset Transformation Complete!\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"Dataset Name: {dataset_name}\")\n",
        "        print(f\"S3 Location: s3://{BUCKET_NAME}/datasets/{dataset_name}/\")\n",
        "        print(f\"Classes: {len(class_names)} ({', '.join(class_names)})\")\n",
        "        print(f\"Train Images: {transformation_result['train_processed']}\")\n",
        "        print(f\"Validation Images: {transformation_result['val_processed']}\")\n",
        "        print(f\"Total Images: {transformation_result['train_processed'] + transformation_result['val_processed']}\")\n",
        "        \n",
        "        print(\"\\n📁 Dataset Structure:\")\n",
        "        print(f\"s3://{BUCKET_NAME}/datasets/{dataset_name}/\")\n",
        "        print(\"├── train/\")\n",
        "        print(\"│   ├── images/     # Training images\")\n",
        "        print(\"│   └── labels/     # Training labels (.txt files)\")\n",
        "        print(\"├── val/\")\n",
        "        print(\"│   ├── images/     # Validation images\")\n",
        "        print(\"│   └── labels/     # Validation labels (.txt files)\")\n",
        "        print(\"└── data.yaml       # Dataset configuration\")\n",
        "        \n",
        "        print(\"\\n🏷️  Class Mapping:\")\n",
        "        for class_name, class_id in transformation_result['class_to_id'].items():\n",
        "            print(f\"  {class_id}: {class_name}\")\n",
        "        \n",
        "        print(\"\\n📝 Label Format:\")\n",
        "        print(\"Each .txt file contains one line per object:\")\n",
        "        print(\"<class_id> <x_center> <y_center> <width> <height>\")\n",
        "        print(\"All coordinates are normalized (0.0 to 1.0)\")\n",
        "        \n",
        "        print(\"\\n🚀 Next Steps:\")\n",
        "        print(\"1. Use this dataset in the ML Engineer notebook for training\")\n",
        "        print(\"2. The dataset is ready for YOLOv11 training\")\n",
        "        print(f\"3. Reference the dataset using: s3://{BUCKET_NAME}/datasets/{dataset_name}/data.yaml\")\n",
        "        \n",
        "        # Save dataset info for later use\n",
        "        dataset_info = {\n",
        "            'dataset_name': dataset_name,\n",
        "            'bucket': BUCKET_NAME,\n",
        "            'base_path': f\"s3://{BUCKET_NAME}/datasets/{dataset_name}/\",\n",
        "            'config_path': f\"s3://{BUCKET_NAME}/datasets/{dataset_name}/data.yaml\",\n",
        "            'classes': class_names,\n",
        "            'class_to_id': transformation_result['class_to_id'],\n",
        "            'train_count': transformation_result['train_processed'],\n",
        "            'val_count': transformation_result['val_processed'],\n",
        "            'created_at': datetime.now().isoformat(),\n",
        "            'transformation_method': 'classification_to_yolo',\n",
        "            'bbox_strategy': '80% centered',\n",
        "            'mlflow_experiment': experiment_name\n",
        "        }\n",
        "        \n",
        "        # Save dataset info to S3 for reference\n",
        "        info_key = f\"datasets/{dataset_name}/dataset_info.json\"\n",
        "        s3_client.put_object(\n",
        "            Bucket=BUCKET_NAME,\n",
        "            Key=info_key,\n",
        "            Body=json.dumps(dataset_info, indent=2).encode('utf-8')\n",
        "        )\n",
        "        \n",
        "        print(f\"\\n💾 Dataset info saved to: s3://{BUCKET_NAME}/{info_key}\")\n",
        "        \n",
        "        # Log final summary to MLFlow\n",
        "        mlflow.log_param(\"final_dataset_name\", dataset_name)\n",
        "        mlflow.log_param(\"final_dataset_path\", f\"s3://{BUCKET_NAME}/datasets/{dataset_name}/\")\n",
        "        mlflow.log_param(\"dataset_info_path\", f\"s3://{BUCKET_NAME}/{info_key}\")\n",
        "        mlflow.log_metric(\"final_train_count\", transformation_result['train_processed'])\n",
        "        mlflow.log_metric(\"final_val_count\", transformation_result['val_processed'])\n",
        "        mlflow.log_metric(\"final_total_count\", transformation_result['train_processed'] + transformation_result['val_processed'])\n",
        "        \n",
        "        # Log dataset info as artifact\n",
        "        with open('dataset_info.json', 'w') as f:\n",
        "            json.dump(dataset_info, f, indent=2)\n",
        "        mlflow.log_artifact('dataset_info.json')\n",
        "        \n",
        "        # Set tags for easy filtering\n",
        "        mlflow.set_tag(\"stage\", \"dataset_creation\")\n",
        "        mlflow.set_tag(\"dataset_ready\", \"true\")\n",
        "        mlflow.set_tag(\"dataset_name\", dataset_name)\n",
        "        mlflow.set_tag(\"transformation_type\", \"classification_to_yolo\")\n",
        "        \n",
        "    else:\n",
        "        print(\"No dataset transformation was completed.\")\n",
        "        print(\"Please run the transformation cells above first.\")\n",
        "        \n",
        "        # Log failure\n",
        "        mlflow.log_param(\"transformation_status\", \"failed\")\n",
        "        mlflow.set_tag(\"dataset_ready\", \"false\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Updated Summary and Next Steps\n",
        "\n",
        "In this enhanced notebook, we've explored the drone imagery dataset, transformed it for YOLOv11 training, created Ground Truth labeling jobs, and tracked everything with MLFlow. Here's a comprehensive summary of what we've accomplished:\n",
        "\n",
        "### Completed Tasks:\n",
        "\n",
        "1. **Data Exploration with MLFlow**:\n",
        "   - Listed and displayed sample images from the S3 bucket\n",
        "   - Analyzed image characteristics (dimensions, aspect ratios, file sizes)\n",
        "   - Visualized image statistics\n",
        "   - Tracked all metrics and artifacts in MLFlow\n",
        "\n",
        "2. **Data Preparation**:\n",
        "   - Checked for existing labeled data\n",
        "   - Created YOLO dataset structure in S3\n",
        "   - Logged dataset information to MLFlow\n",
        "\n",
        "3. **Image Transformation** (NEW):\n",
        "   - Discovered classes from raw-images/ directory structure\n",
        "   - Split images into train/validation sets (80/20 split)\n",
        "   - Created YOLO format labels for each image\n",
        "   - Organized data in proper YOLOv11 structure\n",
        "   - Generated data.yaml configuration file\n",
        "   - Tracked entire transformation process in MLFlow\n",
        "\n",
        "4. **Ground Truth Labeling**:\n",
        "   - Configured labeling job parameters\n",
        "   - Created input manifest for Ground Truth\n",
        "   - Set up Ground Truth labeling job for object detection\n",
        "   - Implemented job monitoring functionality\n",
        "\n",
        "5. **Comprehensive MLFlow Tracking**:\n",
        "   - Used MLFlow to track all data exploration and labeling activities\n",
        "   - Saved visualizations as artifacts\n",
        "   - Logged parameters and metrics for reproducibility\n",
        "   - Tracked transformation process with detailed metrics\n",
        "   - Created experiment lineage from exploration to dataset creation\n",
        "\n",
        "### Key Features of the Enhanced Transformation:\n",
        "\n",
        "- **Complete MLFlow Integration**: Every step is tracked with parameters, metrics, and artifacts\n",
        "- **Automatic Class Discovery**: Discovers classes from S3 directory structure\n",
        "- **Smart Label Generation**: Creates bounding boxes covering 80% of each image (centered)\n",
        "- **Train/Val Split Tracking**: Logs split ratios and per-class distributions\n",
        "- **YOLO Format Compliance**: Generates proper YOLO format labels with normalized coordinates\n",
        "- **Dataset Verification**: Validates the created dataset structure\n",
        "- **Configuration Management**: Creates data.yaml and dataset_info.json with full metadata\n",
        "- **Artifact Management**: Saves all configuration files and summaries as MLFlow artifacts\n",
        "- **Experiment Tagging**: Uses tags for easy filtering and organization\n",
        "\n",
        "### MLFlow Experiment Organization:\n",
        "\n",
        "The notebook creates multiple MLFlow runs for different stages:\n",
        "- **Data Exploration**: Image analysis and statistics\n",
        "- **Image Analysis**: Detailed image characteristics\n",
        "- **Data Preparation**: Dataset structure preparation\n",
        "- **Labeling Job Creation**: Ground Truth job configuration\n",
        "- **Image Transformation**: Classification to YOLO conversion\n",
        "- **Dataset Creation**: YOLO dataset assembly\n",
        "- **Dataset Finalization**: Configuration file creation\n",
        "- **Dataset Summary**: Final validation and metadata\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. **Use the transformed dataset** in the ML Engineer notebook for YOLOv11 training\n",
        "2. **Monitor Ground Truth labeling jobs** if created\n",
        "3. **Review MLFlow experiments** in the SageMaker Studio MLFlow UI\n",
        "4. **Fine-tune the bounding boxes** if needed (currently uses 80% centered boxes)\n",
        "5. **Adjust train/val split ratio** if different proportions are needed\n",
        "6. **Proceed to model training** using the generated dataset\n",
        "\n",
        "### Dataset Ready for Training!\n",
        "\n",
        "Your dataset is now in the proper YOLOv11 format and ready for training. The ML Engineer can use the dataset path provided in the transformation summary to train YOLOv11 models.\n",
        "\n",
        "### Accessing Your Work\n",
        "\n",
        "- **MLFlow UI**: Go to \"Experiments and trials\" > \"MLflow\" in SageMaker Studio\n",
        "- **Ground Truth Console**: Monitor labeling jobs in the SageMaker console\n",
        "- **S3 Data**: All data and artifacts are stored in your S3 bucket\n",
        "- **Dataset Info**: Complete metadata available in dataset_info.json\n",
        "\n",
        "### Benefits Summary\n",
        "\n",
        "**Ground Truth Integration**:\n",
        "- Quality control with professional annotation\n",
        "- Scalable handling of large datasets\n",
        "- Cost management with budget controls\n",
        "- Flexible workforce options (private/public)\n",
        "- Seamless SageMaker integration\n",
        "\n",
        "**MLFlow Integration**:\n",
        "- Complete activity tracking and lineage\n",
        "- Full reproducibility with logged parameters\n",
        "- Team collaboration through shared experiments\n",
        "- Comprehensive artifact management\n",
        "- Organized experiment structure with tagging\n",
        "- Easy filtering and searching capabilities\n",
        "\n",
        "**Image Transformation**:\n",
        "- Automatic conversion from classification to object detection format\n",
        "- Proper YOLO format compliance\n",
        "- Intelligent bounding box generation\n",
        "- Complete dataset validation\n",
        "- Ready-to-use training configuration\n",
        "\n",
        "For more detailed functionality, refer to the comprehensive notebooks in the `notebooks/data-labeling/` directory."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
