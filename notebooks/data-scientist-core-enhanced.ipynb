{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Scientist Core Workflow with MLFlow\n",
        "\n",
        "This notebook provides essential functionality for Data Scientists to explore and prepare drone imagery data for YOLOv11 model training, with MLFlow experiment tracking integration.\n",
        "\n",
        "## Workflow Overview\n",
        "\n",
        "1. **Data Exploration**: Analyze and visualize the drone imagery dataset\n",
        "2. **Data Preparation**: Prepare data for YOLOv11 training\n",
        "3. **Ground Truth Labeling**: Create labeling jobs for annotation\n",
        "4. **Experiment Tracking**: Track data exploration experiments with MLFlow\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- AWS account with appropriate permissions\n",
        "- AWS CLI configured with \"ab\" profile\n",
        "- SageMaker Studio access with Data Scientist role\n",
        "- Access to the drone imagery dataset in S3 bucket: `lucaskle-ab3-project-pv`\n",
        "- SageMaker managed MLFlow tracking server\n",
        "\n",
        "Let's start by importing the necessary libraries and setting up our environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import boto3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from IPython.display import display, HTML\n",
        "import io\n",
        "import json\n",
        "from PIL import Image\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import sagemaker\n",
        "\n",
        "# Set up AWS session with \"ab\" profile\n",
        "session = boto3.Session(profile_name='ab')\n",
        "s3_client = session.client('s3')\n",
        "sagemaker_client = session.client('sagemaker')\n",
        "sagemaker_session = sagemaker.Session(boto_session=session)\n",
        "region = session.region_name\n",
        "account_id = session.client('sts').get_caller_identity()['Account']\n",
        "\n",
        "# Set up MLFlow tracking\n",
        "# Get SageMaker managed MLFlow tracking server URI\n",
        "mlflow_tracking_uri = sagemaker_session.get_caller_identity_arn().replace('arn:aws:sts::', 'https://').replace(':assumed-role', '.mlflow')\n",
        "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
        "\n",
        "# Set up visualization\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
        "\n",
        "# Define bucket name\n",
        "BUCKET_NAME = 'lucaskle-ab3-project-pv'\n",
        "\n",
        "print(f\"Data Bucket: {BUCKET_NAME}\")\n",
        "print(f\"Region: {region}\")\n",
        "print(f\"Account ID: {account_id}\")\n",
        "print(f\"MLFlow Tracking URI: {mlflow_tracking_uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Exploration with MLFlow Tracking\n",
        "\n",
        "Let's start by exploring the drone imagery dataset stored in S3 and track our exploration with MLFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start MLFlow experiment for data exploration\n",
        "experiment_name = \"drone-imagery-data-exploration\"\n",
        "mlflow.set_experiment(experiment_name)\n",
        "\n",
        "# Start MLFlow run\n",
        "with mlflow.start_run(run_name=f\"data-exploration-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"):\n",
        "    # Function to list objects in S3 bucket\n",
        "    def list_s3_objects(bucket, prefix=\"\", max_items=100):\n",
        "        \"\"\"List objects in an S3 bucket with the given prefix\"\"\"\n",
        "        response = s3_client.list_objects_v2(\n",
        "            Bucket=bucket,\n",
        "            Prefix=prefix,\n",
        "            MaxKeys=max_items\n",
        "        )\n",
        "        \n",
        "        if 'Contents' in response:\n",
        "            return response['Contents']\n",
        "        else:\n",
        "            return []\n",
        "\n",
        "    # Function to filter image files\n",
        "    def filter_image_files(objects):\n",
        "        \"\"\"Filter image files from S3 objects list\"\"\"\n",
        "        image_extensions = [\".jpg\", \".jpeg\", \".png\", \".tiff\", \".tif\"]\n",
        "        return [obj for obj in objects \n",
        "                if any(obj['Key'].lower().endswith(ext) for ext in image_extensions)]\n",
        "\n",
        "    # List raw images in the bucket\n",
        "    raw_objects = list_s3_objects(BUCKET_NAME, prefix=\"raw-images/\")\n",
        "    raw_images = filter_image_files(raw_objects)\n",
        "\n",
        "    print(f\"Found {len(raw_images)} raw images in the bucket\")\n",
        "    \n",
        "    # Log dataset statistics to MLFlow\n",
        "    mlflow.log_param(\"bucket_name\", BUCKET_NAME)\n",
        "    mlflow.log_param(\"data_prefix\", \"raw-images/\")\n",
        "    mlflow.log_metric(\"total_images\", len(raw_images))\n",
        "    \n",
        "    # Display the first few image keys\n",
        "    if raw_images:\n",
        "        print(\"\\nSample image keys:\")\n",
        "        for i, img in enumerate(raw_images[:5]):\n",
        "            print(f\"  {i+1}. {img['Key']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Display Sample Images\n",
        "\n",
        "Let's display some sample images from the dataset to get a visual understanding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to download and display images\n",
        "def display_sample_images(bucket, image_objects, num_samples=4):\n",
        "    \"\"\"Download and display sample images from S3\"\"\"\n",
        "    # Limit to the requested number of samples\n",
        "    samples = image_objects[:min(num_samples, len(image_objects))]\n",
        "    \n",
        "    # Create a figure with subplots\n",
        "    fig, axes = plt.subplots(1, len(samples), figsize=(16, 4))\n",
        "    \n",
        "    # If only one sample, axes is not an array\n",
        "    if len(samples) == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    # Download and display each image\n",
        "    for i, img_obj in enumerate(samples):\n",
        "        try:\n",
        "            # Download image from S3\n",
        "            response = s3_client.get_object(Bucket=bucket, Key=img_obj['Key'])\n",
        "            img_data = response['Body'].read()\n",
        "            \n",
        "            # Open image with PIL\n",
        "            img = Image.open(io.BytesIO(img_data))\n",
        "            \n",
        "            # Display image\n",
        "            axes[i].imshow(img)\n",
        "            axes[i].set_title(os.path.basename(img_obj['Key']))\n",
        "            axes[i].axis('off')\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error displaying image {img_obj['Key']}: {str(e)}\")\n",
        "            axes[i].text(0.5, 0.5, f\"Error loading image\", ha='center')\n",
        "            axes[i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Save plot as artifact in MLFlow\n",
        "    plt.savefig('sample_images.png', dpi=150, bbox_inches='tight')\n",
        "    mlflow.log_artifact('sample_images.png')\n",
        "\n",
        "# Display sample images\n",
        "if raw_images:\n",
        "    display_sample_images(BUCKET_NAME, raw_images, num_samples=4)\n",
        "else:\n",
        "    print(\"No images found to display\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Basic Image Analysis with MLFlow Tracking\n",
        "\n",
        "Let's analyze some basic characteristics of the images in our dataset and track the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Continue with the same MLFlow run\n",
        "with mlflow.start_run(run_name=f\"image-analysis-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"):\n",
        "    # Function to analyze image characteristics\n",
        "    def analyze_images(bucket, image_objects, sample_size=20):\n",
        "        \"\"\"Analyze basic characteristics of images\"\"\"\n",
        "        # Limit to sample size\n",
        "        samples = image_objects[:min(sample_size, len(image_objects))]\n",
        "        \n",
        "        # Initialize lists to store image characteristics\n",
        "        widths = []\n",
        "        heights = []\n",
        "        aspect_ratios = []\n",
        "        file_sizes = []\n",
        "        formats = []\n",
        "        \n",
        "        print(f\"Analyzing {len(samples)} sample images...\")\n",
        "        \n",
        "        # Process each image\n",
        "        for img_obj in samples:\n",
        "            try:\n",
        "                # Download image from S3\n",
        "                response = s3_client.get_object(Bucket=bucket, Key=img_obj['Key'])\n",
        "                img_data = response['Body'].read()\n",
        "                \n",
        "                # Get file size\n",
        "                file_size = len(img_data) / (1024 * 1024)  # Convert to MB\n",
        "                file_sizes.append(file_size)\n",
        "                \n",
        "                # Open image with PIL\n",
        "                img = Image.open(io.BytesIO(img_data))\n",
        "                \n",
        "                # Get image dimensions\n",
        "                width, height = img.size\n",
        "                widths.append(width)\n",
        "                heights.append(height)\n",
        "                \n",
        "                # Calculate aspect ratio\n",
        "                aspect_ratio = width / height\n",
        "                aspect_ratios.append(aspect_ratio)\n",
        "                \n",
        "                # Get image format\n",
        "                formats.append(img.format)\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error analyzing image {img_obj['Key']}: {str(e)}\")\n",
        "        \n",
        "        # Calculate statistics\n",
        "        stats = {\n",
        "            'count': len(widths),\n",
        "            'avg_width': np.mean(widths) if widths else 0,\n",
        "            'avg_height': np.mean(heights) if heights else 0,\n",
        "            'min_width': min(widths) if widths else 0,\n",
        "            'max_width': max(widths) if widths else 0,\n",
        "            'min_height': min(heights) if heights else 0,\n",
        "            'max_height': max(heights) if heights else 0,\n",
        "            'avg_aspect_ratio': np.mean(aspect_ratios) if aspect_ratios else 0,\n",
        "            'avg_file_size': np.mean(file_sizes) if file_sizes else 0,\n",
        "            'formats': list(set(formats)) if formats else []\n",
        "        }\n",
        "        \n",
        "        return {\n",
        "            'stats': stats,\n",
        "            'widths': widths,\n",
        "            'heights': heights,\n",
        "            'aspect_ratios': aspect_ratios,\n",
        "            'file_sizes': file_sizes,\n",
        "            'formats': formats\n",
        "        }\n",
        "\n",
        "    # Analyze sample images\n",
        "    if raw_images:\n",
        "        analysis_results = analyze_images(BUCKET_NAME, raw_images, sample_size=20)\n",
        "        \n",
        "        # Display statistics\n",
        "        stats = analysis_results['stats']\n",
        "        print(\"\\nImage Statistics:\")\n",
        "        print(f\"Total images analyzed: {stats['count']}\")\n",
        "        print(f\"Average dimensions: {stats['avg_width']:.1f}x{stats['avg_height']:.1f} pixels\")\n",
        "        print(f\"Dimension range: {stats['min_width']}x{stats['min_height']} to {stats['max_width']}x{stats['max_height']} pixels\")\n",
        "        print(f\"Average aspect ratio: {stats['avg_aspect_ratio']:.2f}\")\n",
        "        print(f\"Average file size: {stats['avg_file_size']:.2f} MB\")\n",
        "        print(f\"Image formats: {', '.join(stats['formats'])}\")\n",
        "        \n",
        "        # Log statistics to MLFlow\n",
        "        mlflow.log_param(\"sample_size\", stats['count'])\n",
        "        mlflow.log_metric(\"avg_width\", stats['avg_width'])\n",
        "        mlflow.log_metric(\"avg_height\", stats['avg_height'])\n",
        "        mlflow.log_metric(\"min_width\", stats['min_width'])\n",
        "        mlflow.log_metric(\"max_width\", stats['max_width'])\n",
        "        mlflow.log_metric(\"min_height\", stats['min_height'])\n",
        "        mlflow.log_metric(\"max_height\", stats['max_height'])\n",
        "        mlflow.log_metric(\"avg_aspect_ratio\", stats['avg_aspect_ratio'])\n",
        "        mlflow.log_metric(\"avg_file_size_mb\", stats['avg_file_size'])\n",
        "        mlflow.log_param(\"image_formats\", \", \".join(stats['formats']))\n",
        "        \n",
        "    else:\n",
        "        print(\"No images found to analyze\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 Visualize Image Characteristics\n",
        "\n",
        "Let's create some visualizations to better understand our dataset and save them as MLFlow artifacts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize image characteristics\n",
        "if 'analysis_results' in locals() and analysis_results['stats']['count'] > 0:\n",
        "    # Create a figure with subplots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    \n",
        "    # Plot image dimensions\n",
        "    axes[0, 0].scatter(analysis_results['widths'], analysis_results['heights'])\n",
        "    axes[0, 0].set_xlabel('Width (pixels)')\n",
        "    axes[0, 0].set_ylabel('Height (pixels)')\n",
        "    axes[0, 0].set_title('Image Dimensions')\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot aspect ratio distribution\n",
        "    axes[0, 1].hist(analysis_results['aspect_ratios'], bins=10)\n",
        "    axes[0, 1].set_xlabel('Aspect Ratio (width/height)')\n",
        "    axes[0, 1].set_ylabel('Count')\n",
        "    axes[0, 1].set_title('Aspect Ratio Distribution')\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot file size distribution\n",
        "    axes[1, 0].hist(analysis_results['file_sizes'], bins=10)\n",
        "    axes[1, 0].set_xlabel('File Size (MB)')\n",
        "    axes[1, 0].set_ylabel('Count')\n",
        "    axes[1, 0].set_title('File Size Distribution')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot format distribution\n",
        "    format_counts = {}\n",
        "    for fmt in analysis_results['formats']:\n",
        "        if fmt in format_counts:\n",
        "            format_counts[fmt] += 1\n",
        "        else:\n",
        "            format_counts[fmt] = 1\n",
        "    \n",
        "    formats = list(format_counts.keys())\n",
        "    counts = list(format_counts.values())\n",
        "    \n",
        "    axes[1, 1].bar(formats, counts)\n",
        "    axes[1, 1].set_xlabel('Image Format')\n",
        "    axes[1, 1].set_ylabel('Count')\n",
        "    axes[1, 1].set_title('Image Format Distribution')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Save visualization as MLFlow artifact\n",
        "    plt.savefig('image_analysis.png', dpi=150, bbox_inches='tight')\n",
        "    mlflow.log_artifact('image_analysis.png')\n",
        "    \n",
        "else:\n",
        "    print(\"No analysis results available for visualization\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Preparation for YOLOv11 Training\n",
        "\n",
        "Now let's prepare our data for YOLOv11 training and track the preparation process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start new MLFlow run for data preparation\n",
        "with mlflow.start_run(run_name=f\"data-preparation-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"):\n",
        "    # Function to check if labeled data exists\n",
        "    def check_labeled_data(bucket, prefix=\"labeled-data/\"):\n",
        "        \"\"\"Check if labeled data exists in the bucket\"\"\"\n",
        "        objects = list_s3_objects(bucket, prefix=prefix)\n",
        "        \n",
        "        if objects:\n",
        "            print(f\"Found {len(objects)} objects in labeled data directory\")\n",
        "            \n",
        "            # Group by job name (assuming directory structure)\n",
        "            jobs = {}\n",
        "            for obj in objects:\n",
        "                key = obj['Key']\n",
        "                parts = key.split('/')\n",
        "                if len(parts) > 2:\n",
        "                    job_name = parts[1]\n",
        "                    if job_name not in jobs:\n",
        "                        jobs[job_name] = []\n",
        "                    jobs[job_name].append(key)\n",
        "            \n",
        "            # Display job information\n",
        "            if jobs:\n",
        "                print(f\"\\nFound {len(jobs)} labeling jobs:\")\n",
        "                for job, files in jobs.items():\n",
        "                    print(f\"  - {job}: {len(files)} files\")\n",
        "                \n",
        "                # Log to MLFlow\n",
        "                mlflow.log_metric(\"labeled_jobs_count\", len(jobs))\n",
        "                mlflow.log_metric(\"labeled_files_count\", len(objects))\n",
        "            \n",
        "            return jobs\n",
        "        else:\n",
        "            print(\"No labeled data found\")\n",
        "            mlflow.log_metric(\"labeled_jobs_count\", 0)\n",
        "            return {}\n",
        "\n",
        "    # Check for labeled data\n",
        "    labeled_jobs = check_labeled_data(BUCKET_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Prepare Data Structure for YOLOv11\n",
        "\n",
        "YOLOv11 requires a specific data structure. Let's prepare our data accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to create YOLO dataset structure\n",
        "def prepare_yolo_structure(bucket, job_name=None):\n",
        "    \"\"\"Prepare YOLO dataset structure in S3\"\"\"\n",
        "    # Define dataset structure\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    dataset_name = f\"yolov11_dataset_{timestamp}\"\n",
        "    \n",
        "    # Define directories\n",
        "    base_prefix = f\"datasets/{dataset_name}/\"\n",
        "    train_prefix = f\"{base_prefix}train/\"\n",
        "    val_prefix = f\"{base_prefix}val/\"\n",
        "    \n",
        "    # Create empty directories in S3\n",
        "    for prefix in [train_prefix, val_prefix]:\n",
        "        for subdir in [\"images/\", \"labels/\"]:\n",
        "            full_prefix = f\"{prefix}{subdir}\"\n",
        "            # Create an empty object to represent the directory\n",
        "            s3_client.put_object(Bucket=bucket, Key=full_prefix)\n",
        "    \n",
        "    print(f\"Created YOLO dataset structure at s3://{bucket}/{base_prefix}\")\n",
        "    print(\"\\nDirectory structure:\")\n",
        "    print(f\"s3://{bucket}/{base_prefix}\")\n",
        "    print(f\"├── train/\")\n",
        "    print(f\"│   ├── images/\")\n",
        "    print(f\"│   └── labels/\")\n",
        "    print(f\"└── val/\")\n",
        "    print(f\"    ├── images/\")\n",
        "    print(f\"    └── labels/\")\n",
        "    \n",
        "    # Log to MLFlow\n",
        "    mlflow.log_param(\"dataset_name\", dataset_name)\n",
        "    mlflow.log_param(\"dataset_s3_path\", f\"s3://{bucket}/{base_prefix}\")\n",
        "    \n",
        "    return {\n",
        "        'dataset_name': dataset_name,\n",
        "        'base_prefix': base_prefix,\n",
        "        'train_prefix': train_prefix,\n",
        "        'val_prefix': val_prefix\n",
        "    }\n",
        "\n",
        "# Create YOLO dataset structure\n",
        "yolo_structure = prepare_yolo_structure(BUCKET_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Ground Truth Labeling Job Creation\n",
        "\n",
        "Now let's create a SageMaker Ground Truth labeling job to annotate our drone imagery for object detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Configure Labeling Job Parameters\n",
        "\n",
        "Let's configure the parameters for our Ground Truth labeling job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start new MLFlow run for labeling job creation\n",
        "with mlflow.start_run(run_name=f\"labeling-job-creation-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"):\n",
        "    # Configure labeling job parameters\n",
        "    labeling_job_config = {\n",
        "        'job_name': f\"drone-detection-labeling-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
        "        'input_s3_path': f\"s3://{BUCKET_NAME}/raw-images/\",\n",
        "        'output_s3_path': f\"s3://{BUCKET_NAME}/labeled-data/\",\n",
        "        'task_type': 'BoundingBox',\n",
        "        'labels': ['drone', 'vehicle', 'person', 'building'],\n",
        "        'instructions': 'Please draw bounding boxes around all drones and other objects visible in the image.',\n",
        "        'max_budget_usd': 50.00,\n",
        "        'workforce_type': 'private'  # or 'public' for Mechanical Turk\n",
        "    }\n",
        "    \n",
        "    # Display configuration\n",
        "    print(\"Labeling Job Configuration:\")\n",
        "    for key, value in labeling_job_config.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "    \n",
        "    # Log configuration to MLFlow\n",
        "    for key, value in labeling_job_config.items():\n",
        "        if isinstance(value, (str, int, float)):\n",
        "            mlflow.log_param(f\"labeling_{key}\", value)\n",
        "        elif isinstance(value, list):\n",
        "            mlflow.log_param(f\"labeling_{key}\", \", \".join(value))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Create Input Manifest for Ground Truth\n",
        "\n",
        "Ground Truth requires an input manifest file that lists all images to be labeled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to create input manifest for Ground Truth\n",
        "def create_input_manifest(bucket, image_objects, output_key=\"input-manifest.json\"):\n",
        "    \"\"\"Create input manifest file for Ground Truth labeling job\"\"\"\n",
        "    \n",
        "    # Create manifest entries\n",
        "    manifest_entries = []\n",
        "    for img_obj in image_objects[:10]:  # Limit to first 10 images for demo\n",
        "        s3_uri = f\"s3://{bucket}/{img_obj['Key']}\"\n",
        "        manifest_entry = {\n",
        "            \"source-ref\": s3_uri\n",
        "        }\n",
        "        manifest_entries.append(json.dumps(manifest_entry))\n",
        "    \n",
        "    # Create manifest content\n",
        "    manifest_content = \"\\n\".join(manifest_entries)\n",
        "    \n",
        "    # Upload manifest to S3\n",
        "    s3_client.put_object(\n",
        "        Bucket=bucket,\n",
        "        Key=output_key,\n",
        "        Body=manifest_content,\n",
        "        ContentType='application/json'\n",
        "    )\n",
        "    \n",
        "    manifest_s3_uri = f\"s3://{bucket}/{output_key}\"\n",
        "    print(f\"Created input manifest: {manifest_s3_uri}\")\n",
        "    print(f\"Number of images in manifest: {len(manifest_entries)}\")\n",
        "    \n",
        "    return manifest_s3_uri\n",
        "\n",
        "# Create input manifest\n",
        "if raw_images:\n",
        "    manifest_uri = create_input_manifest(BUCKET_NAME, raw_images)\n",
        "    mlflow.log_param(\"input_manifest_uri\", manifest_uri)\n",
        "    mlflow.log_metric(\"images_to_label\", min(10, len(raw_images)))\n",
        "else:\n",
        "    print(\"No images available for labeling\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Create Ground Truth Labeling Job\n",
        "\n",
        "Now let's create the actual Ground Truth labeling job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to create Ground Truth labeling job\n",
        "def create_ground_truth_job(config, manifest_uri):\n",
        "    \"\"\"Create SageMaker Ground Truth labeling job\"\"\"\n",
        "    \n",
        "    try:\n",
        "        # Get execution role\n",
        "        role_arn = sagemaker_session.get_caller_identity_arn()\n",
        "        \n",
        "        # Create labeling job\n",
        "        response = sagemaker_client.create_labeling_job(\n",
        "            LabelingJobName=config['job_name'],\n",
        "            LabelAttributeName='drone-detection',\n",
        "            InputConfig={\n",
        "                'DataSource': {\n",
        "                    'S3DataSource': {\n",
        "                        'ManifestS3Uri': manifest_uri\n",
        "                    }\n",
        "                }\n",
        "            },\n",
        "            OutputConfig={\n",
        "                'S3OutputPath': config['output_s3_path']\n",
        "            },\n",
        "            RoleArn=role_arn,\n",
        "            HumanTaskConfig={\n",
        "                'WorkteamArn': f\"arn:aws:sagemaker:{region}:{account_id}:workteam/private-crowd/default\",\n",
        "                'UiConfig': {\n",
        "                    'UiTemplateS3Uri': f\"s3://sagemaker-{region}/labeling-jobs/templates/bounding-box/template.liquid\"\n",
        "                },\n",
        "                'PreHumanTaskLambdaArn': f\"arn:aws:lambda:{region}:432418664414:function:PRE-BoundingBox\",\n",
        "                'TaskTitle': 'Drone Detection Labeling',\n",
        "                'TaskDescription': config['instructions'],\n",
        "                'NumberOfHumanWorkersPerDataObject': 1,\n",
        "                'TaskTimeLimitInSeconds': 3600,\n",
        "                'AnnotationConsolidationLambdaArn': f\"arn:aws:lambda:{region}:432418664414:function:ACS-BoundingBox\"\n",
        "            }\n",
        "        )\n",
        "        \n",
        "        job_arn = response['LabelingJobArn']\n",
        "        print(f\"✅ Created labeling job: {config['job_name']}\")\n",
        "        print(f\"Job ARN: {job_arn}\")\n",
        "        print(f\"You can monitor the job in the SageMaker console\")\n",
        "        \n",
        "        # Log to MLFlow\n",
        "        mlflow.log_param(\"labeling_job_arn\", job_arn)\n",
        "        mlflow.log_param(\"labeling_job_status\", \"created\")\n",
        "        \n",
        "        return job_arn\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error creating labeling job: {str(e)}\")\n",
        "        print(\"\\nPossible causes:\")\n",
        "        print(\"1. Insufficient permissions to create labeling jobs\")\n",
        "        print(\"2. No private workforce configured\")\n",
        "        print(\"3. Invalid S3 paths or manifest format\")\n",
        "        print(\"\\nTo set up a private workforce:\")\n",
        "        print(\"1. Go to SageMaker Console > Ground Truth > Labeling workforces\")\n",
        "        print(\"2. Create a private workforce\")\n",
        "        print(\"3. Add team members to the workforce\")\n",
        "        \n",
        "        # Log error to MLFlow\n",
        "        mlflow.log_param(\"labeling_job_error\", str(e))\n",
        "        mlflow.log_param(\"labeling_job_status\", \"failed\")\n",
        "        \n",
        "        return None\n",
        "\n",
        "# Create the labeling job\n",
        "if 'manifest_uri' in locals():\n",
        "    job_arn = create_ground_truth_job(labeling_job_config, manifest_uri)\n",
        "else:\n",
        "    print(\"No manifest available for labeling job creation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 Monitor Labeling Job Progress\n",
        "\n",
        "Let's create a function to monitor the labeling job progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to monitor labeling job\n",
        "def monitor_labeling_job(job_name):\n",
        "    \"\"\"Monitor Ground Truth labeling job progress\"\"\"\n",
        "    \n",
        "    try:\n",
        "        response = sagemaker_client.describe_labeling_job(\n",
        "            LabelingJobName=job_name\n",
        "        )\n",
        "        \n",
        "        status = response['LabelingJobStatus']\n",
        "        creation_time = response['CreationTime']\n",
        "        \n",
        "        print(f\"Job Name: {job_name}\")\n",
        "        print(f\"Status: {status}\")\n",
        "        print(f\"Created: {creation_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        \n",
        "        if 'LabelCounters' in response:\n",
        "            counters = response['LabelCounters']\n",
        "            print(f\"Total objects: {counters.get('TotalLabeled', 0) + counters.get('Unlabeled', 0)}\")\n",
        "            print(f\"Labeled: {counters.get('TotalLabeled', 0)}\")\n",
        "            print(f\"Remaining: {counters.get('Unlabeled', 0)}\")\n",
        "        \n",
        "        if status == 'Completed':\n",
        "            output_location = response['LabelingJobOutput']['OutputDatasetS3Uri']\n",
        "            print(f\"✅ Job completed! Output: {output_location}\")\n",
        "            \n",
        "            # Log completion to MLFlow\n",
        "            mlflow.log_param(\"labeling_job_output\", output_location)\n",
        "            mlflow.log_param(\"labeling_job_status\", \"completed\")\n",
        "            \n",
        "        elif status == 'Failed':\n",
        "            failure_reason = response.get('FailureReason', 'Unknown')\n",
        "            print(f\"❌ Job failed: {failure_reason}\")\n",
        "            \n",
        "            # Log failure to MLFlow\n",
        "            mlflow.log_param(\"labeling_job_failure\", failure_reason)\n",
        "            mlflow.log_param(\"labeling_job_status\", \"failed\")\n",
        "        \n",
        "        return response\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error monitoring labeling job: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Monitor the job if it was created\n",
        "if 'job_arn' in locals() and job_arn:\n",
        "    job_status = monitor_labeling_job(labeling_job_config['job_name'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. View MLFlow Experiments\n",
        "\n",
        "Let's view our MLFlow experiments and runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to list MLFlow experiments\n",
        "def list_mlflow_experiments():\n",
        "    \"\"\"List all MLFlow experiments\"\"\"\n",
        "    experiments = mlflow.search_experiments()\n",
        "    \n",
        "    if experiments:\n",
        "        print(\"MLFlow Experiments:\")\n",
        "        for exp in experiments:\n",
        "            print(f\"  - {exp.name} (ID: {exp.experiment_id})\")\n",
        "            \n",
        "            # Get runs for this experiment\n",
        "            runs = mlflow.search_runs(experiment_ids=[exp.experiment_id])\n",
        "            print(f\"    Runs: {len(runs)}\")\n",
        "            \n",
        "            if len(runs) > 0:\n",
        "                print(\"    Recent runs:\")\n",
        "                for _, run in runs.head(3).iterrows():\n",
        "                    run_name = run.get('tags.mlflow.runName', 'Unnamed')\n",
        "                    status = run.get('status', 'Unknown')\n",
        "                    print(f\"      - {run_name} ({status})\")\n",
        "            print()\n",
        "    else:\n",
        "        print(\"No MLFlow experiments found\")\n",
        "\n",
        "# List experiments\n",
        "list_mlflow_experiments()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Summary and Next Steps\n",
        "\n",
        "In this notebook, we've explored the drone imagery dataset, prepared the structure for YOLOv11 training, created a Ground Truth labeling job, and tracked our work with MLFlow. Here's a summary of what we've accomplished:\n",
        "\n",
        "1. **Data Exploration with MLFlow**:\n",
        "   - Listed and displayed sample images from the S3 bucket\n",
        "   - Analyzed image characteristics (dimensions, aspect ratios, file sizes)\n",
        "   - Visualized image statistics\n",
        "   - Tracked all metrics and artifacts in MLFlow\n",
        "\n",
        "2. **Data Preparation**:\n",
        "   - Checked for existing labeled data\n",
        "   - Created YOLO dataset structure in S3\n",
        "   - Logged dataset information to MLFlow\n",
        "\n",
        "3. **Ground Truth Labeling**:\n",
        "   - Configured labeling job parameters\n",
        "   - Created input manifest for Ground Truth\n",
        "   - Set up Ground Truth labeling job for object detection\n",
        "   - Implemented job monitoring functionality\n",
        "\n",
        "4. **Experiment Tracking**:\n",
        "   - Used MLFlow to track all data exploration and labeling activities\n",
        "   - Saved visualizations as artifacts\n",
        "   - Logged parameters and metrics for reproducibility\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. **Monitor Labeling Job**: Check the progress of your Ground Truth labeling job\n",
        "2. **Complete Labeling**: Ensure all images are properly labeled\n",
        "3. **Convert Labels**: Convert Ground Truth output to YOLOv11 format\n",
        "4. **Organize Training Data**: Place labeled data in the YOLO structure we created\n",
        "5. **Proceed to Training**: Use the ML Engineer notebook for model training\n",
        "6. **Review MLFlow**: Check all experiments in the SageMaker Studio MLFlow UI\n",
        "\n",
        "### Ground Truth Integration Benefits\n",
        "\n",
        "- **Quality Control**: Professional annotation with quality checks\n",
        "- **Scalability**: Handle large datasets efficiently\n",
        "- **Cost Management**: Budget controls and cost estimation\n",
        "- **Workforce Management**: Private or public workforce options\n",
        "- **Integration**: Seamless integration with SageMaker training pipelines\n",
        "\n",
        "### MLFlow Integration Benefits\n",
        "\n",
        "- **Complete Tracking**: All data exploration and labeling activities are tracked\n",
        "- **Reproducibility**: Parameters and configurations are logged\n",
        "- **Collaboration**: Team members can view and compare experiments\n",
        "- **Artifact Management**: Visualizations and data summaries are stored\n",
        "- **Lineage**: Track data from exploration to training\n",
        "\n",
        "### Accessing Your Work\n",
        "\n",
        "- **MLFlow UI**: Go to \"Experiments and trials\" > \"MLflow\" in SageMaker Studio\n",
        "- **Ground Truth Console**: Monitor labeling jobs in the SageMaker console\n",
        "- **S3 Data**: All data and artifacts are stored in your S3 bucket\n",
        "\n",
        "For more detailed functionality, refer to the comprehensive notebooks in the `notebooks/data-labeling/` directory."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
