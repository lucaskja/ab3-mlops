{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ML Engineer SageMaker Pipeline for YOLOv11 Object Detection\n",
        "\n",
        "This notebook implements a comprehensive SageMaker Pipeline for YOLOv11 object detection model training, evaluation, registration, and deployment. It replaces individual training job management with complete MLOps pipeline orchestration.\n",
        "\n",
        "## Pipeline Architecture Overview\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ Data Validation ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Model Training  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Model Evaluation‚îÇ\n",
        "‚îÇ ProcessingStep  ‚îÇ    ‚îÇ TrainingStep    ‚îÇ    ‚îÇ ProcessingStep  ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                                                        ‚îÇ\n",
        "                                                        ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ Serverless      ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ Model Creation  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ Performance     ‚îÇ\n",
        "‚îÇ Endpoint Deploy ‚îÇ    ‚îÇ CreateModelStep ‚îÇ    ‚îÇ Condition Check ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                                ‚ñ≤                       ‚îÇ\n",
        "                                ‚îÇ                       ‚ñº\n",
        "                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "                       ‚îÇ Approval        ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ Model Registry  ‚îÇ\n",
        "                       ‚îÇ Condition Check ‚îÇ    ‚îÇ RegisterModel   ‚îÇ\n",
        "                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "## Key Features\n",
        "\n",
        "- **Complete Pipeline Orchestration**: End-to-end automation from data to deployment\n",
        "- **Conditional Logic**: Performance-based deployment decisions\n",
        "- **Model Registry Integration**: Centralized model management and versioning\n",
        "- **Serverless Endpoints**: Cost-effective inference with auto-scaling\n",
        "- **MLflow Integration**: Comprehensive experiment tracking and lineage\n",
        "- **Error Recovery**: Robust error handling and retry mechanisms\n",
        "- **Performance Monitoring**: Real-time pipeline execution monitoring\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- AWS account with appropriate permissions\n",
        "- AWS CLI configured with \"ab\" profile\n",
        "- SageMaker Studio access with ML Engineer role\n",
        "- Access to drone imagery dataset in S3: `lucaskle-ab3-project-pv`\n",
        "- YOLOv11 training and inference containers in ECR\n",
        "- SageMaker managed MLFlow tracking server\n",
        "\n",
        "Let's start by setting up our environment and importing the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages for SageMaker Pipelines\n",
        "!pip install --quiet sagemaker>=2.190.0 boto3>=1.28.0 pandas>=2.0.0 matplotlib>=3.7.0 \\\n",
        "    numpy>=1.24.0 PyYAML>=6.0 mlflow>=3.0.0 requests-auth-aws-sigv4>=0.7 ipywidgets>=8.0.0\n",
        "\n",
        "print(\"‚úÖ Required packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core imports\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import boto3\n",
        "import sagemaker\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta\n",
        "from IPython.display import display, HTML, Markdown\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "\n",
        "# SageMaker Pipeline imports\n",
        "from sagemaker.workflow.pipeline import Pipeline\n",
        "from sagemaker.workflow.steps import ProcessingStep, TrainingStep, CreateModelStep\n",
        "from sagemaker.workflow.step_collections import RegisterModel\n",
        "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo, ConditionEquals\n",
        "from sagemaker.workflow.condition_step import ConditionStep\n",
        "from sagemaker.workflow.functions import JsonGet\n",
        "from sagemaker.workflow.parameters import ParameterString, ParameterFloat, ParameterInteger\n",
        "from sagemaker.workflow.pipeline_context import PipelineSession\n",
        "from sagemaker.workflow.properties import PropertyFile\n",
        "\n",
        "# SageMaker components\n",
        "from sagemaker.estimator import Estimator\n",
        "from sagemaker.processing import ProcessingInput, ProcessingOutput, Processor\n",
        "from sagemaker.inputs import TrainingInput\n",
        "from sagemaker.model import Model\n",
        "from sagemaker.predictor import Predictor\n",
        "from sagemaker.serverless import ServerlessInferenceConfig\n",
        "\n",
        "# MLflow imports\n",
        "import mlflow\n",
        "import mlflow.sagemaker\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up AWS session with \"ab\" profile\n",
        "session = boto3.Session(profile_name='ab')\n",
        "sagemaker_session = sagemaker.Session(boto_session=session)\n",
        "pipeline_session = PipelineSession(boto_session=session)\n",
        "sagemaker_client = session.client('sagemaker')\n",
        "region = session.region_name\n",
        "account_id = session.client('sts').get_caller_identity()['Account']\n",
        "\n",
        "# Configuration\n",
        "BUCKET_NAME = 'lucaskle-ab3-project-pv'\n",
        "ROLE_ARN = sagemaker_session.get_caller_identity_arn()\n",
        "MODEL_PACKAGE_GROUP_NAME = \"yolov11-drone-detection-models\"\n",
        "PIPELINE_NAME = \"yolov11-training-pipeline\"\n",
        "\n",
        "# Set up MLFlow tracking with SageMaker managed server\n",
        "try:\n",
        "    tracking_server_arn = \"arn:aws:sagemaker:us-east-1:192771711075:mlflow-tracking-server/sagemaker-core-setup-mlflow-server\"\n",
        "    mlflow.set_tracking_uri(tracking_server_arn)\n",
        "    \n",
        "    # Create or set experiment\n",
        "    experiment_name = \"yolov11-pipeline-experiments\"\n",
        "    try:\n",
        "        mlflow.create_experiment(experiment_name)\n",
        "        print(f\"Created new MLflow experiment: {experiment_name}\")\n",
        "    except Exception:\n",
        "        mlflow.set_experiment(experiment_name)\n",
        "        print(f\"Using existing MLflow experiment: {experiment_name}\")\n",
        "    \n",
        "    print(f\"‚úÖ Connected to SageMaker managed MLflow server\")\n",
        "    print(f\"Tracking Server ARN: {tracking_server_arn}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Could not connect to SageMaker managed MLflow: {e}\")\n",
        "    print(\"Using basic MLflow setup as fallback\")\n",
        "    experiment_name = \"yolov11-pipeline-experiments\"\n",
        "    mlflow.set_experiment(experiment_name)\n",
        "\n",
        "# Display configuration\n",
        "print(f\"\\nüìã Configuration Summary:\")\n",
        "print(f\"   Data Bucket: {BUCKET_NAME}\")\n",
        "print(f\"   Region: {region}\")\n",
        "print(f\"   Account ID: {account_id}\")\n",
        "print(f\"   Role ARN: {ROLE_ARN}\")\n",
        "print(f\"   Model Package Group: {MODEL_PACKAGE_GROUP_NAME}\")\n",
        "print(f\"   Pipeline Name: {PIPELINE_NAME}\")\n",
        "print(f\"   MLflow Experiment: {experiment_name}\")\n",
        "\n",
        "print(\"\\n‚úÖ Environment setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset Discovery and Validation\n",
        "\n",
        "Before creating our pipeline, let's discover and validate available YOLOv11 datasets. The pipeline will use parameterized dataset paths for flexibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def discover_yolo_datasets(bucket, prefix=\"datasets/\"):\n",
        "    \"\"\"Discover available YOLOv11 datasets with comprehensive validation\"\"\"\n",
        "    s3_client = session.client('s3')\n",
        "    \n",
        "    try:\n",
        "        response = s3_client.list_objects_v2(\n",
        "            Bucket=bucket,\n",
        "            Prefix=prefix,\n",
        "            Delimiter='/'\n",
        "        )\n",
        "        \n",
        "        datasets = []\n",
        "        if 'CommonPrefixes' in response:\n",
        "            for obj in response['CommonPrefixes']:\n",
        "                dataset_prefix = obj['Prefix']\n",
        "                dataset_name = dataset_prefix.split('/')[-2]\n",
        "                \n",
        "                # Validate dataset structure\n",
        "                validation_result = validate_yolo_dataset_structure(bucket, dataset_prefix)\n",
        "                \n",
        "                datasets.append({\n",
        "                    'name': dataset_name,\n",
        "                    'prefix': dataset_prefix,\n",
        "                    'full_path': f's3://{bucket}/{dataset_prefix}',\n",
        "                    'valid': validation_result['valid'],\n",
        "                    'validation_details': validation_result\n",
        "                })\n",
        "        \n",
        "        return datasets\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error discovering datasets: {e}\")\n",
        "        return []\n",
        "\n",
        "def validate_yolo_dataset_structure(bucket, dataset_prefix):\n",
        "    \"\"\"Validate YOLOv11 dataset structure for pipeline compatibility\"\"\"\n",
        "    s3_client = session.client('s3')\n",
        "    \n",
        "    # Required structure for YOLOv11 pipeline\n",
        "    required_structure = {\n",
        "        'train/images/': False,\n",
        "        'train/labels/': False,\n",
        "        'validation/images/': False,  # Note: validation/ not val/\n",
        "        'validation/labels/': False,\n",
        "        'data.yaml': False,\n",
        "        'dataset_info.json': False\n",
        "    }\n",
        "    \n",
        "    validation_details = {\n",
        "        'valid': False,\n",
        "        'missing_components': [],\n",
        "        'found_components': [],\n",
        "        'train_image_count': 0,\n",
        "        'val_image_count': 0,\n",
        "        'train_label_count': 0,\n",
        "        'val_label_count': 0,\n",
        "        'pipeline_ready': False\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        print(f\"üîç Validating dataset: {dataset_prefix}\")\n",
        "        \n",
        "        for required_path in required_structure.keys():\n",
        "            full_path = dataset_prefix + required_path\n",
        "            \n",
        "            if required_path.endswith('/'):\n",
        "                # Check directories with pagination for large datasets\n",
        "                paginator = s3_client.get_paginator('list_objects_v2')\n",
        "                page_iterator = paginator.paginate(\n",
        "                    Bucket=bucket,\n",
        "                    Prefix=full_path,\n",
        "                    PaginationConfig={'PageSize': 1000}\n",
        "                )\n",
        "                \n",
        "                file_count = 0\n",
        "                has_files = False\n",
        "                \n",
        "                for page in page_iterator:\n",
        "                    if 'Contents' in page:\n",
        "                        has_files = True\n",
        "                        page_files = [obj for obj in page['Contents'] \n",
        "                                    if not obj['Key'].endswith('/') and \n",
        "                                       obj['Key'] != full_path]\n",
        "                        file_count += len(page_files)\n",
        "                \n",
        "                if has_files and file_count > 0:\n",
        "                    required_structure[required_path] = True\n",
        "                    validation_details['found_components'].append(required_path)\n",
        "                    \n",
        "                    # Store counts\n",
        "                    if 'train/images/' in required_path:\n",
        "                        validation_details['train_image_count'] = file_count\n",
        "                    elif 'validation/images/' in required_path:\n",
        "                        validation_details['val_image_count'] = file_count\n",
        "                    elif 'train/labels/' in required_path:\n",
        "                        validation_details['train_label_count'] = file_count\n",
        "                    elif 'validation/labels/' in required_path:\n",
        "                        validation_details['val_label_count'] = file_count\n",
        "                    \n",
        "                    print(f\"   ‚úÖ {required_path}: {file_count:,} files\")\n",
        "                else:\n",
        "                    validation_details['missing_components'].append(required_path)\n",
        "                    print(f\"   ‚ùå {required_path}: Not found or empty\")\n",
        "            else:\n",
        "                # Check individual files\n",
        "                try:\n",
        "                    s3_client.head_object(Bucket=bucket, Key=full_path)\n",
        "                    required_structure[required_path] = True\n",
        "                    validation_details['found_components'].append(required_path)\n",
        "                    print(f\"   ‚úÖ {required_path}: Found\")\n",
        "                except:\n",
        "                    validation_details['missing_components'].append(required_path)\n",
        "                    print(f\"   ‚ùå {required_path}: Not found\")\n",
        "        \n",
        "        # Dataset is valid if all required components are found\n",
        "        validation_details['valid'] = all(required_structure.values())\n",
        "        \n",
        "        # Additional pipeline readiness checks\n",
        "        if validation_details['valid']:\n",
        "            # Check for reasonable dataset sizes\n",
        "            min_images = 100  # Minimum for meaningful training\n",
        "            train_images = validation_details['train_image_count']\n",
        "            val_images = validation_details['val_image_count']\n",
        "            \n",
        "            pipeline_ready = (\n",
        "                train_images >= min_images and\n",
        "                val_images >= min_images // 4 and  # At least 25% of training size\n",
        "                validation_details['train_image_count'] == validation_details['train_label_count'] and\n",
        "                validation_details['val_image_count'] == validation_details['val_label_count']\n",
        "            )\n",
        "            \n",
        "            validation_details['pipeline_ready'] = pipeline_ready\n",
        "            \n",
        "            if pipeline_ready:\n",
        "                print(f\"   üöÄ Dataset is PIPELINE READY\")\n",
        "            else:\n",
        "                print(f\"   ‚ö†Ô∏è  Dataset valid but may have issues for pipeline training\")\n",
        "        \n",
        "        # Summary\n",
        "        total_images = validation_details['train_image_count'] + validation_details['val_image_count']\n",
        "        total_labels = validation_details['train_label_count'] + validation_details['val_label_count']\n",
        "        \n",
        "        print(f\"   üìä Summary: {total_images:,} images, {total_labels:,} labels\")\n",
        "        print(f\"   Status: {'‚úÖ VALID' if validation_details['valid'] else '‚ùå INVALID'}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error during validation: {e}\")\n",
        "    \n",
        "    return validation_details\n",
        "\n",
        "# Discover and validate datasets\n",
        "print(\"üîç Discovering YOLOv11 datasets for pipeline...\")\n",
        "available_datasets = discover_yolo_datasets(BUCKET_NAME)\n",
        "\n",
        "if available_datasets:\n",
        "    print(f\"\\nüìä Found {len(available_datasets)} datasets:\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    pipeline_ready_datasets = []\n",
        "    for i, dataset in enumerate(available_datasets):\n",
        "        status_icon = \"üöÄ\" if dataset['validation_details'].get('pipeline_ready', False) else \"‚úÖ\" if dataset['valid'] else \"‚ùå\"\n",
        "        print(f\"{i+1}. {status_icon} {dataset['name']}\")\n",
        "        print(f\"   Path: {dataset['full_path']}\")\n",
        "        \n",
        "        if dataset['valid']:\n",
        "            details = dataset['validation_details']\n",
        "            print(f\"   üìà Training: {details['train_image_count']:,} images, {details['train_label_count']:,} labels\")\n",
        "            print(f\"   üìä Validation: {details['val_image_count']:,} images, {details['val_label_count']:,} labels\")\n",
        "            \n",
        "            if details.get('pipeline_ready', False):\n",
        "                pipeline_ready_datasets.append(dataset)\n",
        "        else:\n",
        "            print(f\"   ‚ö†Ô∏è  Missing: {', '.join(details['missing_components'])}\")\n",
        "        \n",
        "        print(\"-\" * 80)\n",
        "    \n",
        "    print(f\"\\nüöÄ {len(pipeline_ready_datasets)} dataset(s) ready for pipeline execution\")\n",
        "    \n",
        "    # Store for pipeline configuration\n",
        "    global validated_datasets, pipeline_ready_datasets_global\n",
        "    validated_datasets = available_datasets\n",
        "    pipeline_ready_datasets_global = pipeline_ready_datasets\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No datasets found. Please prepare datasets using the Data Scientist notebook first.\")\n",
        "    validated_datasets = []\n",
        "    pipeline_ready_datasets_global = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Pipeline Parameters Configuration\n",
        "\n",
        "Define parameterized pipeline configuration for flexibility and reusability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive dataset selection widget\n",
        "def create_dataset_selector():\n",
        "    \"\"\"Create interactive widget for dataset selection\"\"\"\n",
        "    if not pipeline_ready_datasets_global:\n",
        "        print(\"‚ùå No pipeline-ready datasets available\")\n",
        "        return None\n",
        "    \n",
        "    dataset_options = [(f\"{ds['name']} ({ds['validation_details']['train_image_count'] + ds['validation_details']['val_image_count']:,} images)\", \n",
        "                       ds) for ds in pipeline_ready_datasets_global]\n",
        "    \n",
        "    dataset_selector = widgets.Dropdown(\n",
        "        options=dataset_options,\n",
        "        description='Dataset:',\n",
        "        style={'description_width': 'initial'},\n",
        "        layout=widgets.Layout(width='600px')\n",
        "    )\n",
        "    \n",
        "    return dataset_selector\n",
        "\n",
        "# Create parameter configuration widgets\n",
        "def create_pipeline_config_widgets():\n",
        "    \"\"\"Create interactive widgets for pipeline configuration\"\"\"\n",
        "    \n",
        "    # Dataset selection\n",
        "    dataset_selector = create_dataset_selector()\n",
        "    if not dataset_selector:\n",
        "        return None\n",
        "    \n",
        "    # Model configuration\n",
        "    model_variant = widgets.Dropdown(\n",
        "        options=['yolov11n', 'yolov11s', 'yolov11m', 'yolov11l', 'yolov11x'],\n",
        "        value='yolov11n',\n",
        "        description='Model Variant:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    image_size = widgets.IntSlider(\n",
        "        value=640,\n",
        "        min=320,\n",
        "        max=1280,\n",
        "        step=32,\n",
        "        description='Image Size:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    # Training configuration\n",
        "    batch_size = widgets.IntSlider(\n",
        "        value=16,\n",
        "        min=4,\n",
        "        max=64,\n",
        "        step=4,\n",
        "        description='Batch Size:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    epochs = widgets.IntSlider(\n",
        "        value=50,\n",
        "        min=10,\n",
        "        max=200,\n",
        "        step=10,\n",
        "        description='Epochs:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    learning_rate = widgets.FloatLogSlider(\n",
        "        value=0.001,\n",
        "        base=10,\n",
        "        min=-5,\n",
        "        max=-1,\n",
        "        step=0.1,\n",
        "        description='Learning Rate:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    # Infrastructure configuration\n",
        "    instance_type = widgets.Dropdown(\n",
        "        options=['ml.g4dn.xlarge', 'ml.g4dn.2xlarge', 'ml.g4dn.4xlarge', 'ml.p3.2xlarge', 'ml.p3.8xlarge'],\n",
        "        value='ml.g4dn.xlarge',\n",
        "        description='Instance Type:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    use_spot = widgets.Checkbox(\n",
        "        value=True,\n",
        "        description='Use Spot Instances',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    # Performance thresholds\n",
        "    performance_threshold = widgets.FloatSlider(\n",
        "        value=0.3,\n",
        "        min=0.1,\n",
        "        max=0.9,\n",
        "        step=0.05,\n",
        "        description='mAP@0.5 Threshold:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    # Deployment configuration\n",
        "    auto_deploy = widgets.Checkbox(\n",
        "        value=False,\n",
        "        description='Auto-deploy if approved',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    endpoint_name = widgets.Text(\n",
        "        value=f\"yolov11-endpoint-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\",\n",
        "        description='Endpoint Name:',\n",
        "        style={'description_width': 'initial'},\n",
        "        layout=widgets.Layout(width='400px')\n",
        "    )\n",
        "    \n",
        "    return {\n",
        "        'dataset_selector': dataset_selector,\n",
        "        'model_variant': model_variant,\n",
        "        'image_size': image_size,\n",
        "        'batch_size': batch_size,\n",
        "        'epochs': epochs,\n",
        "        'learning_rate': learning_rate,\n",
        "        'instance_type': instance_type,\n",
        "        'use_spot': use_spot,\n",
        "        'performance_threshold': performance_threshold,\n",
        "        'auto_deploy': auto_deploy,\n",
        "        'endpoint_name': endpoint_name\n",
        "    }\n",
        "\n",
        "# Create configuration widgets\n",
        "config_widgets = create_pipeline_config_widgets()\n",
        "\n",
        "if config_widgets:\n",
        "    print(\"üéõÔ∏è Pipeline Configuration Interface\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Display widgets in organized groups\n",
        "    dataset_box = widgets.VBox([\n",
        "        widgets.HTML(\"<h3>üìä Dataset Configuration</h3>\"),\n",
        "        config_widgets['dataset_selector']\n",
        "    ])\n",
        "    \n",
        "    model_box = widgets.VBox([\n",
        "        widgets.HTML(\"<h3>ü§ñ Model Configuration</h3>\"),\n",
        "        config_widgets['model_variant'],\n",
        "        config_widgets['image_size']\n",
        "    ])\n",
        "    \n",
        "    training_box = widgets.VBox([\n",
        "        widgets.HTML(\"<h3>üèãÔ∏è Training Configuration</h3>\"),\n",
        "        config_widgets['batch_size'],\n",
        "        config_widgets['epochs'],\n",
        "        config_widgets['learning_rate']\n",
        "    ])\n",
        "    \n",
        "    infrastructure_box = widgets.VBox([\n",
        "        widgets.HTML(\"<h3>üèóÔ∏è Infrastructure Configuration</h3>\"),\n",
        "        config_widgets['instance_type'],\n",
        "        config_widgets['use_spot']\n",
        "    ])\n",
        "    \n",
        "    deployment_box = widgets.VBox([\n",
        "        widgets.HTML(\"<h3>üöÄ Deployment Configuration</h3>\"),\n",
        "        config_widgets['performance_threshold'],\n",
        "        config_widgets['auto_deploy'],\n",
        "        config_widgets['endpoint_name']\n",
        "    ])\n",
        "    \n",
        "    # Display all configuration widgets\n",
        "    display(widgets.VBox([\n",
        "        dataset_box,\n",
        "        model_box,\n",
        "        training_box,\n",
        "        infrastructure_box,\n",
        "        deployment_box\n",
        "    ]))\n",
        "    \n",
        "    print(\"\\nüí° Configure the parameters above, then run the next cell to create the pipeline.\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå Cannot create configuration interface - no pipeline-ready datasets available\")\n",
        "   \n",
        "def extract_config_values():\n",
        "    \"\"\"Extract current values from configuration widgets\"\"\"\n",
        "    if not config_widgets:\n",
        "        return None\n",
        "    \n",
        "    selected_dataset = config_widgets['dataset_selector'].value\n",
        "    \n",
        "    return {\n",
        "        'dataset_name': selected_dataset['name'],\n",
        "        'dataset_prefix': selected_dataset['prefix'],\n",
        "        'dataset_path': selected_dataset['full_path'],\n",
        "        'model_variant': config_widgets['model_variant'].value,\n",
        "        'image_size': config_widgets['image_size'].value,\n",
        "        'batch_size': config_widgets['batch_size'].value,\n",
        "        'epochs': config_widgets['epochs'].value,\n",
        "        'learning_rate': config_widgets['learning_rate'].value,\n",
        "        'instance_type': config_widgets['instance_type'].value,\n",
        "        'use_spot': config_widgets['use_spot'].value,\n",
        "        'performance_threshold': config_widgets['performance_threshold'].value,\n",
        "        'auto_deploy': config_widgets['auto_deploy'].value,\n",
        "        'endpoint_name': config_widgets['endpoint_name'].value\n",
        "    }\n",
        "   \n",
        "print(\"‚úÖ Configuration interface ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Pipeline Parameters Definition\n",
        "\n",
        "Define SageMaker Pipeline parameters for dynamic configuration and reusability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_pipeline_parameters():\n",
        "    \"\"\"Create SageMaker Pipeline parameters\"\"\"\n",
        "    \n",
        "    # Extract current configuration\n",
        "    config = extract_config_values()\n",
        "    if not config:\n",
        "        print(\"‚ùå No configuration available\")\n",
        "        return None\n",
        "    \n",
        "    # Define pipeline parameters with current values as defaults\n",
        "    parameters = {\n",
        "        # Dataset parameters\n",
        "        'dataset_path': ParameterString(\n",
        "            name=\"DatasetPath\",\n",
        "            default_value=config['dataset_path']\n",
        "        ),\n",
        "        'dataset_name': ParameterString(\n",
        "            name=\"DatasetName\",\n",
        "            default_value=config['dataset_name']\n",
        "        ),\n",
        "        \n",
        "        # Model parameters\n",
        "        'model_variant': ParameterString(\n",
        "            name=\"ModelVariant\",\n",
        "            default_value=config['model_variant']\n",
        "        ),\n",
        "        'image_size': ParameterInteger(\n",
        "            name=\"ImageSize\",\n",
        "            default_value=config['image_size']\n",
        "        ),\n",
        "        \n",
        "        # Training parameters\n",
        "        'batch_size': ParameterInteger(\n",
        "            name=\"BatchSize\",\n",
        "            default_value=config['batch_size']\n",
        "        ),\n",
        "        'epochs': ParameterInteger(\n",
        "            name=\"Epochs\",\n",
        "            default_value=config['epochs']\n",
        "        ),\n",
        "        'learning_rate': ParameterFloat(\n",
        "            name=\"LearningRate\",\n",
        "            default_value=config['learning_rate']\n",
        "        ),\n",
        "        \n",
        "        # Infrastructure parameters\n",
        "        'instance_type': ParameterString(\n",
        "            name=\"InstanceType\",\n",
        "            default_value=config['instance_type']\n",
        "        ),\n",
        "        'use_spot': ParameterString(\n",
        "            name=\"UseSpot\",\n",
        "            default_value=\"true\" if config['use_spot'] else \"false\"\n",
        "        ),\n",
        "        \n",
        "        # Performance threshold\n",
        "        'performance_threshold': ParameterFloat(\n",
        "            name=\"PerformanceThreshold\",\n",
        "            default_value=config['performance_threshold']\n",
        "        ),\n",
        "        \n",
        "        # Deployment parameters\n",
        "        'endpoint_name': ParameterString(\n",
        "            name=\"EndpointName\",\n",
        "            default_value=config['endpoint_name']\n",
        "        ),\n",
        "        \n",
        "        # Output paths\n",
        "        'model_output_path': ParameterString(\n",
        "            name=\"ModelOutputPath\",\n",
        "            default_value=f\"s3://{BUCKET_NAME}/pipeline-artifacts/models\"\n",
        "        ),\n",
        "        'evaluation_output_path': ParameterString(\n",
        "            name=\"EvaluationOutputPath\",\n",
        "            default_value=f\"s3://{BUCKET_NAME}/pipeline-artifacts/evaluation\"\n",
        "        )\n",
        "    }\n",
        "    \n",
        "    return parameters, config\n",
        "\n",
        "# Create pipeline parameters\n",
        "pipeline_parameters, current_config = create_pipeline_parameters()\n",
        "\n",
        "if pipeline_parameters:\n",
        "    print(\"‚úÖ Pipeline parameters created successfully!\")\n",
        "    print(\"\\nüìã Parameter Summary:\")\n",
        "    for name, param in pipeline_parameters.items():\n",
        "        print(f\"   {name}: {param.default_value}\")\n",
        "else:\n",
        "    print(\"‚ùå Failed to create pipeline parameters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Pipeline Step Definitions\n",
        "\n",
        "Define each step of the SageMaker Pipeline with proper dependencies and data flow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_data_validation_step(parameters):\n",
        "    \"\"\"Create data validation processing step\"\"\"\n",
        "    \n",
        "    # Data validation processor\n",
        "    validation_processor = Processor(\n",
        "        image_uri=f\"{account_id}.dkr.ecr.{region}.amazonaws.com/yolov11-preprocessing:latest\",\n",
        "        role=ROLE_ARN,\n",
        "        instance_count=1,\n",
        "        instance_type=\"ml.m5.large\",\n",
        "        sagemaker_session=pipeline_session\n",
        "    )\n",
        "    \n",
        "    # Define processing step\n",
        "    validation_step = ProcessingStep(\n",
        "        name=\"DataValidation\",\n",
        "        processor=validation_processor,\n",
        "        inputs=[\n",
        "            ProcessingInput(\n",
        "                source=parameters['dataset_path'],\n",
        "                destination=\"/opt/ml/processing/input\",\n",
        "                input_name=\"dataset\"\n",
        "            )\n",
        "        ],\n",
        "        outputs=[\n",
        "            ProcessingOutput(\n",
        "                output_name=\"validation_report\",\n",
        "                source=\"/opt/ml/processing/output\",\n",
        "                destination=f\"s3://{BUCKET_NAME}/pipeline-artifacts/validation\"\n",
        "            )\n",
        "        ],\n",
        "        code=\"scripts/validate_dataset.py\",\n",
        "        job_arguments=[\n",
        "            \"--dataset-name\", parameters['dataset_name'],\n",
        "            \"--model-variant\", parameters['model_variant']\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    return validation_step\n",
        "\n",
        "def create_training_step(parameters, validation_step):\n",
        "    \"\"\"Create YOLOv11 training step\"\"\"\n",
        "    \n",
        "    # Training estimator\n",
        "    estimator = Estimator(\n",
        "        image_uri=f\"{account_id}.dkr.ecr.{region}.amazonaws.com/yolov11-training:latest\",\n",
        "        role=ROLE_ARN,\n",
        "        instance_count=1,\n",
        "        instance_type=parameters['instance_type'],\n",
        "        output_path=parameters['model_output_path'],\n",
        "        sagemaker_session=pipeline_session,\n",
        "        use_spot_instances=(parameters['use_spot'] == \"true\"),\n",
        "        max_wait=3600 if parameters['use_spot'] == \"true\" else None,\n",
        "        max_run=3600,\n",
        "        hyperparameters={\n",
        "            \"model_variant\": parameters['model_variant'],\n",
        "            \"image_size\": parameters['image_size'],\n",
        "            \"batch_size\": parameters['batch_size'],\n",
        "            \"epochs\": parameters['epochs'],\n",
        "            \"learning_rate\": parameters['learning_rate'],\n",
        "            \"dataset_name\": parameters['dataset_name']\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    # Training step\n",
        "    training_step = TrainingStep(\n",
        "        name=\"YOLOv11Training\",\n",
        "        estimator=estimator,\n",
        "        inputs={\n",
        "            \"training\": TrainingInput(\n",
        "                s3_data=parameters['dataset_path'],\n",
        "                content_type=\"application/x-parquet\"\n",
        "            )\n",
        "        },\n",
        "        depends_on=[validation_step.name]  # Wait for validation to complete\n",
        "    )\n",
        "    \n",
        "    return training_step\n",
        "\n",
        "def create_evaluation_step(parameters, training_step):\n",
        "    \"\"\"Create model evaluation processing step\"\"\"\n",
        "    \n",
        "    # Evaluation processor\n",
        "    evaluation_processor = Processor(\n",
        "        image_uri=f\"{account_id}.dkr.ecr.{region}.amazonaws.com/yolov11-evaluation:latest\",\n",
        "        role=ROLE_ARN,\n",
        "        instance_count=1,\n",
        "        instance_type=\"ml.g4dn.xlarge\",  # GPU for faster evaluation\n",
        "        sagemaker_session=pipeline_session\n",
        "    )\n",
        "    \n",
        "    # Property file for evaluation metrics\n",
        "    evaluation_report = PropertyFile(\n",
        "        name=\"EvaluationReport\",\n",
        "        output_name=\"evaluation\",\n",
        "        path=\"evaluation.json\"\n",
        "    )\n",
        "    \n",
        "    # Evaluation step\n",
        "    evaluation_step = ProcessingStep(\n",
        "        name=\"ModelEvaluation\",\n",
        "        processor=evaluation_processor,\n",
        "        inputs=[\n",
        "            ProcessingInput(\n",
        "                source=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
        "                destination=\"/opt/ml/processing/model\",\n",
        "                input_name=\"model\"\n",
        "            ),\n",
        "            ProcessingInput(\n",
        "                source=parameters['dataset_path'],\n",
        "                destination=\"/opt/ml/processing/test\",\n",
        "                input_name=\"test_data\"\n",
        "            )\n",
        "        ],\n",
        "        outputs=[\n",
        "            ProcessingOutput(\n",
        "                output_name=\"evaluation\",\n",
        "                source=\"/opt/ml/processing/evaluation\",\n",
        "                destination=parameters['evaluation_output_path']\n",
        "            )\n",
        "        ],\n",
        "        property_files=[evaluation_report],\n",
        "        code=\"scripts/evaluate_model.py\",\n",
        "        job_arguments=[\n",
        "            \"--model-variant\", parameters['model_variant'],\n",
        "            \"--dataset-name\", parameters['dataset_name']\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    return evaluation_step, evaluation_report\n",
        "\n",
        "def create_performance_condition(evaluation_step, evaluation_report, parameters):\n",
        "    \"\"\"Create condition step for performance threshold checking\"\"\"\n",
        "    \n",
        "    # Condition: mAP@0.5 >= threshold\n",
        "    performance_condition = ConditionGreaterThanOrEqualTo(\n",
        "        left=JsonGet(\n",
        "            step_name=evaluation_step.name,\n",
        "            property_file=evaluation_report,\n",
        "            json_path=\"metrics.mAP_50\"\n",
        "        ),\n",
        "        right=parameters['performance_threshold']\n",
        "    )\n",
        "    \n",
        "    return performance_condition\n",
        "\n",
        "def create_model_registration_step(parameters, training_step, evaluation_step):\n",
        "    \"\"\"Create model registration step for Model Registry\"\"\"\n",
        "    \n",
        "    # Model registration\n",
        "    register_model_step = RegisterModel(\n",
        "        name=\"RegisterYOLOv11Model\",\n",
        "        estimator=training_step.estimator,\n",
        "        model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
        "        content_types=[\"application/json\", \"image/jpeg\", \"image/png\"],\n",
        "        response_types=[\"application/json\"],\n",
        "        inference_instances=[\"ml.t2.medium\", \"ml.m5.large\", \"ml.g4dn.xlarge\"],\n",
        "        transform_instances=[\"ml.m5.large\", \"ml.g4dn.xlarge\"],\n",
        "        model_package_group_name=MODEL_PACKAGE_GROUP_NAME,\n",
        "        approval_status=\"PendingManualApproval\",\n",
        "        model_metrics=[\n",
        "            {\n",
        "                \"Name\": \"mAP@0.5\",\n",
        "                \"Value\": JsonGet(\n",
        "                    step_name=evaluation_step.name,\n",
        "                    property_file=\"EvaluationReport\",\n",
        "                    json_path=\"metrics.mAP_50\"\n",
        "                )\n",
        "            },\n",
        "            {\n",
        "                \"Name\": \"mAP@0.5:0.95\",\n",
        "                \"Value\": JsonGet(\n",
        "                    step_name=evaluation_step.name,\n",
        "                    property_file=\"EvaluationReport\",\n",
        "                    json_path=\"metrics.mAP_50_95\"\n",
        "                )\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    return register_model_step\n",
        "\n",
        "def create_model_creation_step(parameters, register_model_step):\n",
        "    \"\"\"Create model creation step for deployment\"\"\"\n",
        "    \n",
        "    # Model creation for deployment\n",
        "    model = Model(\n",
        "        image_uri=f\"{account_id}.dkr.ecr.{region}.amazonaws.com/yolov11-inference:latest\",\n",
        "        model_data=register_model_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
        "        role=ROLE_ARN,\n",
        "        sagemaker_session=pipeline_session\n",
        "    )\n",
        "    \n",
        "    create_model_step = CreateModelStep(\n",
        "        name=\"CreateYOLOv11Model\",\n",
        "        model=model\n",
        "    )\n",
        "    \n",
        "    return create_model_step\n",
        "\n",
        "def create_serverless_endpoint_step(parameters, create_model_step):\n",
        "    \"\"\"Create serverless endpoint deployment step\"\"\"\n",
        "    \n",
        "    # Serverless inference configuration\n",
        "    serverless_config = ServerlessInferenceConfig(\n",
        "        memory_size_in_mb=4096,\n",
        "        max_concurrency=20,\n",
        "        provisioned_concurrency=1  # Keep warm for faster response\n",
        "    )\n",
        "    \n",
        "    # Endpoint deployment processor\n",
        "    deployment_processor = Processor(\n",
        "        image_uri=f\"{account_id}.dkr.ecr.{region}.amazonaws.com/sagemaker-deployment:latest\",\n",
        "        role=ROLE_ARN,\n",
        "        instance_count=1,\n",
        "        instance_type=\"ml.t3.medium\",\n",
        "        sagemaker_session=pipeline_session\n",
        "    )\n",
        "    \n",
        "    # Deployment step\n",
        "    deployment_step = ProcessingStep(\n",
        "        name=\"DeployServerlessEndpoint\",\n",
        "        processor=deployment_processor,\n",
        "        inputs=[\n",
        "            ProcessingInput(\n",
        "                source=create_model_step.properties.ModelName,\n",
        "                destination=\"/opt/ml/processing/model\",\n",
        "                input_name=\"model_name\"\n",
        "            )\n",
        "        ],\n",
        "        outputs=[\n",
        "            ProcessingOutput(\n",
        "                output_name=\"deployment_status\",\n",
        "                source=\"/opt/ml/processing/output\",\n",
        "                destination=f\"s3://{BUCKET_NAME}/pipeline-artifacts/deployment\"\n",
        "            )\n",
        "        ],\n",
        "        code=\"scripts/deploy_serverless_endpoint.py\",\n",
        "        job_arguments=[\n",
        "            \"--endpoint-name\", parameters['endpoint_name'],\n",
        "            \"--memory-size\", \"4096\",\n",
        "            \"--max-concurrency\", \"20\",\n",
        "            \"--provisioned-concurrency\", \"1\"\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    return deployment_step\n",
        "\n",
        "print(\"‚úÖ Pipeline step definition functions created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Pipeline Assembly and Creation\n",
        "\n",
        "Assemble all pipeline steps with proper conditional logic and dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_complete_pipeline(parameters):\n",
        "    \"\"\"Create the complete SageMaker Pipeline with all steps and conditions\"\"\"\n",
        "    \n",
        "    print(\"üîß Creating pipeline steps...\")\n",
        "    \n",
        "    # Step 1: Data Validation\n",
        "    validation_step = create_data_validation_step(parameters)\n",
        "    print(\"   ‚úÖ Data validation step created\")\n",
        "    \n",
        "    # Step 2: Model Training\n",
        "    training_step = create_training_step(parameters, validation_step)\n",
        "    print(\"   ‚úÖ Training step created\")\n",
        "    \n",
        "    # Step 3: Model Evaluation\n",
        "    evaluation_step, evaluation_report = create_evaluation_step(parameters, training_step)\n",
        "    print(\"   ‚úÖ Evaluation step created\")\n",
        "    \n",
        "    # Step 4: Performance Condition Check\n",
        "    performance_condition = create_performance_condition(evaluation_step, evaluation_report, parameters)\n",
        "    print(\"   ‚úÖ Performance condition created\")\n",
        "    \n",
        "    # Step 5: Model Registration (conditional on performance)\n",
        "    register_model_step = create_model_registration_step(parameters, training_step, evaluation_step)\n",
        "    print(\"   ‚úÖ Model registration step created\")\n",
        "    \n",
        "    # Step 6: Model Creation for Deployment\n",
        "    create_model_step = create_model_creation_step(parameters, register_model_step)\n",
        "    print(\"   ‚úÖ Model creation step created\")\n",
        "    \n",
        "    # Step 7: Serverless Endpoint Deployment\n",
        "    deployment_step = create_serverless_endpoint_step(parameters, create_model_step)\n",
        "    print(\"   ‚úÖ Serverless deployment step created\")\n",
        "    \n",
        "    # Create conditional step for performance-based registration\n",
        "    performance_condition_step = ConditionStep(\n",
        "        name=\"CheckPerformanceThreshold\",\n",
        "        conditions=[performance_condition],\n",
        "        if_steps=[register_model_step],\n",
        "        else_steps=[]  # No registration if performance is below threshold\n",
        "    )\n",
        "    \n",
        "    # Create approval condition for deployment\n",
        "    # Note: In practice, this would check Model Registry approval status\n",
        "    # For this demo, we'll use auto-deploy configuration\n",
        "    auto_deploy_condition = ConditionEquals(\n",
        "        left=\"true\",  # This would be replaced with actual approval status check\n",
        "        right=\"true\"\n",
        "    )\n",
        "    \n",
        "    deployment_condition_step = ConditionStep(\n",
        "        name=\"CheckDeploymentApproval\",\n",
        "        conditions=[auto_deploy_condition],\n",
        "        if_steps=[create_model_step, deployment_step],\n",
        "        else_steps=[]\n",
        "    )\n",
        "    \n",
        "    # Assemble pipeline steps\n",
        "    pipeline_steps = [\n",
        "        validation_step,\n",
        "        training_step,\n",
        "        evaluation_step,\n",
        "        performance_condition_step,\n",
        "        deployment_condition_step\n",
        "    ]\n",
        "    \n",
        "    # Create the pipeline\n",
        "    pipeline = Pipeline(\n",
        "        name=PIPELINE_NAME,\n",
        "        parameters=list(parameters.values()),\n",
        "        steps=pipeline_steps,\n",
        "        sagemaker_session=pipeline_session\n",
        "    )\n",
        "    \n",
        "    print(\"   ‚úÖ Pipeline assembly completed\")\n",
        "    \n",
        "    return pipeline\n",
        "\n",
        "# Create the complete pipeline\n",
        "if pipeline_parameters:\n",
        "    print(\"üöÄ Creating YOLOv11 SageMaker Pipeline...\")\n",
        "    yolov11_pipeline = create_complete_pipeline(pipeline_parameters)\n",
        "    \n",
        "    print(f\"\\n‚úÖ Pipeline '{PIPELINE_NAME}' created successfully!\")\n",
        "    print(f\"\\nüìã Pipeline Summary:\")\n",
        "    print(f\"   Name: {yolov11_pipeline.name}\")\n",
        "    print(f\"   Steps: {len(yolov11_pipeline.steps)}\")\n",
        "    print(f\"   Parameters: {len(yolov11_pipeline.parameters)}\")\n",
        "    \n",
        "    # Display pipeline structure\n",
        "    print(f\"\\nüîó Pipeline Flow:\")\n",
        "    print(\"   1. DataValidation (ProcessingStep)\")\n",
        "    print(\"   2. YOLOv11Training (TrainingStep)\")\n",
        "    print(\"   3. ModelEvaluation (ProcessingStep)\")\n",
        "    print(\"   4. CheckPerformanceThreshold (ConditionStep)\")\n",
        "    print(\"      ‚îú‚îÄ IF mAP@0.5 >= threshold: RegisterYOLOv11Model\")\n",
        "    print(\"      ‚îî‚îÄ ELSE: Skip registration\")\n",
        "    print(\"   5. CheckDeploymentApproval (ConditionStep)\")\n",
        "    print(\"      ‚îú‚îÄ IF approved: CreateYOLOv11Model ‚Üí DeployServerlessEndpoint\")\n",
        "    print(\"      ‚îî‚îÄ ELSE: Skip deployment\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå Cannot create pipeline - parameters not available\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Pipeline Execution with MLflow Integration\n",
        "\n",
        "Execute the pipeline with comprehensive MLflow tracking and monitoring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def execute_pipeline_with_mlflow(pipeline, parameters, config):\n",
        "    \"\"\"Execute pipeline with comprehensive MLflow tracking\"\"\"\n",
        "    \n",
        "    # Start MLflow run for pipeline execution\n",
        "    run_name = f\"pipeline-{config['dataset_name']}-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
        "    \n",
        "    with mlflow.start_run(run_name=run_name) as run:\n",
        "        print(f\"üöÄ Starting pipeline execution with MLflow tracking\")\n",
        "        print(f\"   MLflow Run ID: {run.info.run_id}\")\n",
        "        print(f\"   Run Name: {run_name}\")\n",
        "        \n",
        "        # Log pipeline parameters to MLflow\n",
        "        mlflow.log_params({\n",
        "            \"pipeline_name\": pipeline.name,\n",
        "            \"dataset_name\": config['dataset_name'],\n",
        "            \"dataset_path\": config['dataset_path'],\n",
        "            \"model_variant\": config['model_variant'],\n",
        "            \"image_size\": config['image_size'],\n",
        "            \"batch_size\": config['batch_size'],\n",
        "            \"epochs\": config['epochs'],\n",
        "            \"learning_rate\": config['learning_rate'],\n",
        "            \"instance_type\": config['instance_type'],\n",
        "            \"use_spot\": config['use_spot'],\n",
        "            \"performance_threshold\": config['performance_threshold'],\n",
        "            \"auto_deploy\": config['auto_deploy']\n",
        "        })\n",
        "        \n",
        "        # Set MLflow tags\n",
        "        mlflow.set_tags({\n",
        "            \"pipeline_type\": \"sagemaker_pipeline\",\n",
        "            \"model_type\": \"YOLOv11\",\n",
        "            \"task_type\": \"object_detection\",\n",
        "            \"execution_type\": \"automated_pipeline\",\n",
        "            \"dataset\": config['dataset_name'],\n",
        "            \"infrastructure\": \"sagemaker\"\n",
        "        })\n",
        "        \n",
        "        try:\n",
        "            # Create or update the pipeline\n",
        "            print(\"\\nüìù Creating/updating pipeline definition...\")\n",
        "            pipeline.create(role_arn=ROLE_ARN)\n",
        "            print(\"   ‚úÖ Pipeline definition created/updated\")\n",
        "            \n",
        "            # Start pipeline execution\n",
        "            print(\"\\nüé¨ Starting pipeline execution...\")\n",
        "            execution = pipeline.start(\n",
        "                parameters={\n",
        "                    param_name: param.default_value \n",
        "                    for param_name, param in parameters.items()\n",
        "                }\n",
        "            )\n",
        "            \n",
        "            execution_arn = execution.arn\n",
        "            print(f\"   ‚úÖ Pipeline execution started\")\n",
        "            print(f\"   Execution ARN: {execution_arn}\")\n",
        "            \n",
        "            # Log execution details to MLflow\n",
        "            mlflow.log_param(\"pipeline_execution_arn\", execution_arn)\n",
        "            mlflow.log_param(\"execution_start_time\", datetime.now().isoformat())\n",
        "            mlflow.set_tag(\"pipeline_status\", \"running\")\n",
        "            \n",
        "            return execution, run.info.run_id\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Pipeline execution failed: {str(e)}\")\n",
        "            \n",
        "            # Log error to MLflow\n",
        "            mlflow.set_tag(\"pipeline_status\", \"failed\")\n",
        "            mlflow.set_tag(\"error_message\", str(e))\n",
        "            \n",
        "            return None, run.info.run_id\n",
        "\n",
        "# Execute the pipeline\n",
        "if 'yolov11_pipeline' in locals() and yolov11_pipeline and current_config:\n",
        "    print(\"üéØ Ready to execute YOLOv11 Pipeline\")\n",
        "    print(\"\\n‚ö†Ô∏è  Note: This will start a complete pipeline execution which may take 1-2 hours\")\n",
        "    print(\"   and incur AWS costs for training instances and storage.\")\n",
        "    \n",
        "    # Confirmation widget\n",
        "    execute_button = widgets.Button(\n",
        "        description=\"üöÄ Execute Pipeline\",\n",
        "        button_style='success',\n",
        "        layout=widgets.Layout(width='200px', height='40px')\n",
        "    )\n",
        "    \n",
        "    output_widget = widgets.Output()\n",
        "    \n",
        "    def on_execute_clicked(b):\n",
        "        with output_widget:\n",
        "            output_widget.clear_output()\n",
        "            print(\"üöÄ Executing pipeline...\")\n",
        "            \n",
        "            global pipeline_execution, mlflow_run_id\n",
        "            pipeline_execution, mlflow_run_id = execute_pipeline_with_mlflow(\n",
        "                yolov11_pipeline, \n",
        "                pipeline_parameters, \n",
        "                current_config\n",
        "            )\n",
        "            \n",
        "            if pipeline_execution:\n",
        "                print(f\"\\n‚úÖ Pipeline execution started successfully!\")\n",
        "                print(f\"   You can monitor progress in the next section.\")\n",
        "            else:\n",
        "                print(f\"\\n‚ùå Pipeline execution failed. Check the error messages above.\")\n",
        "    \n",
        "    execute_button.on_click(on_execute_clicked)\n",
        "    \n",
        "    display(widgets.VBox([\n",
        "        widgets.HTML(\"<h3>üöÄ Pipeline Execution</h3>\"),\n",
        "        widgets.HTML(\"<p>Click the button below to start the complete YOLOv11 training pipeline:</p>\"),\n",
        "        execute_button,\n",
        "        output_widget\n",
        "    ]))\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå Pipeline not ready for execution\")\n",
        "    print(\"   Please ensure the pipeline was created successfully in the previous steps.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Real-time Pipeline Monitoring\n",
        "\n",
        "Monitor pipeline execution with real-time status updates and step-by-step progress tracking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_pipeline_monitor():\n",
        "    \"\"\"Create interactive pipeline monitoring interface\"\"\"\n",
        "    \n",
        "    # Status display widgets\n",
        "    status_html = widgets.HTML(value=\"<h3>üìä Pipeline Status: Not Started</h3>\")\n",
        "    progress_bar = widgets.IntProgress(\n",
        "        value=0,\n",
        "        min=0,\n",
        "        max=100,\n",
        "        description='Progress:',\n",
        "        bar_style='info',\n",
        "        style={'bar_color': '#1f77b4'},\n",
        "        layout=widgets.Layout(width='500px')\n",
        "    )\n",
        "    \n",
        "    steps_output = widgets.Output()\n",
        "    metrics_output = widgets.Output()\n",
        "    \n",
        "    # Control buttons\n",
        "    refresh_button = widgets.Button(\n",
        "        description=\"üîÑ Refresh Status\",\n",
        "        button_style='info',\n",
        "        layout=widgets.Layout(width='150px')\n",
        "    )\n",
        "    \n",
        "    stop_button = widgets.Button(\n",
        "        description=\"‚èπÔ∏è Stop Pipeline\",\n",
        "        button_style='danger',\n",
        "        layout=widgets.Layout(width='150px')\n",
        "    )\n",
        "    \n",
        "    def update_pipeline_status():\n",
        "        \"\"\"Update pipeline status and progress\"\"\"\n",
        "        if 'pipeline_execution' not in globals() or not pipeline_execution:\n",
        "            status_html.value = \"<h3>üìä Pipeline Status: No Active Execution</h3>\"\n",
        "            return\n",
        "        \n",
        "        try:\n",
        "            # Get execution status\n",
        "            execution_status = pipeline_execution.describe()\n",
        "            \n",
        "            # Update status display\n",
        "            status = execution_status['PipelineExecutionStatus']\n",
        "            status_color = {\n",
        "                'Executing': 'orange',\n",
        "                'Succeeded': 'green',\n",
        "                'Failed': 'red',\n",
        "                'Stopped': 'gray'\n",
        "            }.get(status, 'blue')\n",
        "            \n",
        "            status_html.value = f\"<h3 style='color: {status_color}'>üìä Pipeline Status: {status}</h3>\"\n",
        "            \n",
        "            # Update progress bar\n",
        "            if status == 'Executing':\n",
        "                progress_bar.bar_style = 'info'\n",
        "                progress_bar.value = 50  # Approximate progress\n",
        "            elif status == 'Succeeded':\n",
        "                progress_bar.bar_style = 'success'\n",
        "                progress_bar.value = 100\n",
        "            elif status == 'Failed':\n",
        "                progress_bar.bar_style = 'danger'\n",
        "                progress_bar.value = 0\n",
        "            \n",
        "            # Update steps status\n",
        "            with steps_output:\n",
        "                steps_output.clear_output()\n",
        "                print(\"üîó Pipeline Steps Status:\")\n",
        "                print(\"=\" * 50)\n",
        "                \n",
        "                # Get step executions\n",
        "                steps = pipeline_execution.list_steps()\n",
        "                \n",
        "                for i, step in enumerate(steps):\n",
        "                    step_name = step['StepName']\n",
        "                    step_status = step['StepStatus']\n",
        "                    \n",
        "                    status_icon = {\n",
        "                        'Executing': 'üîÑ',\n",
        "                        'Succeeded': '‚úÖ',\n",
        "                        'Failed': '‚ùå',\n",
        "                        'Stopped': '‚èπÔ∏è'\n",
        "                    }.get(step_status, '‚è≥')\n",
        "                    \n",
        "                    print(f\"{i+1}. {status_icon} {step_name}: {step_status}\")\n",
        "                    \n",
        "                    # Show additional details for active/failed steps\n",
        "                    if step_status in ['Executing', 'Failed']:\n",
        "                        if 'FailureReason' in step:\n",
        "                            print(f\"   ‚ö†Ô∏è  Reason: {step['FailureReason']}\")\n",
        "                        if 'StartTime' in step:\n",
        "                            elapsed = datetime.now() - step['StartTime'].replace(tzinfo=None)\n",
        "                            print(f\"   ‚è±Ô∏è  Elapsed: {str(elapsed).split('.')[0]}\")\n",
        "            \n",
        "            # Update MLflow with current status\n",
        "            if 'mlflow_run_id' in globals() and mlflow_run_id:\n",
        "                with mlflow.start_run(run_id=mlflow_run_id):\n",
        "                    mlflow.set_tag(\"pipeline_status\", status.lower())\n",
        "                    mlflow.log_metric(\"pipeline_progress\", progress_bar.value)\n",
        "                    \n",
        "                    if status == 'Succeeded':\n",
        "                        mlflow.log_param(\"execution_end_time\", datetime.now().isoformat())\n",
        "                        mlflow.set_tag(\"pipeline_completed\", \"true\")\n",
        "            \n",
        "            # Update metrics if available\n",
        "            with metrics_output:\n",
        "                metrics_output.clear_output()\n",
        "                if status == 'Succeeded':\n",
        "                    print(\"üìà Pipeline Metrics:\")\n",
        "                    print(\"=\" * 30)\n",
        "                    print(\"‚úÖ Pipeline completed successfully!\")\n",
        "                    print(\"üìä Check Model Registry for registered model\")\n",
        "                    print(\"üöÄ Check endpoints for deployed model (if auto-deploy enabled)\")\n",
        "                elif status == 'Failed':\n",
        "                    print(\"‚ùå Pipeline Execution Failed\")\n",
        "                    print(\"=\" * 30)\n",
        "                    print(\"Check the steps status above for failure details.\")\n",
        "                    print(\"Review CloudWatch logs for detailed error information.\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            status_html.value = f\"<h3 style='color: red'>‚ùå Error monitoring pipeline: {str(e)}</h3>\"\n",
        "    \n",
        "    def on_refresh_clicked(b):\n",
        "        update_pipeline_status()\n",
        "    \n",
        "    def on_stop_clicked(b):\n",
        "        if 'pipeline_execution' in globals() and pipeline_execution:\n",
        "            try:\n",
        "                pipeline_execution.stop()\n",
        "                status_html.value = \"<h3 style='color: orange'>‚èπÔ∏è Pipeline Stop Requested</h3>\"\n",
        "            except Exception as e:\n",
        "                status_html.value = f\"<h3 style='color: red'>‚ùå Error stopping pipeline: {str(e)}</h3>\"\n",
        "    \n",
        "    refresh_button.on_click(on_refresh_clicked)\n",
        "    stop_button.on_click(on_stop_clicked)\n",
        "    \n",
        "    # Initial status update\n",
        "    update_pipeline_status()\n",
        "    \n",
        "    return widgets.VBox([\n",
        "        status_html,\n",
        "        progress_bar,\n",
        "        widgets.HBox([refresh_button, stop_button]),\n",
        "        widgets.HTML(\"<h4>üìã Step Details:</h4>\"),\n",
        "        steps_output,\n",
        "        widgets.HTML(\"<h4>üìä Execution Metrics:</h4>\"),\n",
        "        metrics_output\n",
        "    ])\n",
        "\n",
        "# Create and display monitoring interface\n",
        "print(\"üìä Pipeline Monitoring Interface\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "monitoring_interface = create_pipeline_monitor()\n",
        "display(monitoring_interface)\n",
        "\n",
        "print(\"\\nüí° Use the 'Refresh Status' button to update the pipeline status.\")\n",
        "print(\"   The interface will show real-time progress of each pipeline step.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Pipeline Results Analysis\n",
        "\n",
        "Analyze pipeline execution results, model performance, and deployment status."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_pipeline_results():\n",
        "    \"\"\"Analyze and display comprehensive pipeline results\"\"\"\n",
        "    \n",
        "    if 'pipeline_execution' not in globals() or not pipeline_execution:\n",
        "        print(\"‚ùå No pipeline execution to analyze\")\n",
        "        return\n",
        "    \n",
        "    try:\n",
        "        # Get execution details\n",
        "        execution_status = pipeline_execution.describe()\n",
        "        steps = pipeline_execution.list_steps()\n",
        "        \n",
        "        print(\"üìä PIPELINE EXECUTION ANALYSIS\")\n",
        "        print(\"=\" * 60)\n",
        "        \n",
        "        # Overall execution summary\n",
        "        status = execution_status['PipelineExecutionStatus']\n",
        "        start_time = execution_status.get('CreationTime')\n",
        "        end_time = execution_status.get('LastModifiedTime')\n",
        "        \n",
        "        print(f\"\\nüéØ Execution Summary:\")\n",
        "        print(f\"   Status: {status}\")\n",
        "        print(f\"   Start Time: {start_time}\")\n",
        "        print(f\"   End Time: {end_time}\")\n",
        "        \n",
        "        if start_time and end_time:\n",
        "            duration = end_time - start_time\n",
        "            print(f\"   Duration: {str(duration).split('.')[0]}\")\n",
        "        \n",
        "        # Step-by-step analysis\n",
        "        print(f\"\\nüîó Step Analysis:\")\n",
        "        successful_steps = 0\n",
        "        failed_steps = 0\n",
        "        \n",
        "        for step in steps:\n",
        "            step_name = step['StepName']\n",
        "            step_status = step['StepStatus']\n",
        "            \n",
        "            if step_status == 'Succeeded':\n",
        "                successful_steps += 1\n",
        "                print(f\"   ‚úÖ {step_name}: {step_status}\")\n",
        "            elif step_status == 'Failed':\n",
        "                failed_steps += 1\n",
        "                print(f\"   ‚ùå {step_name}: {step_status}\")\n",
        "                if 'FailureReason' in step:\n",
        "                    print(f\"      Reason: {step['FailureReason']}\")\n",
        "            else:\n",
        "                print(f\"   üîÑ {step_name}: {step_status}\")\n",
        "        \n",
        "        print(f\"\\nüìà Step Summary: {successful_steps} succeeded, {failed_steps} failed\")\n",
        "        \n",
        "        # Model Registry analysis\n",
        "        if status == 'Succeeded':\n",
        "            print(f\"\\nüèÜ SUCCESS ANALYSIS:\")\n",
        "            \n",
        "            # Check Model Registry for new models\n",
        "            try:\n",
        "                models = sagemaker_client.list_model_packages(\n",
        "                    ModelPackageGroupName=MODEL_PACKAGE_GROUP_NAME,\n",
        "                    SortBy='CreationTime',\n",
        "                    SortOrder='Descending',\n",
        "                    MaxResults=5\n",
        "                )\n",
        "                \n",
        "                recent_models = models.get('ModelPackageSummaryList', [])\n",
        "                if recent_models:\n",
        "                    latest_model = recent_models[0]\n",
        "                    print(f\"   üì¶ Latest Model Registered:\")\n",
        "                    print(f\"      ARN: {latest_model['ModelPackageArn']}\")\n",
        "                    print(f\"      Status: {latest_model['ModelPackageStatus']}\")\n",
        "                    print(f\"      Approval: {latest_model['ModelApprovalStatus']}\")\n",
        "                    print(f\"      Created: {latest_model['CreationTime']}\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ö†Ô∏è  Could not retrieve model registry info: {e}\")\n",
        "            \n",
        "            # Check for deployed endpoints\n",
        "            try:\n",
        "                endpoints = sagemaker_client.list_endpoints(\n",
        "                    SortBy='CreationTime',\n",
        "                    SortOrder='Descending',\n",
        "                    MaxResults=10\n",
        "                )\n",
        "                \n",
        "                recent_endpoints = [\n",
        "                    ep for ep in endpoints.get('Endpoints', [])\n",
        "                    if current_config['endpoint_name'] in ep['EndpointName']\n",
        "                ]\n",
        "                \n",
        "                if recent_endpoints:\n",
        "                    endpoint = recent_endpoints[0]\n",
        "                    print(f\"   üöÄ Endpoint Deployed:\")\n",
        "                    print(f\"      Name: {endpoint['EndpointName']}\")\n",
        "                    print(f\"      Status: {endpoint['EndpointStatus']}\")\n",
        "                    print(f\"      Created: {endpoint['CreationTime']}\")\n",
        "                else:\n",
        "                    print(f\"   ‚ÑπÔ∏è  No matching endpoints found (auto-deploy may be disabled)\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ö†Ô∏è  Could not retrieve endpoint info: {e}\")\n",
        "        \n",
        "        elif status == 'Failed':\n",
        "            print(f\"\\n‚ùå FAILURE ANALYSIS:\")\n",
        "            print(f\"   Pipeline execution failed. Common causes:\")\n",
        "            print(f\"   ‚Ä¢ Data validation issues\")\n",
        "            print(f\"   ‚Ä¢ Training job failures (resource limits, code errors)\")\n",
        "            print(f\"   ‚Ä¢ Model performance below threshold\")\n",
        "            print(f\"   ‚Ä¢ Infrastructure or permission issues\")\n",
        "            print(f\"\\n   üí° Check CloudWatch logs for detailed error information.\")\n",
        "        \n",
        "        # MLflow integration summary\n",
        "        if 'mlflow_run_id' in globals() and mlflow_run_id:\n",
        "            print(f\"\\nüìä MLflow Integration:\")\n",
        "            print(f\"   Run ID: {mlflow_run_id}\")\n",
        "            print(f\"   Experiment: {experiment_name}\")\n",
        "            print(f\"   All pipeline parameters and metrics logged to MLflow\")\n",
        "        \n",
        "        # Recommendations\n",
        "        print(f\"\\nüí° RECOMMENDATIONS:\")\n",
        "        if status == 'Succeeded':\n",
        "            print(f\"   ‚úÖ Pipeline completed successfully!\")\n",
        "            print(f\"   ‚Ä¢ Review model performance in Model Registry\")\n",
        "            print(f\"   ‚Ä¢ Consider approving model for production deployment\")\n",
        "            print(f\"   ‚Ä¢ Set up monitoring for deployed endpoints\")\n",
        "            print(f\"   ‚Ä¢ Compare results with previous pipeline runs\")\n",
        "        else:\n",
        "            print(f\"   üîß Pipeline needs attention:\")\n",
        "            print(f\"   ‚Ä¢ Review failed step details above\")\n",
        "            print(f\"   ‚Ä¢ Check CloudWatch logs for detailed errors\")\n",
        "            print(f\"   ‚Ä¢ Verify dataset quality and format\")\n",
        "            print(f\"   ‚Ä¢ Consider adjusting hyperparameters\")\n",
        "            print(f\"   ‚Ä¢ Ensure sufficient compute resources\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error analyzing pipeline results: {str(e)}\")\n",
        "\n",
        "# Create analysis button\n",
        "analysis_button = widgets.Button(\n",
        "    description=\"üìä Analyze Results\",\n",
        "    button_style='info',\n",
        "    layout=widgets.Layout(width='200px', height='40px')\n",
        ")\n",
        "\n",
        "analysis_output = widgets.Output()\n",
        "\n",
        "def on_analysis_clicked(b):\n",
        "    with analysis_output:\n",
        "        analysis_output.clear_output()\n",
        "        analyze_pipeline_results()\n",
        "\n",
        "analysis_button.on_click(on_analysis_clicked)\n",
        "\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h3>üìä Pipeline Results Analysis</h3>\"),\n",
        "    widgets.HTML(\"<p>Click below to analyze the pipeline execution results:</p>\"),\n",
        "    analysis_button,\n",
        "    analysis_output\n",
        "]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Model Management and Approval Workflow\n",
        "\n",
        "Manage models in the Model Registry and handle approval workflows for production deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model_management_interface():\n",
        "    \"\"\"Create interface for model management and approval\"\"\"\n",
        "    \n",
        "    # Model list display\n",
        "    models_output = widgets.Output()\n",
        "    \n",
        "    # Control buttons\n",
        "    refresh_models_button = widgets.Button(\n",
        "        description=\"üîÑ Refresh Models\",\n",
        "        button_style='info',\n",
        "        layout=widgets.Layout(width='150px')\n",
        "    )\n",
        "    \n",
        "    approve_button = widgets.Button(\n",
        "        description=\"‚úÖ Approve Latest\",\n",
        "        button_style='success',\n",
        "        layout=widgets.Layout(width='150px')\n",
        "    )\n",
        "    \n",
        "    deploy_button = widgets.Button(\n",
        "        description=\"üöÄ Deploy Approved\",\n",
        "        button_style='warning',\n",
        "        layout=widgets.Layout(width='150px')\n",
        "    )\n",
        "    \n",
        "    def refresh_models():\n",
        "        \"\"\"Refresh and display models from Model Registry\"\"\"\n",
        "        with models_output:\n",
        "            models_output.clear_output()\n",
        "            \n",
        "            try:\n",
        "                # Get models from registry\n",
        "                response = sagemaker_client.list_model_packages(\n",
        "                    ModelPackageGroupName=MODEL_PACKAGE_GROUP_NAME,\n",
        "                    SortBy='CreationTime',\n",
        "                    SortOrder='Descending',\n",
        "                    MaxResults=10\n",
        "                )\n",
        "                \n",
        "                models = response.get('ModelPackageSummaryList', [])\n",
        "                \n",
        "                if not models:\n",
        "                    print(\"üì¶ No models found in Model Registry\")\n",
        "                    print(\"   Run a successful pipeline to register models.\")\n",
        "                    return\n",
        "                \n",
        "                print(f\"üì¶ Models in Registry ({len(models)} found):\")\n",
        "                print(\"=\" * 80)\n",
        "                \n",
        "                for i, model in enumerate(models):\n",
        "                    model_arn = model['ModelPackageArn']\n",
        "                    model_id = model_arn.split('/')[-1]\n",
        "                    status = model['ModelPackageStatus']\n",
        "                    approval = model['ModelApprovalStatus']\n",
        "                    created = model['CreationTime']\n",
        "                    \n",
        "                    # Status icons\n",
        "                    status_icon = \"‚úÖ\" if status == \"Completed\" else \"üîÑ\"\n",
        "                    approval_icon = {\n",
        "                        'Approved': '‚úÖ',\n",
        "                        'PendingManualApproval': '‚è≥',\n",
        "                        'Rejected': '‚ùå'\n",
        "                    }.get(approval, '‚ùì')\n",
        "                    \n",
        "                    print(f\"{i+1}. {status_icon} Model: {model_id}\")\n",
        "                    print(f\"   Status: {status} | Approval: {approval_icon} {approval}\")\n",
        "                    print(f\"   Created: {created.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "                    \n",
        "                    # Get additional details for latest model\n",
        "                    if i == 0:\n",
        "                        try:\n",
        "                            details = sagemaker_client.describe_model_package(\n",
        "                                ModelPackageName=model_arn\n",
        "                            )\n",
        "                            \n",
        "                            if 'ModelMetrics' in details:\n",
        "                                print(f\"   üìä Metrics: Available\")\n",
        "                            \n",
        "                            if 'Tags' in details:\n",
        "                                pipeline_tag = next(\n",
        "                                    (tag['Value'] for tag in details['Tags'] \n",
        "                                     if tag['Key'] == 'TrainingJob'), \n",
        "                                    'Unknown'\n",
        "                                )\n",
        "                                print(f\"   üè∑Ô∏è  Source: {pipeline_tag}\")\n",
        "                                \n",
        "                        except Exception as e:\n",
        "                            print(f\"   ‚ö†Ô∏è  Could not get details: {e}\")\n",
        "                    \n",
        "                    print(\"-\" * 80)\n",
        "                \n",
        "                # Store latest model for actions\n",
        "                global latest_model_arn\n",
        "                latest_model_arn = models[0]['ModelPackageArn'] if models else None\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error retrieving models: {str(e)}\")\n",
        "    \n",
        "    def approve_latest_model():\n",
        "        \"\"\"Approve the latest model for deployment\"\"\"\n",
        "        if 'latest_model_arn' not in globals() or not latest_model_arn:\n",
        "            print(\"‚ùå No model available for approval\")\n",
        "            return\n",
        "        \n",
        "        try:\n",
        "            sagemaker_client.update_model_package(\n",
        "                ModelPackageArn=latest_model_arn,\n",
        "                ModelApprovalStatus='Approved',\n",
        "                ApprovalDescription='Approved via ML Engineer Pipeline notebook'\n",
        "            )\n",
        "            \n",
        "            print(f\"‚úÖ Model approved successfully!\")\n",
        "            print(f\"   Model ARN: {latest_model_arn.split('/')[-1]}\")\n",
        "            \n",
        "            # Update MLflow if available\n",
        "            if 'mlflow_run_id' in globals() and mlflow_run_id:\n",
        "                with mlflow.start_run(run_id=mlflow_run_id):\n",
        "                    mlflow.set_tag(\"model_approved\", \"true\")\n",
        "                    mlflow.log_param(\"approved_model_arn\", latest_model_arn)\n",
        "            \n",
        "            # Refresh display\n",
        "            refresh_models()\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error approving model: {str(e)}\")\n",
        "    \n",
        "    def deploy_approved_model():\n",
        "        \"\"\"Deploy the latest approved model to a serverless endpoint\"\"\"\n",
        "        try:\n",
        "            # Find latest approved model\n",
        "            response = sagemaker_client.list_model_packages(\n",
        "                ModelPackageGroupName=MODEL_PACKAGE_GROUP_NAME,\n",
        "                ModelApprovalStatus='Approved',\n",
        "                SortBy='CreationTime',\n",
        "                SortOrder='Descending',\n",
        "                MaxResults=1\n",
        "            )\n",
        "            \n",
        "            approved_models = response.get('ModelPackageSummaryList', [])\n",
        "            if not approved_models:\n",
        "                print(\"‚ùå No approved models found for deployment\")\n",
        "                print(\"   Please approve a model first.\")\n",
        "                return\n",
        "            \n",
        "            approved_model = approved_models[0]\n",
        "            model_arn = approved_model['ModelPackageArn']\n",
        "            \n",
        "            print(f\"üöÄ Deploying approved model...\")\n",
        "            print(f\"   Model: {model_arn.split('/')[-1]}\")\n",
        "            \n",
        "            # Create endpoint name\n",
        "            endpoint_name = f\"yolov11-serverless-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"\n",
        "            \n",
        "            # Get model details\n",
        "            model_details = sagemaker_client.describe_model_package(\n",
        "                ModelPackageName=model_arn\n",
        "            )\n",
        "            \n",
        "            # Create model\n",
        "            model_name = f\"yolov11-model-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
        "            \n",
        "            sagemaker_client.create_model(\n",
        "                ModelName=model_name,\n",
        "                Containers=model_details['InferenceSpecification']['Containers'],\n",
        "                ExecutionRoleArn=ROLE_ARN\n",
        "            )\n",
        "            \n",
        "            print(f\"   ‚úÖ Model created: {model_name}\")\n",
        "            \n",
        "            # Create endpoint configuration\n",
        "            config_name = f\"yolov11-serverless-config-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
        "            \n",
        "            sagemaker_client.create_endpoint_configuration(\n",
        "                EndpointConfigName=config_name,\n",
        "                ProductionVariants=[\n",
        "                    {\n",
        "                        'VariantName': 'primary',\n",
        "                        'ModelName': model_name,\n",
        "                        'ServerlessConfig': {\n",
        "                            'MemorySizeInMB': 4096,\n",
        "                            'MaxConcurrency': 20,\n",
        "                            'ProvisionedConcurrency': 1\n",
        "                        }\n",
        "                    }\n",
        "                ]\n",
        "            )\n",
        "            \n",
        "            print(f\"   ‚úÖ Endpoint configuration created: {config_name}\")\n",
        "            \n",
        "            # Create endpoint\n",
        "            sagemaker_client.create_endpoint(\n",
        "                EndpointName=endpoint_name,\n",
        "                EndpointConfigName=config_name\n",
        "            )\n",
        "            \n",
        "            print(f\"   ‚úÖ Serverless endpoint deployment started: {endpoint_name}\")\n",
        "            print(f\"   ‚è≥ Endpoint will be ready in 5-10 minutes\")\n",
        "            \n",
        "            # Update MLflow\n",
        "            if 'mlflow_run_id' in globals() and mlflow_run_id:\n",
        "                with mlflow.start_run(run_id=mlflow_run_id):\n",
        "                    mlflow.set_tag(\"model_deployed\", \"true\")\n",
        "                    mlflow.log_param(\"deployed_endpoint_name\", endpoint_name)\n",
        "                    mlflow.log_param(\"deployed_model_arn\", model_arn)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error deploying model: {str(e)}\")\n",
        "    \n",
        "    # Button event handlers\n",
        "    def on_refresh_clicked(b):\n",
        "        refresh_models()\n",
        "    \n",
        "    def on_approve_clicked(b):\n",
        "        with models_output:\n",
        "            approve_latest_model()\n",
        "    \n",
        "    def on_deploy_clicked(b):\n",
        "        with models_output:\n",
        "            deploy_approved_model()\n",
        "    \n",
        "    refresh_models_button.on_click(on_refresh_clicked)\n",
        "    approve_button.on_click(on_approve_clicked)\n",
        "    deploy_button.on_click(on_deploy_clicked)\n",
        "    \n",
        "    # Initial load\n",
        "    refresh_models()\n",
        "    \n",
        "    return widgets.VBox([\n",
        "        widgets.HTML(\"<h3>üì¶ Model Registry Management</h3>\"),\n",
        "        widgets.HBox([refresh_models_button, approve_button, deploy_button]),\n",
        "        models_output\n",
        "    ])\n",
        "\n",
        "# Display model management interface\n",
        "model_management_interface = create_model_management_interface()\n",
        "display(model_management_interface)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Troubleshooting and Best Practices\n",
        "\n",
        "Common issues and solutions for SageMaker Pipeline execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_troubleshooting_guide():\n",
        "    \"\"\"Display comprehensive troubleshooting guide\"\"\"\n",
        "    \n",
        "    troubleshooting_html = \"\"\"\n",
        "    <div style=\"background-color: #f8f9fa; padding: 20px; border-radius: 10px; border-left: 5px solid #007bff;\">\n",
        "        <h3>üîß Troubleshooting Guide</h3>\n",
        "        \n",
        "        <h4>üìä Common Pipeline Issues</h4>\n",
        "        <ul>\n",
        "            <li><strong>Data Validation Failures:</strong>\n",
        "                <ul>\n",
        "                    <li>Verify dataset structure matches YOLOv11 requirements</li>\n",
        "                    <li>Check that validation/ directory exists (not val/)</li>\n",
        "                    <li>Ensure image and label counts match</li>\n",
        "                    <li>Validate data.yaml file format</li>\n",
        "                </ul>\n",
        "            </li>\n",
        "            \n",
        "            <li><strong>Training Step Failures:</strong>\n",
        "                <ul>\n",
        "                    <li>Check instance type availability in your region</li>\n",
        "                    <li>Verify ECR container image exists and is accessible</li>\n",
        "                    <li>Review hyperparameters for reasonable values</li>\n",
        "                    <li>Check CloudWatch logs for detailed error messages</li>\n",
        "                    <li>Ensure sufficient disk space for dataset size</li>\n",
        "                </ul>\n",
        "            </li>\n",
        "            \n",
        "            <li><strong>Performance Threshold Issues:</strong>\n",
        "                <ul>\n",
        "                    <li>Lower performance threshold if models consistently fail</li>\n",
        "                    <li>Increase training epochs for better convergence</li>\n",
        "                    <li>Adjust learning rate and batch size</li>\n",
        "                    <li>Verify dataset quality and annotation accuracy</li>\n",
        "                </ul>\n",
        "            </li>\n",
        "            \n",
        "            <li><strong>Deployment Failures:</strong>\n",
        "                <ul>\n",
        "                    <li>Verify inference container image exists</li>\n",
        "                    <li>Check endpoint name uniqueness</li>\n",
        "                    <li>Ensure model approval status is correct</li>\n",
        "                    <li>Review serverless configuration limits</li>\n",
        "                </ul>\n",
        "            </li>\n",
        "        </ul>\n",
        "        \n",
        "        <h4>üöÄ Performance Optimization</h4>\n",
        "        <ul>\n",
        "            <li><strong>Training Optimization:</strong>\n",
        "                <ul>\n",
        "                    <li>Use GPU instances (ml.g4dn.xlarge or larger) for training</li>\n",
        "                    <li>Enable spot instances for cost savings</li>\n",
        "                    <li>Optimize batch size based on GPU memory</li>\n",
        "                    <li>Use mixed precision training for faster convergence</li>\n",
        "                </ul>\n",
        "            </li>\n",
        "            \n",
        "            <li><strong>Pipeline Efficiency:</strong>\n",
        "                <ul>\n",
        "                    <li>Cache pipeline steps when possible</li>\n",
        "                    <li>Use parallel execution for independent steps</li>\n",
        "                    <li>Optimize data preprocessing steps</li>\n",
        "                    <li>Monitor step execution times</li>\n",
        "                </ul>\n",
        "            </li>\n",
        "            \n",
        "            <li><strong>Cost Optimization:</strong>\n",
        "                <ul>\n",
        "                    <li>Use spot instances for training (up to 70% savings)</li>\n",
        "                    <li>Right-size instance types for workload</li>\n",
        "                    <li>Use serverless endpoints for variable traffic</li>\n",
        "                    <li>Clean up unused resources regularly</li>\n",
        "                </ul>\n",
        "            </li>\n",
        "        </ul>\n",
        "        \n",
        "        <h4>üìã Best Practices</h4>\n",
        "        <ul>\n",
        "            <li><strong>Pipeline Design:</strong>\n",
        "                <ul>\n",
        "                    <li>Use parameterized pipelines for flexibility</li>\n",
        "                    <li>Implement proper error handling and retries</li>\n",
        "                    <li>Add comprehensive logging and monitoring</li>\n",
        "                    <li>Use conditional steps for complex workflows</li>\n",
        "                </ul>\n",
        "            </li>\n",
        "            \n",
        "            <li><strong>Model Management:</strong>\n",
        "                <ul>\n",
        "                    <li>Always use Model Registry for model versioning</li>\n",
        "                    <li>Implement approval workflows for production</li>\n",
        "                    <li>Tag models with relevant metadata</li>\n",
        "                    <li>Track model lineage and performance</li>\n",
        "                </ul>\n",
        "            </li>\n",
        "            \n",
        "            <li><strong>Security:</strong>\n",
        "                <ul>\n",
        "                    <li>Use least privilege IAM roles</li>\n",
        "                    <li>Encrypt data at rest and in transit</li>\n",
        "                    <li>Use VPC endpoints for secure communication</li>\n",
        "                    <li>Regularly audit access and permissions</li>\n",
        "                </ul>\n",
        "            </li>\n",
        "        </ul>\n",
        "        \n",
        "        <h4>üîç Debugging Resources</h4>\n",
        "        <ul>\n",
        "            <li><strong>CloudWatch Logs:</strong> /aws/sagemaker/TrainingJobs and /aws/sagemaker/ProcessingJobs</li>\n",
        "            <li><strong>SageMaker Console:</strong> Pipeline executions and step details</li>\n",
        "            <li><strong>MLflow UI:</strong> Experiment tracking and model comparison</li>\n",
        "            <li><strong>Model Registry:</strong> Model versions and approval status</li>\n",
        "        </ul>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    \n",
        "    display(HTML(troubleshooting_html))\n",
        "\n",
        "# Display troubleshooting guide\n",
        "display_troubleshooting_guide()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Summary and Next Steps\n",
        "\n",
        "This comprehensive ML Engineer SageMaker Pipeline notebook has successfully implemented a complete MLOps workflow for YOLOv11 object detection models.\n",
        "\n",
        "### üéØ What We've Accomplished\n",
        "\n",
        "1. **Complete Pipeline Architecture**: Built a full SageMaker Pipeline with:\n",
        "   - Data validation and preprocessing\n",
        "   - YOLOv11 model training with GPU optimization\n",
        "   - Automated model evaluation and performance checking\n",
        "   - Conditional model registration based on performance thresholds\n",
        "   - Automated serverless endpoint deployment for approved models\n",
        "\n",
        "2. **Advanced MLOps Features**:\n",
        "   - **Parameterized Pipelines**: Flexible configuration for different datasets and hyperparameters\n",
        "   - **Conditional Logic**: Performance-based decision making for model registration and deployment\n",
        "   - **Model Registry Integration**: Centralized model management with approval workflows\n",
        "   - **Serverless Endpoints**: Cost-effective inference with auto-scaling capabilities\n",
        "   - **Comprehensive Monitoring**: Real-time pipeline execution tracking\n",
        "\n",
        "3. **Production-Ready Capabilities**:\n",
        "   - **Error Recovery**: Robust error handling and retry mechanisms\n",
        "   - **Cost Optimization**: Spot instances and serverless inference\n",
        "   - **Security**: IAM role-based access control\n",
        "   - **Observability**: MLflow integration for experiment tracking and lineage\n",
        "\n",
        "4. **User Experience Enhancements**:\n",
        "   - **Interactive Configuration**: Widget-based parameter configuration\n",
        "   - **Real-time Monitoring**: Live pipeline status updates\n",
        "   - **Model Management**: Easy model approval and deployment workflows\n",
        "   - **Comprehensive Analysis**: Detailed pipeline results and recommendations\n",
        "\n",
        "### üöÄ Key Advantages Over Individual Training Jobs\n",
        "\n",
        "| Aspect | Individual Jobs | SageMaker Pipeline |\n",
        "|--------|----------------|--------------------|\n",
        "| **Automation** | Manual execution | Fully automated workflow |\n",
        "| **Reproducibility** | Manual tracking | Built-in versioning and lineage |\n",
        "| **Error Handling** | Manual intervention | Automatic retry and recovery |\n",
        "| **Deployment** | Manual process | Conditional automated deployment |\n",
        "| **Monitoring** | Basic job status | Comprehensive step-by-step tracking |\n",
        "| **Governance** | Limited | Full approval workflows and audit trails |\n",
        "| **Scalability** | Single job focus | End-to-end workflow orchestration |\n",
        "\n",
        "### üìà Business Impact\n",
        "\n",
        "- **Reduced Time-to-Market**: Automated workflows eliminate manual steps\n",
        "- **Improved Quality**: Consistent validation and performance thresholds\n",
        "- **Cost Efficiency**: Spot instances and serverless inference reduce costs\n",
        "- **Risk Mitigation**: Approval workflows prevent poor models from reaching production\n",
        "- **Operational Excellence**: Comprehensive monitoring and alerting\n",
        "\n",
        "### üîÆ Next Steps and Enhancements\n",
        "\n",
        "1. **Advanced Monitoring**:\n",
        "   - Implement data drift detection\n",
        "   - Set up model performance monitoring in production\n",
        "   - Create automated retraining triggers\n",
        "\n",
        "2. **Multi-Model Support**:\n",
        "   - Extend pipeline for different YOLO variants\n",
        "   - Support for ensemble models\n",
        "   - A/B testing framework for model comparison\n",
        "\n",
        "3. **Advanced Deployment Patterns**:\n",
        "   - Blue/green deployment strategies\n",
        "   - Canary deployments with traffic splitting\n",
        "   - Multi-region deployment automation\n",
        "\n",
        "4. **Integration Enhancements**:\n",
        "   - CI/CD integration with Git workflows\n",
        "   - Integration with external monitoring tools\n",
        "   - Custom metrics and alerting\n",
        "\n",
        "5. **Performance Optimization**:\n",
        "   - Pipeline caching for faster iterations\n",
        "   - Distributed training for larger datasets\n",
        "   - Advanced hyperparameter optimization\n",
        "\n",
        "### üí° Key Takeaways\n",
        "\n",
        "- **Pipeline-First Approach**: Always design ML workflows as pipelines for production readiness\n",
        "- **Automation is Key**: Reduce manual intervention through comprehensive automation\n",
        "- **Governance Matters**: Implement proper approval workflows and audit trails\n",
        "- **Monitor Everything**: Comprehensive monitoring enables proactive issue resolution\n",
        "- **Cost Consciousness**: Use spot instances and serverless where appropriate\n",
        "\n",
        "This notebook demonstrates the transformation from individual training job management to complete MLOps pipeline orchestration, providing a foundation for production-ready machine learning workflows with YOLOv11 object detection models.\n",
        "\n",
        "---\n",
        "\n",
        "**üéâ Congratulations!** You've successfully implemented a comprehensive SageMaker Pipeline for YOLOv11 object detection with full MLOps capabilities, automated deployment, and production-ready governance features."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
