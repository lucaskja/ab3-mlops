{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Engineer Core Workflow\n",
    "\n",
    "This notebook provides essential functionality for ML Engineers to execute and manage YOLOv11 training pipelines. It focuses on core capabilities while maintaining simplicity.\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "1. **Pipeline Configuration**: Set up YOLOv11 training pipeline parameters\n",
    "2. **Pipeline Execution**: Execute the training pipeline\n",
    "3. **Pipeline Monitoring**: Monitor training progress and results\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- AWS account with appropriate permissions\n",
    "- AWS CLI configured with \"ab\" profile\n",
    "- SageMaker Studio access with ML Engineer role\n",
    "- Access to the drone imagery dataset in S3 bucket: `lucaskle-ab3-project-pv`\n",
    "- Labeled data in YOLOv11 format\n",
    "\n",
    "Let's start by importing the necessary libraries and setting up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Set up AWS session with \"ab\" profile\n",
    "session = boto3.Session(profile_name='ab')\n",
    "sagemaker_session = sagemaker.Session(boto_session=session)\n",
    "sagemaker_client = session.client('sagemaker')\n",
    "region = session.region_name\n",
    "account_id = session.client('sts').get_caller_identity()['Account']\n",
    "\n",
    "# Set up visualization\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "# Define bucket name\n",
    "BUCKET_NAME = 'lucaskle-ab3-project-pv'\n",
    "ROLE_ARN = sagemaker_session.get_caller_identity_arn()\n",
    "\n",
    "print(f\"Data Bucket: {BUCKET_NAME}\")\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"Account ID: {account_id}\")\n",
    "print(f\"Role ARN: {ROLE_ARN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pipeline Configuration\n",
    "\n",
    "Let's configure our YOLOv11 training pipeline parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to list available datasets\n",
    "def list_datasets(bucket, prefix=\"datasets/\"):\n",
    "    \"\"\"List available datasets in S3\"\"\"\n",
    "    s3_client = session.client('s3')\n",
    "    response = s3_client.list_objects_v2(\n",
    "        Bucket=bucket,\n",
    "        Prefix=prefix,\n",
    "        Delimiter='/'\n",
    "    )\n",
    "    \n",
    "    datasets = []\n",
    "    if 'CommonPrefixes' in response:\n",
    "        for obj in response['CommonPrefixes']:\n",
    "            dataset_prefix = obj['Prefix']\n",
    "            dataset_name = dataset_prefix.split('/')[-2]\n",
    "            datasets.append({\n",
    "                'name': dataset_name,\n",
    "                'prefix': dataset_prefix\n",
    "            })\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "# List available datasets\n",
    "datasets = list_datasets(BUCKET_NAME)\n",
    "\n",
    "print(f\"Found {len(datasets)} datasets:\")\n",
    "for i, dataset in enumerate(datasets):\n",
    "    print(f\"  {i+1}. {dataset['name']} - s3://{BUCKET_NAME}/{dataset['prefix']}\")\n",
    "\n",
    "# If no datasets found, provide instructions\n",
    "if not datasets:\n",
    "    print(\"\\nNo datasets found. Please prepare a dataset using the Data Scientist notebook first.\")\n",
    "    print(\"The dataset should be organized in the following structure:\")\n",
    "    print(\"s3://lucaskle-ab3-project-pv/datasets/your_dataset_name/\")\n",
    "    print(\"├── train/\")\n",
    "    print(\"│   ├── images/\")\n",
    "    print(\"│   └── labels/\")\n",
    "    print(\"└── val/\")\n",
    "    print(\"    ├── images/\")\n",
    "    print(\"    └── labels/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "# You can modify these parameters based on your requirements\n",
    "training_params = {\n",
    "    # Dataset parameters\n",
    "    'dataset_name': datasets[0]['name'] if datasets else 'your_dataset_name',\n",
    "    'dataset_prefix': datasets[0]['prefix'] if datasets else 'datasets/your_dataset_name/',\n",
    "    \n",
    "    # Model parameters\n",
    "    'model_variant': 'yolov11n',  # Options: yolov11n, yolov11s, yolov11m, yolov11l, yolov11x\n",
    "    'image_size': 640,  # Input image size (px)\n",
    "    \n",
    "    # Training parameters\n",
    "    'batch_size': 16,\n",
    "    'epochs': 50,\n",
    "    'learning_rate': 0.001,\n",
    "    \n",
    "    # Infrastructure parameters\n",
    "    'instance_type': 'ml.g4dn.xlarge',\n",
    "    'instance_count': 1,\n",
    "    'use_spot': True,\n",
    "    'max_wait': 36000,  # Max wait time for spot instances (seconds)\n",
    "    'max_run': 3600,    # Max run time (seconds)\n",
    "    \n",
    "    # Output parameters\n",
    "    'output_path': f\"s3://{BUCKET_NAME}/model-artifacts/\",\n",
    "    'job_name': f\"yolov11-training-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "}\n",
    "\n",
    "# Display training parameters\n",
    "print(\"YOLOv11 Training Parameters:\")\n",
    "for key, value in training_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Customize Training Parameters\n",
    "\n",
    "You can modify the training parameters above based on your requirements. Here's a guide to the parameters:\n",
    "\n",
    "- **Dataset Parameters**:\n",
    "  - `dataset_name`: Name of your dataset\n",
    "  - `dataset_prefix`: S3 prefix where your dataset is stored\n",
    "\n",
    "- **Model Parameters**:\n",
    "  - `model_variant`: YOLOv11 model variant (yolov11n, yolov11s, yolov11m, yolov11l, yolov11x)\n",
    "  - `image_size`: Input image size in pixels\n",
    "\n",
    "- **Training Parameters**:\n",
    "  - `batch_size`: Batch size for training\n",
    "  - `epochs`: Number of training epochs\n",
    "  - `learning_rate`: Learning rate for optimizer\n",
    "\n",
    "- **Infrastructure Parameters**:\n",
    "  - `instance_type`: SageMaker instance type for training\n",
    "  - `instance_count`: Number of instances to use\n",
    "  - `use_spot`: Whether to use spot instances (cheaper but can be interrupted)\n",
    "  - `max_wait`: Maximum wait time for spot instances (seconds)\n",
    "  - `max_run`: Maximum run time for training job (seconds)\n",
    "\n",
    "- **Output Parameters**:\n",
    "  - `output_path`: S3 path for model artifacts\n",
    "  - `job_name`: Name for the training job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pipeline Execution\n",
    "\n",
    "Now let's execute the YOLOv11 training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and execute training job\n",
    "def execute_training_job(params):\n",
    "    \"\"\"Create and execute SageMaker training job for YOLOv11\"\"\"\n",
    "    # Define hyperparameters\n",
    "    hyperparameters = {\n",
    "        \"model_variant\": params['model_variant'],\n",
    "        \"image_size\": str(params['image_size']),\n",
    "        \"batch_size\": str(params['batch_size']),\n",
    "        \"epochs\": str(params['epochs']),\n",
    "        \"learning_rate\": str(params['learning_rate'])\n",
    "    }\n",
    "    \n",
    "    # Define input data channels\n",
    "    input_data = {\n",
    "        'training': f\"s3://{BUCKET_NAME}/{params['dataset_prefix']}\"\n",
    "    }\n",
    "    \n",
    "    # Create SageMaker estimator\n",
    "    estimator = sagemaker.estimator.Estimator(\n",
    "        image_uri=f\"{account_id}.dkr.ecr.{region}.amazonaws.com/yolov11-training:latest\",\n",
    "        role=ROLE_ARN,\n",
    "        instance_count=params['instance_count'],\n",
    "        instance_type=params['instance_type'],\n",
    "        hyperparameters=hyperparameters,\n",
    "        output_path=params['output_path'],\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        use_spot_instances=params['use_spot'],\n",
    "        max_wait=params['max_wait'] if params['use_spot'] else None,\n",
    "        max_run=params['max_run']\n",
    "    )\n",
    "    \n",
    "    # Start training job\n",
    "    print(f\"Starting training job: {params['job_name']}\")\n",
    "    estimator.fit(input_data, job_name=params['job_name'], wait=False)\n",
    "    \n",
    "    return params['job_name']\n",
    "\n",
    "# Execute training job\n",
    "try:\n",
    "    job_name = execute_training_job(training_params)\n",
    "    print(f\"\\nTraining job started: {job_name}\")\n",
    "    print(f\"You can monitor the job in the SageMaker console or using the cell below.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error starting training job: {str(e)}\")\n",
    "    print(\"\\nPossible causes:\")\n",
    "    print(\"1. The dataset doesn't exist or has incorrect structure\")\n",
    "    print(\"2. The YOLOv11 training container doesn't exist in ECR\")\n",
    "    print(\"3. Insufficient permissions to start training job\")\n",
    "    print(\"\\nPlease check the error message and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pipeline Monitoring\n",
    "\n",
    "Let's monitor the progress of our training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to monitor training job\n",
    "def monitor_training_job(job_name):\n",
    "    \"\"\"Monitor SageMaker training job status\"\"\"\n",
    "    # Get job description\n",
    "    response = sagemaker_client.describe_training_job(\n",
    "        TrainingJobName=job_name\n",
    "    )\n",
    "    \n",
    "    # Extract job status\n",
    "    status = response['TrainingJobStatus']\n",
    "    creation_time = response['CreationTime']\n",
    "    last_modified_time = response.get('LastModifiedTime', creation_time)\n",
    "    \n",
    "    # Calculate duration\n",
    "    duration = last_modified_time - creation_time\n",
    "    duration_minutes = duration.total_seconds() / 60\n",
    "    \n",
    "    # Display job information\n",
    "    print(f\"Job Name: {job_name}\")\n",
    "    print(f\"Status: {status}\")\n",
    "    print(f\"Creation Time: {creation_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Last Modified: {last_modified_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Duration: {duration_minutes:.2f} minutes\")\n",
    "    \n",
    "    # Display additional information based on status\n",
    "    if status == 'InProgress':\n",
    "        print(\"\\nJob is still running. Check back later for results.\")\n",
    "    elif status == 'Completed':\n",
    "        print(\"\\nJob completed successfully!\")\n",
    "        print(f\"Model artifacts: {response['ModelArtifacts']['S3ModelArtifacts']}\")\n",
    "    elif status == 'Failed':\n",
    "        print(\"\\nJob failed!\")\n",
    "        print(f\"Failure reason: {response.get('FailureReason', 'Unknown')}\")\n",
    "    elif status == 'Stopped':\n",
    "        print(\"\\nJob was stopped.\")\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Monitor the training job\n",
    "try:\n",
    "    if 'job_name' in locals():\n",
    "        job_response = monitor_training_job(job_name)\n",
    "    else:\n",
    "        print(\"No active training job to monitor.\")\n",
    "        print(\"Please execute a training job first.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error monitoring training job: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Refresh Job Status\n",
    "\n",
    "You can run the cell below to refresh the job status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refresh job status\n",
    "try:\n",
    "    if 'job_name' in locals():\n",
    "        job_response = monitor_training_job(job_name)\n",
    "    else:\n",
    "        print(\"No active training job to monitor.\")\n",
    "        print(\"Please execute a training job first.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error monitoring training job: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 View Training Metrics\n",
    "\n",
    "Once the training job is complete, you can view the training metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get training metrics\n",
    "def get_training_metrics(job_name):\n",
    "    \"\"\"Get training metrics from CloudWatch\"\"\"\n",
    "    # Get job description\n",
    "    response = sagemaker_client.describe_training_job(\n",
    "        TrainingJobName=job_name\n",
    "    )\n",
    "    \n",
    "    # Check if job is complete\n",
    "    if response['TrainingJobStatus'] != 'Completed':\n",
    "        print(f\"Job is not yet complete. Current status: {response['TrainingJobStatus']}\")\n",
    "        return None\n",
    "    \n",
    "    # Get CloudWatch metrics\n",
    "    cloudwatch = session.client('cloudwatch')\n",
    "    \n",
    "    # Define metrics to retrieve\n",
    "    metrics = [\n",
    "        'train:loss',\n",
    "        'val:loss',\n",
    "        'val:mAP50',\n",
    "        'val:mAP50-95'\n",
    "    ]\n",
    "    \n",
    "    # Get metrics data\n",
    "    metrics_data = {}\n",
    "    for metric_name in metrics:\n",
    "        try:\n",
    "            response = cloudwatch.get_metric_statistics(\n",
    "                Namespace='SageMaker',\n",
    "                MetricName=metric_name,\n",
    "                Dimensions=[\n",
    "                    {\n",
    "                        'Name': 'TrainingJobName',\n",
    "                        'Value': job_name\n",
    "                    }\n",
    "                ],\n",
    "                StartTime=response['CreationTime'],\n",
    "                EndTime=response['LastModifiedTime'],\n",
    "                Period=60,  # 1-minute periods\n",
    "                Statistics=['Average']\n",
    "            )\n",
    "            \n",
    "            # Extract datapoints\n",
    "            datapoints = response.get('Datapoints', [])\n",
    "            if datapoints:\n",
    "                # Sort by timestamp\n",
    "                datapoints.sort(key=lambda x: x['Timestamp'])\n",
    "                \n",
    "                # Extract values\n",
    "                timestamps = [dp['Timestamp'] for dp in datapoints]\n",
    "                values = [dp['Average'] for dp in datapoints]\n",
    "                \n",
    "                metrics_data[metric_name] = {\n",
    "                    'timestamps': timestamps,\n",
    "                    'values': values\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving metric {metric_name}: {str(e)}\")\n",
    "    \n",
    "    return metrics_data\n",
    "\n",
    "# Get training metrics\n",
    "try:\n",
    "    if 'job_name' in locals():\n",
    "        metrics_data = get_training_metrics(job_name)\n",
    "        \n",
    "        if metrics_data:\n",
    "            # Plot metrics\n",
    "            fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "            \n",
    "            # Plot loss\n",
    "            if 'train:loss' in metrics_data:\n",
    "                axes[0].plot(\n",
    "                    metrics_data['train:loss']['timestamps'],\n",
    "                    metrics_data['train:loss']['values'],\n",
    "                    label='Train Loss'\n",
    "                )\n",
    "            \n",
    "            if 'val:loss' in metrics_data:\n",
    "                axes[0].plot(\n",
    "                    metrics_data['val:loss']['timestamps'],\n",
    "                    metrics_data['val:loss']['values'],\n",
    "                    label='Validation Loss'\n",
    "                )\n",
    "            \n",
    "            axes[0].set_title('Training and Validation Loss')\n",
    "            axes[0].set_xlabel('Time')\n",
    "            axes[0].set_ylabel('Loss')\n",
    "            axes[0].legend()\n",
    "            axes[0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Plot mAP\n",
    "            if 'val:mAP50' in metrics_data:\n",
    "                axes[1].plot(\n",
    "                    metrics_data['val:mAP50']['timestamps'],\n",
    "                    metrics_data['val:mAP50']['values'],\n",
    "                    label='mAP@0.5'\n",
    "                )\n",
    "            \n",
    "            if 'val:mAP50-95' in metrics_data:\n",
    "                axes[1].plot(\n",
    "                    metrics_data['val:mAP50-95']['timestamps'],\n",
    "                    metrics_data['val:mAP50-95']['values'],\n",
    "                    label='mAP@0.5:0.95'\n",
    "                )\n",
    "            \n",
    "            axes[1].set_title('Validation mAP')\n",
    "            axes[1].set_xlabel('Time')\n",
    "            axes[1].set_ylabel('mAP')\n",
    "            axes[1].legend()\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Display final metrics\n",
    "            print(\"Final Metrics:\")\n",
    "            for metric_name, data in metrics_data.items():\n",
    "                if data['values']:\n",
    "                    print(f\"  {metric_name}: {data['values'][-1]:.4f}\")\n",
    "        else:\n",
    "            print(\"No metrics available yet. Job may still be running or has failed.\")\n",
    "    else:\n",
    "        print(\"No active training job to monitor.\")\n",
    "        print(\"Please execute a training job first.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving training metrics: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Artifacts\n",
    "\n",
    "Once the training job is complete, you can access the model artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get model artifacts\n",
    "def get_model_artifacts(job_name):\n",
    "    \"\"\"Get model artifacts from training job\"\"\"\n",
    "    # Get job description\n",
    "    response = sagemaker_client.describe_training_job(\n",
    "        TrainingJobName=job_name\n",
    "    )\n",
    "    \n",
    "    # Check if job is complete\n",
    "    if response['TrainingJobStatus'] != 'Completed':\n",
    "        print(f\"Job is not yet complete. Current status: {response['TrainingJobStatus']}\")\n",
    "        return None\n",
    "    \n",
    "    # Get model artifacts\n",
    "    model_artifacts = response['ModelArtifacts']['S3ModelArtifacts']\n",
    "    \n",
    "    print(f\"Model artifacts: {model_artifacts}\")\n",
    "    print(\"\\nThe model artifacts contain:\")\n",
    "    print(\"1. model.tar.gz - The compressed model files\")\n",
    "    print(\"2. Inside model.tar.gz:\")\n",
    "    print(\"   - best.pt - The best model weights\")\n",
    "    print(\"   - last.pt - The last model weights\")\n",
    "    print(\"   - results.csv - Training results\")\n",
    "    print(\"   - args.yaml - Training arguments\")\n",
    "    \n",
    "    return model_artifacts\n",
    "\n",
    "# Get model artifacts\n",
    "try:\n",
    "    if 'job_name' in locals():\n",
    "        model_artifacts = get_model_artifacts(job_name)\n",
    "    else:\n",
    "        print(\"No active training job to monitor.\")\n",
    "        print(\"Please execute a training job first.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving model artifacts: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary and Next Steps\n",
    "\n",
    "In this notebook, we've executed and monitored a YOLOv11 training pipeline. Here's a summary of what we've accomplished:\n",
    "\n",
    "1. **Pipeline Configuration**:\n",
    "   - Listed available datasets\n",
    "   - Configured training parameters\n",
    "\n",
    "2. **Pipeline Execution**:\n",
    "   - Created and executed a SageMaker training job\n",
    "\n",
    "3. **Pipeline Monitoring**:\n",
    "   - Monitored training job status\n",
    "   - Viewed training metrics\n",
    "\n",
    "4. **Model Artifacts**:\n",
    "   - Accessed model artifacts from the training job\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Model Evaluation**: Evaluate the trained model on test data\n",
    "2. **Model Deployment**: Deploy the model to a SageMaker endpoint\n",
    "3. **Model Monitoring**: Set up monitoring for the deployed model\n",
    "4. **Iterative Improvement**: Refine the model based on evaluation results\n",
    "\n",
    "For more detailed functionality, refer to the comprehensive notebooks in the `notebooks/` directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}